{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "fe = []\n",
    "with open(\"train.txt\", \"r\") as f:\n",
    "    for raw_line in f:\n",
    "        line = raw_line.strip().split(\"\\t\")\n",
    "        fe.append(len(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df(filename=\"train.txt\"):\n",
    "    data = {'Source':[], 'Sink':[]}\n",
    "    with open(filename, \"r\") as f:\n",
    "        for raw_line in f:\n",
    "            line = raw_line.strip().split(\"\\t\")\n",
    "            data['Source'] += [line[0]]*(len(line)-1)\n",
    "            data['Sink'] += line[1:]\n",
    "    pd_data = pd.DataFrame(data=data)\n",
    "    pd_data[['Source', 'Sink']] = pd_data[['Source', 'Sink']].apply(pd.to_numeric)\n",
    "    pd_data = pd_data.drop_duplicates(keep=False)\n",
    "    return pd_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_sub():\n",
    "    with open('test-public.txt', 'r') as f:\n",
    "        # skip the header\n",
    "        f.readline()\n",
    "        data = {'Source':[], 'Sink':[]}\n",
    "        for raw_line in f:\n",
    "            line = raw_line.strip().split(\"\\t\")\n",
    "            data['Source'].append(int(line[1]))\n",
    "            data['Sink'].append(int(line[2]))\n",
    "        return pd.DataFrame(data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = create_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Sink</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540762</td>\n",
       "      <td>1912140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>540762</td>\n",
       "      <td>1537559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>540762</td>\n",
       "      <td>3091331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>540762</td>\n",
       "      <td>2757277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>540762</td>\n",
       "      <td>3237295</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Source     Sink\n",
       "0  540762  1912140\n",
       "1  540762  1537559\n",
       "2  540762  3091331\n",
       "3  540762  2757277\n",
       "4  540762  3237295"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_nodes = set(data['Source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23888876, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19570"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(out_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"processed_train.csv\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_data = read_sub()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Sink</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3563811</td>\n",
       "      <td>3600160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2052043</td>\n",
       "      <td>1401960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4517994</td>\n",
       "      <td>1690636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1660006</td>\n",
       "      <td>4349447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>581111</td>\n",
       "      <td>1882617</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Source     Sink\n",
       "0  3563811  3600160\n",
       "1  2052043  1401960\n",
       "2  4517994  1690636\n",
       "3  1660006  4349447\n",
       "4   581111  1882617"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 2)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_nodes = set(sub_data['Source'].value_counts().keys()).union(sub_data['Sink'].value_counts().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_df = data[(data['Source'].isin(sub_nodes)) | (data['Sink'].isin(sub_nodes))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5037682, 2)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = reduced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"processed_train_reduced.csv\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 945,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 945,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_desire_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.test(X_desire)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [00:10<00:00, 1931.40it/s]\n"
     ]
    }
   ],
   "source": [
    "with open(\"train.txt\",\"r\") as f:\n",
    "    lines = f.readlines() \n",
    "\n",
    "matrix = {}\n",
    "for line in tqdm(lines):\n",
    "    temp = list(map(int, line.split()))\n",
    "    if len(temp[1:]) > 0:\n",
    "        matrix[temp[0]] = set(temp[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test-public.txt\",\"r\") as f:\n",
    "    test = f.readlines()\n",
    "\n",
    "test_s = set()\n",
    "test_d = set()\n",
    "for l in test[1:]:\n",
    "    temp = list(map(int, l.split()))\n",
    "    test_s.add(temp[1]) ; test_d.add(temp[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 1978 19570\n"
     ]
    }
   ],
   "source": [
    "print(len(test_s), len(test_d), len(matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19570/19570 [00:13<00:00, 1415.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4867136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "all_v = {}\n",
    "for v in tqdm(matrix):\n",
    "    #all_v[v] = all_v.get(v, 0) + 1\n",
    "    for d in matrix[v]:\n",
    "        all_v[d] = all_v.get(d, 0) + 1\n",
    "print(len(all_v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1978\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# indegree for sinks in test file\n",
    "freq = []\n",
    "for d in test_d:\n",
    "    freq.append(all_v[d])\n",
    "freq.sort()\n",
    "print(len(freq))\n",
    "plt.hist(freq)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_freq = list(all_v.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8763747304369551\n"
     ]
    }
   ],
   "source": [
    "print(len([n for n in all_freq if n >= 1 and n <= 5])/len(all_freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14711830131445905\n"
     ]
    }
   ],
   "source": [
    "print(len([n for n in freq if n <= 2])/len(freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "sink distribution estimation\n",
    "\n",
    "start         end    pmf    cdf\n",
    "        x  <= 2   -- 0.15   0.15  \n",
    "2    <  x  <= 6   -- 0.1    0.25  \n",
    "6    <  x  <= 13  -- 0.1    0.35  \n",
    "13   <  x  <= 25  -- 0.1    0.45  \n",
    "25   <  x  <= 45  -- 0.1    0.55\n",
    "45   <  x  <= 70  -- 0.1    0.65\n",
    "70   <  x  <= 120 -- 0.1    0.75\n",
    "120  <  x  <= 240 -- 0.1    0.85\n",
    "240  <  x         -- 0.15   1  \n",
    "\"\"\"\n",
    "pmf = np.array([0.15] + [0.1] * 7 + [0.15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4867136/4867136 [00:04<00:00, 1014316.12it/s]\n"
     ]
    }
   ],
   "source": [
    "to_node = {n:[] for n in range(9)}\n",
    "to_dis = {}\n",
    "\n",
    "for v in tqdm(all_v):\n",
    "    indegree = all_v[v]\n",
    "    if indegree <= 2:\n",
    "        to_node[0].append(v)\n",
    "        to_dis[v] = 0\n",
    "    elif indegree <= 6:\n",
    "        to_node[1].append(v)\n",
    "        to_dis[v] = 1\n",
    "    elif indegree <= 13:\n",
    "        to_node[2].append(v)\n",
    "        to_dis[v] = 2\n",
    "    elif indegree <= 25:\n",
    "        to_node[3].append(v)\n",
    "        to_dis[v] = 3\n",
    "    elif indegree <= 45:\n",
    "        to_node[4].append(v)\n",
    "        to_dis[v] = 4\n",
    "    elif indegree <= 70:\n",
    "        to_node[5].append(v)\n",
    "        to_dis[v] = 5\n",
    "    elif indegree <= 120:\n",
    "        to_node[6].append(v)\n",
    "        to_dis[v] = 6\n",
    "    elif indegree <= 240:\n",
    "        to_node[7].append(v)\n",
    "        to_dis[v] = 7\n",
    "    else:\n",
    "        to_node[8].append(v)\n",
    "        to_dis[v] = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix[3563811]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample some edges based on the above distribution\n",
    "SAMPLES = 20000\n",
    "\n",
    "data = []\n",
    "\n",
    "all_source = list(matrix.keys())\n",
    "max_dis_sample = SAMPLES*pmf\n",
    "\n",
    "cumulative_sample = np.zeros(9)\n",
    "\n",
    "\n",
    "while len(data) < SAMPLES//2:\n",
    "    target_source = random.choice(all_source)\n",
    "    target_sink = random.sample(matrix[target_source], 1)[0]\n",
    "    sink_dis = to_dis[target_sink]\n",
    "    if cumulative_sample[sink_dis] < max_dis_sample[sink_dis] and target_source != target_sink:\n",
    "        cumulative_sample[sink_dis] += 1\n",
    "        data.append([len(data), target_source, target_sink, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3000. 2000. 2000. 2000. 2000. 2000. 2000. 2000. 3000.]\n",
      "[1399. 1077.  966. 1028. 1025.  756.  951.  969. 1829.]\n"
     ]
    }
   ],
   "source": [
    "print(max_dis_sample)\n",
    "print(cumulative_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.15, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.15])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pmf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample some neg edge from the graph\n",
    "\n",
    "for i in range(len(pmf)):\n",
    "    while cumulative_sample[i] < max_dis_sample[i]:\n",
    "        src = random.choice(all_source)\n",
    "        dest = random.choice(to_node[i])\n",
    "        if dest != src and dest not in matrix[src]:\n",
    "            data.append([len(data), src, dest, 0])\n",
    "            cumulative_sample[i] += 1\n",
    "\n",
    "random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3000. 2000. 2000. 2000. 2000. 2000. 2000. 2000. 3000.]\n",
      "[3000. 2000. 2000. 2000. 2000. 2000. 2000. 2000. 3000.]\n"
     ]
    }
   ],
   "source": [
    "print(max_dis_sample)\n",
    "print(cumulative_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/train-mix.p', 'wb') as f:\n",
    "    pickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/matrix.p', 'wb') as f:\n",
    "    pickle.dump(matrix, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualising using networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g = nx.read_edgelist('processed_train.csv',delimiter=',',create_using=nx.DiGraph(),nodetype=int)\n",
    "g = nx.from_pandas_edgelist(data, \"Source\", \"Sink\", create_using=nx.DiGraph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_test = nx.from_pandas_edgelist(sub_data, \"Source\", \"Sink\", create_using=nx.DiGraph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: \n",
      "Type: DiGraph\n",
      "Number of nodes: 4842581\n",
      "Number of edges: 23888876\n",
      "Average in degree:   4.9331\n",
      "Average out degree:   4.9331\n"
     ]
    }
   ],
   "source": [
    "print(nx.info(g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "indegree_dist = list(dict(g_test.in_degree()).values())\n",
    "indegree_dist.sort()\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(indegree_dist)\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('# Of Followers')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sink = set(sub_data['Sink'])\n",
    "test_source = set(sub_data['Source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1900547\n",
      "2146310\n",
      "1187846\n",
      "3227660\n",
      "3350546\n",
      "2113556\n",
      "180252\n",
      "1867811\n",
      "3481639\n",
      "1474599\n",
      "1646634\n",
      "1089581\n",
      "2441262\n",
      "450606\n",
      "4046914\n",
      "1843267\n",
      "1065029\n",
      "4202576\n",
      "3366994\n",
      "2809938\n",
      "1499223\n",
      "2449495\n",
      "3342431\n",
      "2039908\n",
      "2547815\n",
      "4210797\n",
      "1761389\n",
      "24687\n",
      "770163\n",
      "909435\n",
      "2457732\n",
      "508039\n",
      "852104\n",
      "327819\n",
      "1310861\n",
      "4407437\n",
      "2449551\n",
      "1024144\n",
      "811154\n",
      "2293906\n",
      "1343638\n",
      "1564823\n",
      "1900696\n",
      "4538521\n",
      "1761432\n",
      "1122465\n",
      "4358309\n",
      "4079785\n",
      "3473583\n",
      "434351\n",
      "4612272\n",
      "1188020\n",
      "975030\n",
      "2875576\n",
      "1704126\n",
      "2744512\n",
      "573643\n",
      "2441425\n",
      "3924181\n",
      "1163482\n",
      "2875611\n",
      "2457828\n",
      "2654447\n",
      "2801903\n",
      "4071665\n",
      "884982\n",
      "581881\n",
      "2212090\n",
      "8446\n",
      "3842326\n",
      "3014937\n",
      "3670301\n",
      "639262\n",
      "2089250\n",
      "1630500\n",
      "2335027\n",
      "401716\n",
      "1147187\n",
      "1737013\n",
      "3096888\n",
      "3113273\n",
      "2015545\n",
      "540988\n",
      "2441535\n",
      "262463\n",
      "1352000\n",
      "975170\n",
      "4776261\n",
      "2695493\n",
      "1999174\n",
      "4825421\n",
      "786765\n",
      "2072911\n",
      "4702544\n",
      "4161872\n",
      "778578\n",
      "2851163\n",
      "1155426\n",
      "3490147\n",
      "1655138\n",
      "3064168\n",
      "3064171\n",
      "4702587\n",
      "74116\n",
      "1106311\n",
      "65928\n",
      "1843598\n",
      "2662809\n",
      "2367900\n",
      "1515937\n",
      "3129768\n",
      "4260267\n",
      "3563963\n",
      "2220479\n",
      "549313\n",
      "4039112\n",
      "1171914\n",
      "4260311\n",
      "786905\n",
      "1638876\n",
      "2310626\n",
      "1335782\n",
      "3326440\n",
      "3056105\n",
      "3383792\n",
      "1434096\n",
      "3203581\n",
      "3973631\n",
      "500235\n",
      "3260942\n",
      "4694545\n",
      "3269138\n",
      "98836\n",
      "3432981\n",
      "2138647\n",
      "623128\n",
      "770589\n",
      "4334115\n",
      "1819176\n",
      "2466351\n",
      "2138671\n",
      "3088946\n",
      "909877\n",
      "2204218\n",
      "4571711\n",
      "614976\n",
      "1516101\n",
      "4137545\n",
      "1720912\n",
      "3228248\n",
      "3220062\n",
      "533091\n",
      "4137575\n",
      "4563567\n",
      "2572914\n",
      "4727412\n",
      "2925174\n",
      "639608\n",
      "2687611\n",
      "4334207\n",
      "1966722\n",
      "2810502\n",
      "66184\n",
      "3113610\n",
      "3842707\n",
      "4121239\n",
      "3023512\n",
      "2081433\n",
      "2638496\n",
      "2687648\n",
      "1630882\n",
      "795302\n",
      "3039911\n",
      "3875495\n",
      "1000106\n",
      "2679468\n",
      "2458286\n",
      "1581753\n",
      "3228350\n",
      "3080895\n",
      "2572994\n",
      "4481730\n",
      "1393346\n",
      "713416\n",
      "2548427\n",
      "3760844\n",
      "1049296\n",
      "1745618\n",
      "3744469\n",
      "3965659\n",
      "959204\n",
      "1934053\n",
      "1221351\n",
      "1319659\n",
      "2802415\n",
      "877298\n",
      "3367669\n",
      "1745664\n",
      "770830\n",
      "2941712\n",
      "336679\n",
      "1270571\n",
      "3171117\n",
      "3736367\n",
      "4416308\n",
      "3023674\n",
      "2294587\n",
      "2646855\n",
      "1573721\n",
      "2098014\n",
      "598888\n",
      "2589553\n",
      "4236149\n",
      "615287\n",
      "1131388\n",
      "2990974\n",
      "2696064\n",
      "1319809\n",
      "820096\n",
      "1704842\n",
      "304011\n",
      "1360784\n",
      "3769237\n",
      "3408790\n",
      "3802013\n",
      "3056546\n",
      "1672105\n",
      "4760492\n",
      "230324\n",
      "2433978\n",
      "4375483\n",
      "4654016\n",
      "2384833\n",
      "1606605\n",
      "3056592\n",
      "2106321\n",
      "1860563\n",
      "4064211\n",
      "3908563\n",
      "4768728\n",
      "607193\n",
      "4318174\n",
      "2614240\n",
      "1098727\n",
      "2835433\n",
      "2876400\n",
      "4711410\n",
      "4482044\n",
      "3638272\n",
      "3515397\n",
      "1598473\n",
      "3023881\n",
      "1164306\n",
      "1090583\n",
      "4441117\n",
      "2343967\n",
      "3957792\n",
      "2130979\n",
      "3048498\n",
      "115767\n",
      "2589752\n",
      "4097086\n",
      "4703305\n",
      "1025098\n",
      "3408973\n",
      "222285\n",
      "2843729\n",
      "2851923\n",
      "517208\n",
      "140386\n",
      "1401960\n",
      "1057896\n",
      "1115243\n",
      "4318317\n",
      "4433005\n",
      "2892915\n",
      "83060\n",
      "2032765\n",
      "1918083\n",
      "4195478\n",
      "2999451\n",
      "3196061\n",
      "3720350\n",
      "4629666\n",
      "3818661\n",
      "4203689\n",
      "3392684\n",
      "3155119\n",
      "4318387\n",
      "2819257\n",
      "345273\n",
      "1721532\n",
      "2426046\n",
      "1868992\n",
      "1918161\n",
      "238815\n",
      "3876066\n",
      "4441316\n",
      "2786542\n",
      "1541364\n",
      "4728065\n",
      "1926404\n",
      "1459460\n",
      "2581767\n",
      "3753229\n",
      "2581775\n",
      "1213713\n",
      "3753233\n",
      "197915\n",
      "4408608\n",
      "1836321\n",
      "4400421\n",
      "156967\n",
      "3597614\n",
      "1557808\n",
      "410934\n",
      "697663\n",
      "795970\n",
      "247107\n",
      "591176\n",
      "714063\n",
      "3687762\n",
      "3114343\n",
      "2590058\n",
      "4416875\n",
      "2360684\n",
      "3663210\n",
      "804205\n",
      "173424\n",
      "3933553\n",
      "4400501\n",
      "2794871\n",
      "4842872\n",
      "1107321\n",
      "312697\n",
      "722306\n",
      "124292\n",
      "918928\n",
      "4400529\n",
      "4572564\n",
      "517527\n",
      "664987\n",
      "4023707\n",
      "1328553\n",
      "198059\n",
      "3155373\n",
      "3827118\n",
      "2090416\n",
      "492976\n",
      "705981\n",
      "1598910\n",
      "1811906\n",
      "1738178\n",
      "2753995\n",
      "1861070\n",
      "3696081\n",
      "689620\n",
      "4318682\n",
      "1172955\n",
      "2901470\n",
      "4752868\n",
      "4711909\n",
      "2319846\n",
      "4392420\n",
      "3261936\n",
      "3565042\n",
      "1140217\n",
      "2885124\n",
      "2172420\n",
      "2270726\n",
      "558599\n",
      "4531721\n",
      "2426389\n",
      "4154903\n",
      "558621\n",
      "2713118\n",
      "321056\n",
      "4187681\n",
      "4843044\n",
      "3819046\n",
      "2819640\n",
      "2016826\n",
      "935482\n",
      "403013\n",
      "2672205\n",
      "460370\n",
      "4220502\n",
      "1230427\n",
      "1246815\n",
      "738916\n",
      "968305\n",
      "2426489\n",
      "2647673\n",
      "1771134\n",
      "935557\n",
      "2197130\n",
      "4040333\n",
      "190093\n",
      "3892883\n",
      "4818581\n",
      "4859544\n",
      "304795\n",
      "2786974\n",
      "4081317\n",
      "2811559\n",
      "1001145\n",
      "4564666\n",
      "4253371\n",
      "2361023\n",
      "3188415\n",
      "1246919\n",
      "3344081\n",
      "2344660\n",
      "4638423\n",
      "4204255\n",
      "4531935\n",
      "2860771\n",
      "4318948\n",
      "1574639\n",
      "722676\n",
      "2696951\n",
      "452349\n",
      "2746118\n",
      "4597512\n",
      "902922\n",
      "665355\n",
      "1746700\n",
      "182032\n",
      "4810513\n",
      "2090771\n",
      "3008278\n",
      "2483991\n",
      "4794137\n",
      "4310815\n",
      "1632040\n",
      "4327211\n",
      "4622137\n",
      "116542\n",
      "3393347\n",
      "2836300\n",
      "902990\n",
      "485201\n",
      "4589394\n",
      "976723\n",
      "4548447\n",
      "4253538\n",
      "4835172\n",
      "3098473\n",
      "4745066\n",
      "3549033\n",
      "2918261\n",
      "2656122\n",
      "3196794\n",
      "3311484\n",
      "1836927\n",
      "2443140\n",
      "3114890\n",
      "3803021\n",
      "534415\n",
      "34704\n",
      "2713489\n",
      "4671379\n",
      "3073940\n",
      "1976222\n",
      "296865\n",
      "4695975\n",
      "2951081\n",
      "2516910\n",
      "1451950\n",
      "3385264\n",
      "2238387\n",
      "3491767\n",
      "1222591\n",
      "272322\n",
      "2910154\n",
      "3499985\n",
      "1476562\n",
      "616404\n",
      "2861020\n",
      "2074589\n",
      "2156513\n",
      "3704805\n",
      "4032495\n",
      "2566130\n",
      "3934208\n",
      "3942401\n",
      "1320967\n",
      "3033095\n",
      "4065294\n",
      "296976\n",
      "485401\n",
      "1124379\n",
      "411698\n",
      "1124406\n",
      "1247289\n",
      "1419327\n",
      "3278915\n",
      "4122693\n",
      "911436\n",
      "1312847\n",
      "2582607\n",
      "3024998\n",
      "1304680\n",
      "2189417\n",
      "4024425\n",
      "829561\n",
      "1706106\n",
      "1173628\n",
      "1222780\n",
      "2607238\n",
      "1345674\n",
      "4458638\n",
      "3696787\n",
      "1558680\n",
      "3188891\n",
      "3541155\n",
      "1403043\n",
      "895153\n",
      "3172531\n",
      "370870\n",
      "2648249\n",
      "4131002\n",
      "993467\n",
      "690364\n",
      "903357\n",
      "4794557\n",
      "968894\n",
      "1263808\n",
      "4761802\n",
      "3885261\n",
      "3156174\n",
      "2861268\n",
      "1239270\n",
      "2189548\n",
      "2877677\n",
      "1075439\n",
      "2238705\n",
      "510202\n",
      "3664123\n",
      "698620\n",
      "1140987\n",
      "1591562\n",
      "3000586\n",
      "4114704\n",
      "2500885\n",
      "2869532\n",
      "3705121\n",
      "2533668\n",
      "4196644\n",
      "4524326\n",
      "3221800\n",
      "2320682\n",
      "3320108\n",
      "887086\n",
      "297263\n",
      "2353469\n",
      "1419584\n",
      "248129\n",
      "4507971\n",
      "4254026\n",
      "3713358\n",
      "485713\n",
      "919892\n",
      "3459413\n",
      "960860\n",
      "3221853\n",
      "59748\n",
      "2828648\n",
      "2697578\n",
      "1698155\n",
      "4082028\n",
      "84344\n",
      "297346\n",
      "2075015\n",
      "657809\n",
      "2648469\n",
      "944540\n",
      "1345951\n",
      "4393389\n",
      "1493425\n",
      "4221366\n",
      "4131275\n",
      "4008396\n",
      "2574799\n",
      "690644\n",
      "2787800\n",
      "3394011\n",
      "1092064\n",
      "1526240\n",
      "3467751\n",
      "3426792\n",
      "797163\n",
      "2451953\n",
      "1337853\n",
      "3451393\n",
      "977416\n",
      "4606486\n",
      "2558493\n",
      "191012\n",
      "3410469\n",
      "1624612\n",
      "3648043\n",
      "1821230\n",
      "3492407\n",
      "2312761\n",
      "4311609\n",
      "182841\n",
      "1034816\n",
      "2140739\n",
      "19017\n",
      "870989\n",
      "4418134\n",
      "354904\n",
      "4762204\n",
      "4360799\n",
      "3648097\n",
      "3361377\n",
      "993901\n",
      "3525229\n",
      "723574\n",
      "3320445\n",
      "4622975\n",
      "1378945\n",
      "4647561\n",
      "1436298\n",
      "3164813\n",
      "633489\n",
      "3918495\n",
      "248487\n",
      "3017387\n",
      "371379\n",
      "2534067\n",
      "3558069\n",
      "2001590\n",
      "2509493\n",
      "1256117\n",
      "3664571\n",
      "2484926\n",
      "4123333\n",
      "1403597\n",
      "4074191\n",
      "1436373\n",
      "3279575\n",
      "887515\n",
      "2345693\n",
      "4811488\n",
      "1895140\n",
      "2910951\n",
      "3214055\n",
      "453354\n",
      "4328170\n",
      "3820268\n",
      "846573\n",
      "3705582\n",
      "756464\n",
      "4582129\n",
      "3599091\n",
      "2108151\n",
      "92920\n",
      "1690361\n",
      "4057848\n",
      "4360960\n",
      "68355\n",
      "3861252\n",
      "240398\n",
      "3754768\n",
      "1149714\n",
      "2444056\n",
      "2771739\n",
      "699184\n",
      "4451122\n",
      "3181364\n",
      "2444092\n",
      "2378559\n",
      "1108799\n",
      "1903425\n",
      "2779969\n",
      "2599749\n",
      "478028\n",
      "3812175\n",
      "4524886\n",
      "1059674\n",
      "3345253\n",
      "4574058\n",
      "4066160\n",
      "568178\n",
      "3918706\n",
      "1117046\n",
      "2730873\n",
      "453500\n",
      "142204\n",
      "4828031\n",
      "2911112\n",
      "387980\n",
      "2894737\n",
      "2132882\n",
      "4557720\n",
      "273306\n",
      "4836251\n",
      "4754336\n",
      "4590497\n",
      "4058017\n",
      "4344743\n",
      "4328360\n",
      "1289131\n",
      "1747884\n",
      "3025840\n",
      "2255796\n",
      "4434869\n",
      "1838008\n",
      "871353\n",
      "3320763\n",
      "2862019\n",
      "650181\n",
      "4017095\n",
      "2771917\n",
      "994253\n",
      "2075599\n",
      "2419664\n",
      "2526161\n",
      "3107791\n",
      "3189711\n",
      "4647893\n",
      "3304408\n",
      "805851\n",
      "3369948\n",
      "1010658\n",
      "4082660\n",
      "27621\n",
      "2427880\n",
      "4582377\n",
      "3402731\n",
      "1813487\n",
      "2845684\n",
      "4385783\n",
      "4467705\n",
      "4541441\n",
      "2657284\n",
      "4008968\n",
      "2321417\n",
      "2935817\n",
      "945160\n",
      "1690636\n",
      "3353614\n",
      "1674256\n",
      "3140629\n",
      "1608725\n",
      "1125413\n",
      "3124263\n",
      "1412136\n",
      "4795438\n",
      "3763255\n",
      "1125432\n",
      "855111\n",
      "781384\n",
      "3345483\n",
      "2853969\n",
      "552019\n",
      "1092702\n",
      "1813598\n",
      "732256\n",
      "3169\n",
      "593011\n",
      "4238451\n",
      "1879159\n",
      "388216\n",
      "3058809\n",
      "3951739\n",
      "3476608\n",
      "1608833\n",
      "3656836\n",
      "1445006\n",
      "3026066\n",
      "1911962\n",
      "3509402\n",
      "1748132\n",
      "945318\n",
      "2862261\n",
      "855227\n",
      "3910845\n",
      "1199298\n",
      "3304647\n",
      "773329\n",
      "1862869\n",
      "4213976\n",
      "1109210\n",
      "1502444\n",
      "1125612\n",
      "1428722\n",
      "1412339\n",
      "19703\n",
      "560375\n",
      "3960056\n",
      "1461498\n",
      "3984642\n",
      "249092\n",
      "3501317\n",
      "4631813\n",
      "773389\n",
      "830741\n",
      "4164891\n",
      "2198813\n",
      "2190627\n",
      "2485539\n",
      "1994021\n",
      "4861222\n",
      "1576236\n",
      "52525\n",
      "3312950\n",
      "4369723\n",
      "4836679\n",
      "4721996\n",
      "2846029\n",
      "4091219\n",
      "4156755\n",
      "3222883\n",
      "2436456\n",
      "748911\n",
      "1871227\n",
      "4025737\n",
      "2272655\n",
      "2411921\n",
      "3481\n",
      "3329439\n",
      "2436512\n",
      "3714465\n",
      "2977185\n",
      "1043873\n",
      "3501482\n",
      "159148\n",
      "36278\n",
      "863671\n",
      "3239351\n",
      "2289085\n",
      "3091907\n",
      "3026372\n",
      "3804611\n",
      "634314\n",
      "2616784\n",
      "3280336\n",
      "568789\n",
      "3698134\n",
      "1494497\n",
      "3689961\n",
      "3059178\n",
      "1297898\n",
      "544234\n",
      "2215408\n",
      "2911731\n",
      "2575864\n",
      "1715708\n",
      "994814\n",
      "4738558\n",
      "2321920\n",
      "1764865\n",
      "560647\n",
      "208391\n",
      "4468239\n",
      "4787734\n",
      "3616284\n",
      "2477600\n",
      "4058656\n",
      "3231270\n",
      "4017703\n",
      "4754984\n",
      "1175089\n",
      "1715763\n",
      "2739766\n",
      "323130\n",
      "3501635\n",
      "2125383\n",
      "429643\n",
      "3550829\n",
      "3100279\n",
      "151165\n",
      "1896069\n",
      "487046\n",
      "3870342\n",
      "2772614\n",
      "4394644\n",
      "1191573\n",
      "4648605\n",
      "2502302\n",
      "2346666\n",
      "4656814\n",
      "2870961\n",
      "4099761\n",
      "2092724\n",
      "2559672\n",
      "3354301\n",
      "3542719\n",
      "4148928\n",
      "3124929\n",
      "3051212\n",
      "1134287\n",
      "3993297\n",
      "2617049\n",
      "331490\n",
      "2780902\n",
      "3820\n",
      "3247853\n",
      "2780911\n",
      "1969903\n",
      "2715377\n",
      "2256637\n",
      "3755773\n",
      "1855236\n",
      "2330373\n",
      "3575558\n",
      "3575562\n",
      "2084623\n",
      "3034901\n",
      "2649879\n",
      "1871640\n",
      "2879256\n",
      "4017946\n",
      "3182363\n",
      "3600160\n",
      "4501283\n",
      "1847077\n",
      "4189992\n",
      "1445676\n",
      "782124\n",
      "3649333\n",
      "4681529\n",
      "2412346\n",
      "2207548\n",
      "4017990\n",
      "4525900\n",
      "593740\n",
      "2854737\n",
      "1904466\n",
      "1265496\n",
      "1290080\n",
      "1118051\n",
      "4738916\n",
      "3608422\n",
      "4435816\n",
      "2174830\n",
      "4771694\n",
      "1552238\n",
      "4280178\n",
      "3968886\n",
      "1593213\n",
      "2150273\n",
      "1421199\n",
      "4542352\n",
      "1511324\n",
      "3010461\n",
      "1052574\n",
      "3084188\n",
      "3223457\n",
      "1642405\n",
      "4222887\n",
      "1920941\n",
      "3846070\n",
      "2191287\n",
      "4468670\n",
      "3190721\n",
      "3755971\n",
      "1724356\n",
      "1642439\n",
      "3821531\n",
      "2527196\n",
      "1314779\n",
      "2682848\n",
      "3035105\n",
      "2371556\n",
      "2297830\n",
      "3985383\n",
      "4067304\n",
      "4591592\n",
      "3141618\n",
      "200707\n",
      "1044484\n",
      "2519046\n",
      "1470471\n",
      "1011725\n",
      "4198413\n",
      "348176\n",
      "2928662\n",
      "4788250\n",
      "2928666\n",
      "3354658\n",
      "1609768\n",
      "3239981\n",
      "1503281\n",
      "356401\n",
      "1822769\n",
      "1970230\n",
      "4001849\n",
      "2404411\n",
      "135231\n",
      "2682951\n",
      "3608649\n",
      "1749071\n",
      "4264020\n",
      "3256406\n",
      "2789463\n",
      "3747929\n",
      "2289754\n",
      "2519141\n",
      "3182700\n",
      "1831022\n",
      "1691759\n",
      "3223667\n",
      "4075641\n",
      "643197\n",
      "1282178\n",
      "1519747\n",
      "2928772\n",
      "2216067\n",
      "684188\n",
      "1994910\n",
      "1683619\n",
      "1724582\n",
      "3510439\n",
      "2216118\n",
      "3289271\n",
      "1650875\n",
      "4395196\n",
      "2560187\n",
      "1577152\n",
      "504000\n",
      "823491\n",
      "184526\n",
      "1552592\n",
      "2658514\n",
      "2429140\n",
      "3584225\n",
      "3723496\n",
      "364778\n",
      "2633963\n",
      "4313335\n",
      "3993850\n",
      "2380029\n",
      "413950\n",
      "676096\n",
      "3969288\n",
      "594192\n",
      "1544471\n",
      "2674970\n",
      "3420449\n",
      "3256611\n",
      "3559716\n",
      "3199279\n",
      "897331\n",
      "3068216\n",
      "2093369\n",
      "3961144\n",
      "2421050\n",
      "422207\n",
      "20800\n",
      "2347332\n",
      "3486026\n",
      "3273034\n",
      "2740556\n",
      "1077581\n",
      "2363726\n",
      "258383\n",
      "4657493\n",
      "1413468\n",
      "4141405\n",
      "2576735\n",
      "1102181\n",
      "3199334\n",
      "3084646\n",
      "2978155\n",
      "766318\n",
      "3084655\n",
      "1356142\n",
      "2707827\n",
      "979316\n",
      "684403\n",
      "2314614\n",
      "1372535\n",
      "4469114\n",
      "4116859\n",
      "20863\n",
      "438662\n",
      "2961801\n",
      "2961804\n",
      "2355600\n",
      "3903892\n",
      "1970580\n",
      "1782166\n",
      "2249139\n",
      "3248566\n",
      "4239798\n",
      "2339256\n",
      "2773437\n",
      "111037\n",
      "3068352\n",
      "2273729\n",
      "2552257\n",
      "1757635\n",
      "2175437\n",
      "684494\n",
      "1151440\n",
      "733665\n",
      "725481\n",
      "651758\n",
      "3117551\n",
      "2085361\n",
      "4420088\n",
      "4592122\n",
      "1053181\n",
      "3125762\n",
      "2150915\n",
      "3502599\n",
      "1749516\n",
      "324108\n",
      "1618448\n",
      "3306001\n",
      "3559969\n",
      "4026913\n",
      "4395556\n",
      "2052650\n",
      "3600942\n",
      "619054\n",
      "2462259\n",
      "3707448\n",
      "1331774\n",
      "2716227\n",
      "528966\n",
      "3887691\n",
      "3076689\n",
      "1692250\n",
      "4747868\n",
      "1004127\n",
      "3895911\n",
      "3134056\n",
      "897640\n",
      "1233516\n",
      "914028\n",
      "2011767\n",
      "684683\n",
      "2724492\n",
      "561807\n",
      "2888336\n",
      "2994833\n",
      "414356\n",
      "1233560\n",
      "2912923\n",
      "1479326\n",
      "2249378\n",
      "496292\n",
      "3453615\n",
      "2896571\n",
      "987844\n",
      "4584133\n",
      "3068619\n",
      "668364\n",
      "2282195\n",
      "3355372\n",
      "2347761\n",
      "3068663\n",
      "226043\n",
      "4035326\n",
      "2388735\n",
      "3707649\n",
      "1454852\n",
      "602885\n",
      "1553164\n",
      "3699470\n",
      "4420367\n",
      "1217299\n",
      "4436755\n",
      "1970964\n",
      "1471256\n",
      "2437913\n",
      "3134235\n",
      "4666147\n",
      "725800\n",
      "4576051\n",
      "2143027\n",
      "3035961\n",
      "4100923\n",
      "3052350\n",
      "2052938\n",
      "2118489\n",
      "217951\n",
      "807776\n",
      "2978657\n",
      "2560869\n",
      "4813671\n",
      "2216830\n",
      "2634625\n",
      "3494785\n",
      "4494215\n",
      "1250193\n",
      "3699604\n",
      "832404\n",
      "3117977\n",
      "2061209\n",
      "775084\n",
      "480173\n",
      "906157\n",
      "2454450\n",
      "4772788\n",
      "816056\n",
      "3208122\n",
      "4715451\n",
      "4289469\n",
      "4371399\n",
      "1709005\n",
      "922576\n",
      "1291219\n",
      "2692053\n",
      "2962391\n",
      "144346\n",
      "1438686\n",
      "3888099\n",
      "3929060\n",
      "1930214\n",
      "3060714\n",
      "1635309\n",
      "70648\n",
      "4772869\n",
      "3855367\n",
      "2536472\n",
      "1954844\n",
      "4781085\n",
      "357407\n",
      "2561058\n",
      "4183076\n",
      "1881129\n",
      "1193003\n",
      "439339\n",
      "2888762\n",
      "209978\n",
      "2085955\n",
      "1020996\n",
      "4371525\n",
      "709701\n",
      "955459\n",
      "2839624\n",
      "4322378\n",
      "3732555\n",
      "4682830\n",
      "2962511\n",
      "2339921\n",
      "2184279\n",
      "2176087\n",
      "4617310\n",
      "742495\n",
      "3159135\n",
      "2479212\n",
      "1365102\n",
      "3798130\n",
      "2634870\n",
      "2307193\n",
      "1512580\n",
      "2659465\n",
      "2176138\n",
      "3413134\n",
      "2290830\n",
      "2184341\n",
      "898199\n",
      "1840280\n",
      "4568216\n",
      "2839713\n",
      "3249325\n",
      "267438\n",
      "2454704\n",
      "300209\n",
      "1488049\n",
      "3798203\n",
      "3470524\n",
      "2176187\n",
      "2372798\n",
      "2012351\n",
      "3617986\n",
      "447696\n",
      "3339479\n",
      "3781850\n",
      "1365213\n",
      "4838623\n",
      "4199650\n",
      "742626\n",
      "2626788\n",
      "1766631\n",
      "537835\n",
      "4576493\n",
      "726255\n",
      "1553648\n",
      "3036402\n",
      "3413236\n",
      "2700537\n",
      "1504506\n",
      "136445\n",
      "3085568\n",
      "439557\n",
      "2798862\n",
      "1979673\n",
      "431388\n",
      "4650269\n",
      "1094944\n",
      "3388705\n",
      "218407\n",
      "685354\n",
      "3405099\n",
      "357684\n",
      "4502842\n",
      "1512774\n",
      "1652042\n",
      "431437\n",
      "2667854\n",
      "2020689\n",
      "4363601\n",
      "4216150\n",
      "2381152\n",
      "955748\n",
      "2479466\n",
      "3880301\n",
      "1963388\n",
      "284033\n",
      "4519298\n",
      "2086284\n",
      "2921872\n",
      "1774992\n",
      "996752\n",
      "2405789\n",
      "3847583\n",
      "2880930\n",
      "2618792\n",
      "1177008\n",
      "988593\n",
      "2373045\n",
      "1152442\n",
      "1037755\n",
      "3470780\n",
      "849342\n",
      "2913734\n",
      "4314568\n",
      "734667\n",
      "3896780\n",
      "1799634\n",
      "3503570\n",
      "218580\n",
      "2774493\n",
      "349662\n",
      "374242\n",
      "4036102\n",
      "2848271\n",
      "4404761\n",
      "2536994\n",
      "2586149\n",
      "4355632\n",
      "3634739\n",
      "2119220\n",
      "4560439\n",
      "1898044\n",
      "2856519\n",
      "3937867\n",
      "2741848\n",
      "3503706\n",
      "1103453\n",
      "3708510\n",
      "3749479\n",
      "3675752\n",
      "1439349\n",
      "4675195\n",
      "628351\n",
      "2111106\n",
      "3323523\n",
      "415372\n",
      "3495564\n",
      "3954325\n",
      "1627800\n",
      "1865375\n",
      "1914544\n",
      "3757747\n",
      "2389688\n",
      "1996476\n",
      "3069633\n",
      "1963713\n",
      "3593924\n",
      "1119943\n",
      "3839688\n",
      "3348174\n",
      "251605\n",
      "833238\n",
      "489176\n",
      "612058\n",
      "480987\n",
      "374494\n",
      "1963746\n",
      "1734382\n",
      "4708082\n",
      "3946228\n",
      "3856122\n",
      "2864890\n",
      "1013507\n",
      "4347654\n",
      "3561222\n",
      "3471113\n",
      "407308\n",
      "4151054\n",
      "3888913\n",
      "4470546\n",
      "751384\n",
      "1554209\n",
      "4052781\n",
      "3127090\n",
      "1709886\n",
      "3135294\n",
      "2479937\n",
      "4298567\n",
      "3143497\n",
      "3159891\n",
      "1939283\n",
      "4274005\n",
      "1734487\n",
      "3004250\n",
      "546654\n",
      "317280\n",
      "2602849\n",
      "3757922\n",
      "3323751\n",
      "3602280\n",
      "2185079\n",
      "2307962\n",
      "1152903\n",
      "2922377\n",
      "2635670\n",
      "4708250\n",
      "4003751\n",
      "2922412\n",
      "4118446\n",
      "79794\n",
      "915390\n",
      "1177536\n",
      "3733440\n",
      "2856899\n",
      "2496454\n",
      "866252\n",
      "4405196\n",
      "4208608\n",
      "4446185\n",
      "1382378\n",
      "956400\n",
      "2684920\n",
      "71675\n",
      "3717119\n",
      "1062915\n",
      "4642822\n",
      "2324491\n",
      "1366030\n",
      "3553296\n",
      "1210385\n",
      "4266005\n",
      "4356123\n",
      "2897948\n",
      "4749344\n",
      "808997\n",
      "2619444\n",
      "4216887\n",
      "2340926\n",
      "3266624\n",
      "1914949\n",
      "3921990\n",
      "325707\n",
      "358481\n",
      "3700822\n",
      "1087575\n",
      "4077658\n",
      "4290652\n",
      "3422300\n",
      "4405345\n",
      "1849445\n",
      "3496038\n",
      "4020327\n",
      "2488425\n",
      "4069484\n",
      "1562733\n",
      "2742381\n",
      "751729\n",
      "3324029\n",
      "3872893\n",
      "1316991\n",
      "120964\n",
      "2586757\n",
      "1300614\n",
      "3963016\n",
      "1710222\n",
      "1341590\n",
      "3135639\n",
      "2971799\n",
      "3414171\n",
      "2185372\n",
      "1710237\n",
      "1161378\n",
      "4397219\n",
      "342180\n",
      "4094117\n",
      "1775782\n",
      "4372648\n",
      "1022123\n",
      "1087665\n",
      "2930869\n",
      "3520697\n",
      "3029178\n",
      "2242746\n",
      "1071292\n",
      "3791041\n",
      "2398402\n",
      "1661124\n",
      "6342\n",
      "4020429\n",
      "1038547\n",
      "2726100\n",
      "309459\n",
      "2947289\n",
      "4618466\n",
      "4077796\n",
      "2586853\n",
      "1243368\n",
      "4569325\n",
      "563440\n",
      "473328\n",
      "2406650\n",
      "456955\n",
      "2922749\n",
      "2627841\n",
      "383234\n",
      "4413698\n",
      "3184903\n",
      "3119369\n",
      "4110603\n",
      "2152724\n",
      "3045658\n",
      "1227048\n",
      "4585771\n",
      "3348780\n",
      "2177327\n",
      "2472245\n",
      "4446522\n",
      "3627323\n",
      "203069\n",
      "3021117\n",
      "2455876\n",
      "3225925\n",
      "3602761\n",
      "3029332\n",
      "4266331\n",
      "2685279\n",
      "2726244\n",
      "4675943\n",
      "2316647\n",
      "2578793\n",
      "1988974\n",
      "2709873\n",
      "2906483\n",
      "1997173\n",
      "743805\n",
      "2562439\n",
      "1448332\n",
      "4176278\n",
      "293274\n",
      "104861\n",
      "498078\n",
      "4528543\n",
      "2341282\n",
      "6569\n",
      "1374634\n",
      "3799466\n",
      "2111916\n",
      "2079148\n",
      "694702\n",
      "2390448\n",
      "1259953\n",
      "2251186\n",
      "2005432\n",
      "2152889\n",
      "1546682\n",
      "3275195\n",
      "407997\n",
      "301504\n",
      "1096132\n",
      "195020\n",
      "1956304\n",
      "874967\n",
      "39384\n",
      "6618\n",
      "2865630\n",
      "3135966\n",
      "1980899\n",
      "2570732\n",
      "3291628\n",
      "2718199\n",
      "4758008\n",
      "1882617\n",
      "1030651\n",
      "2595326\n",
      "3078655\n",
      "4626946\n",
      "1751557\n",
      "2570760\n",
      "3561993\n",
      "1669644\n",
      "1980941\n",
      "4037133\n",
      "3078677\n",
      "1325591\n",
      "2710040\n",
      "3545625\n",
      "4602393\n",
      "3160600\n",
      "121380\n",
      "809513\n",
      "1784364\n",
      "367148\n",
      "4626992\n",
      "793137\n",
      "3390005\n",
      "3054136\n",
      "1358394\n",
      "2120251\n",
      "506428\n",
      "2480704\n",
      "2169410\n",
      "2505283\n",
      "3447365\n",
      "367174\n",
      "4733521\n",
      "3086931\n",
      "1596000\n",
      "2275938\n",
      "23142\n",
      "1751669\n",
      "3504762\n",
      "4676230\n",
      "1940114\n",
      "2316950\n",
      "3537558\n",
      "2423450\n",
      "899758\n",
      "1120944\n",
      "1030840\n",
      "1751736\n",
      "3201723\n",
      "2906814\n",
      "2800320\n",
      "3644096\n",
      "1735364\n",
      "3300036\n",
      "2816710\n",
      "236233\n",
      "3226313\n",
      "408271\n",
      "3775185\n",
      "1956562\n",
      "4373207\n",
      "309978\n",
      "1333981\n",
      "3087074\n",
      "4152035\n",
      "4373229\n",
      "1186542\n",
      "4078325\n",
      "776951\n",
      "3685112\n",
      "2718459\n",
      "260860\n",
      "4168453\n",
      "4479751\n",
      "3119880\n",
      "3971849\n",
      "2661129\n",
      "3717898\n",
      "4307724\n",
      "2333453\n",
      "3832593\n",
      "1653526\n",
      "547610\n",
      "2177822\n",
      "3709733\n",
      "2759472\n",
      "3513137\n",
      "2341683\n",
      "531259\n",
      "2972477\n",
      "3808061\n",
      "3046207\n",
      "3513152\n",
      "252737\n",
      "3816260\n",
      "4741959\n",
      "4258632\n",
      "4012878\n",
      "1153881\n",
      "4373340\n",
      "1801062\n",
      "703336\n",
      "3996522\n",
      "924523\n",
      "4397945\n",
      "670587\n",
      "1891218\n",
      "4447130\n",
      "2390938\n",
      "4520863\n",
      "310176\n",
      "1924002\n",
      "940964\n",
      "4709294\n",
      "3914672\n",
      "2243505\n",
      "4668341\n",
      "4258747\n",
      "1489854\n",
      "1686462\n",
      "3005378\n",
      "4520904\n",
      "2259916\n",
      "1768408\n",
      "1326049\n",
      "3873762\n",
      "4496362\n",
      "785388\n",
      "1407983\n",
      "1612785\n",
      "187384\n",
      "1063954\n",
      "3726355\n",
      "400402\n",
      "736277\n",
      "3333143\n",
      "3423256\n",
      "474137\n",
      "4307997\n",
      "3333150\n",
      "1776669\n",
      "2472993\n",
      "3300386\n",
      "1440805\n",
      "4267048\n",
      "4152364\n",
      "2579504\n",
      "3963953\n",
      "875582\n",
      "4619326\n",
      "1064010\n",
      "1858641\n",
      "4734034\n",
      "3447893\n",
      "23641\n",
      "4602973\n",
      "687208\n",
      "1416302\n",
      "2161778\n",
      "4742259\n",
      "4676732\n",
      "1694844\n",
      "3980414\n",
      "220288\n",
      "629892\n",
      "3947656\n",
      "3153041\n",
      "2620563\n",
      "162970\n",
      "842907\n",
      "3767456\n",
      "408740\n",
      "335012\n",
      "1252520\n",
      "1588396\n",
      "900269\n",
      "4365487\n",
      "2931888\n",
      "720062\n",
      "4611266\n",
      "4398275\n",
      "2530501\n",
      "154828\n",
      "4668626\n",
      "1998036\n",
      "2440405\n",
      "957660\n",
      "4414697\n",
      "4250859\n",
      "2456813\n",
      "4693230\n",
      "1547503\n",
      "2465006\n",
      "4504821\n",
      "4152569\n",
      "2923781\n",
      "48391\n",
      "4185352\n",
      "2956553\n",
      "4005132\n",
      "3390742\n",
      "1580313\n",
      "1236249\n",
      "3751202\n",
      "3685670\n",
      "4554027\n",
      "2948400\n",
      "4152626\n",
      "4480308\n",
      "687413\n",
      "2817333\n",
      "3259708\n",
      "3464511\n",
      "834880\n",
      "703809\n",
      "744768\n",
      "4513088\n",
      "4840774\n",
      "1080648\n",
      "1006924\n",
      "1957200\n",
      "3628372\n",
      "1301861\n",
      "3661174\n",
      "3267961\n",
      "4709755\n",
      "1924493\n",
      "1318288\n",
      "4251028\n",
      "4496788\n",
      "3218837\n",
      "990629\n",
      "892334\n",
      "2833839\n",
      "1465777\n",
      "4824499\n",
      "2506163\n",
      "4488629\n",
      "3726775\n",
      "4734391\n",
      "605626\n",
      "4103612\n",
      "114108\n",
      "3702208\n",
      "4079041\n",
      "253382\n",
      "728525\n",
      "4660687\n",
      "2080208\n",
      "2252242\n",
      "2358740\n",
      "4816342\n",
      "695775\n",
      "3079649\n",
      "48617\n",
      "2039273\n",
      "4627952\n",
      "2768371\n",
      "3841523\n",
      "2399736\n",
      "1809918\n",
      "1326590\n",
      "3874308\n",
      "1809926\n",
      "4349447\n",
      "4677126\n",
      "114187\n",
      "2334222\n",
      "1302031\n",
      "1564183\n",
      "2907677\n",
      "3235366\n",
      "1121833\n",
      "859694\n",
      "4333106\n",
      "1523252\n",
      "1957433\n",
      "2129471\n",
      "3546688\n",
      "2137665\n",
      "2162243\n",
      "4816452\n",
      "4136520\n",
      "523852\n",
      "3227213\n",
      "2571854\n",
      "1228370\n",
      "1859161\n",
      "4652644\n",
      "310894\n",
      "4087409\n",
      "7797\n",
      "1752699\n",
      "1990270\n",
      "3595902\n",
      "3669648\n",
      "2129558\n",
      "843434\n",
      "2326192\n",
      "3579569\n",
      "868022\n",
      "4538041\n",
      "4759228\n",
      "2391752\n",
      "376521\n",
      "2481873\n",
      "1572565\n",
      "3342037\n",
      "483029\n",
      "4038363\n",
      "4079324\n",
      "958177\n",
      "466667\n",
      "1769196\n",
      "4030190\n",
      "245493\n",
      "1277693\n",
      "3628797\n",
      "4488963\n",
      "1056518\n",
      "302871\n",
      "2047772\n",
      "1171232\n",
      "2547493\n",
      "4177702\n",
      "130859\n",
      "4570930\n",
      "3981107\n",
      "3301174\n",
      "720696\n",
      "2531130\n",
      "1376063\n",
      "1228608\n",
      "2842435\n",
      "1064772\n",
      "3415877\n",
      "491336\n",
      "8009\n",
      "245586\n",
      "4521813\n",
      "2309976\n",
      "2457436\n",
      "1392477\n",
      "1736544\n",
      "2359143\n",
      "2072437\n",
      "4177782\n",
      "2121590\n",
      "3186551\n",
      "2277245\n",
      "2793348\n",
      "3456906\n",
      "4710285\n",
      "4726674\n",
      "147352\n",
      "1433498\n",
      "1892251\n",
      "2391963\n",
      "2555807\n",
      "3317670\n",
      "4349867\n",
      "3071916\n",
      "4186033\n",
      "1228727\n",
      "221113\n",
      "4792252\n",
      "4046792\n",
      "3424202\n",
      "4161485\n",
      "638930\n",
      "4612050\n",
      "1990620\n",
      "4480989\n",
      "1384420\n",
      "835556\n",
      "3653610\n",
      "1646572\n",
      "81900\n",
      "4276206\n",
      "2203631\n",
      "4161520\n",
      "303087\n",
      "2883570\n",
      "106487\n",
      "4489215\n"
     ]
    }
   ],
   "source": [
    "for i in test_sink:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_v[485713]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "485713\n"
     ]
    }
   ],
   "source": [
    "for i in test_sink:\n",
    "    try:\n",
    "        g.in_degree(i)\n",
    "    except:\n",
    "        print(i)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90 percentile value is 5.0\n",
      "91 percentile value is 5.0\n",
      "92 percentile value is 5.0\n",
      "93 percentile value is 6.0\n",
      "94 percentile value is 6.0\n",
      "95 percentile value is 7.0\n",
      "96 percentile value is 8.0\n",
      "97 percentile value is 9.0\n",
      "98 percentile value is 11.0\n",
      "99 percentile value is 17.0\n",
      "100 percentile value is 513.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,11):\n",
    "    print(90+i,'percentile value is',np.percentile(indegree_dist, 90+i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.1 percentile value is 17.0\n",
      "99.2 percentile value is 19.0\n",
      "99.3 percentile value is 20.0\n",
      "99.4 percentile value is 22.0\n",
      "99.5 percentile value is 24.0\n",
      "99.6 percentile value is 27.4320000000007\n",
      "99.7 percentile value is 32.0\n",
      "99.8 percentile value is 41.0\n",
      "99.9 percentile value is 70.0\n",
      "100.0 percentile value is 513.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(10,110,10):\n",
    "    print(99+(i/100),'percentile value is',np.percentile(indegree_dist,99+(i/100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of persons who have no followers 2126 and % is 1.5731484427606313\n"
     ]
    }
   ],
   "source": [
    "print('# of persons who have no followers' ,sum(np.array(indegree_dist)==0),'and % is',\n",
    "        sum(np.array(indegree_dist)==0)*100/len(indegree_dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "outdegree_dist = list(dict(g.out_degree()).values())\n",
    "outdegree_dist.sort()\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(outdegree_dist)\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('# Of Followee')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.1 percentile value is 9.0\n",
      "99.2 percentile value is 10.0\n",
      "99.3 percentile value is 12.0\n",
      "99.4 percentile value is 16.0\n",
      "99.5 percentile value is 19.29000000000815\n",
      "99.6 percentile value is 25.0\n",
      "99.7 percentile value is 35.0\n",
      "99.8 percentile value is 53.0\n",
      "99.9 percentile value is 130.57400000002235\n",
      "100.0 percentile value is 16663.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(10,110,10):\n",
    "    print(99+(i/100),'percentile value is',np.percentile(outdegree_dist, 99+(i/100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.9 percentile value is 130.57400000002235\n",
      "99.91 percentile value is 150.11660000003758\n",
      "99.92 percentile value is 192.772799999977\n",
      "99.93 percentile value is 283.0\n",
      "99.94 percentile value is 367.7847999999649\n",
      "99.95 percentile value is 450.1450000000186\n",
      "99.96 percentile value is 992.9103999985382\n",
      "99.97 percentile value is 1957.8700000006938\n",
      "99.98 percentile value is 2699.630799999868\n",
      "99.99 percentile value is 5250.934399997117\n",
      "100.0 percentile value is 16663.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(900,1010,10):\n",
    "    print(99+(i/1000),'percentile value is',np.percentile(outdegree_dist, 99+(i/1000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of persons those are not following anyone are 132537 and % is 98.07167222867629\n"
     ]
    }
   ],
   "source": [
    "print('# of persons those are not following anyone are', sum(np.array(outdegree_dist)==0),'and % is',\n",
    "        sum(np.array(outdegree_dist)==0)*100/len(outdegree_dist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Negative Data preparing and Train-validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: \n",
      "Type: DiGraph\n",
      "Number of nodes: 135143\n",
      "Number of edges: 323932\n",
      "Average in degree:   2.3970\n",
      "Average out degree:   2.3970\n"
     ]
    }
   ],
   "source": [
    "print(nx.info(g))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate random missing edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import csv\n",
    "# getting the processed connection\n",
    "raw_connection = csv.reader(open('processed_train.csv', 'r'))\n",
    "\n",
    "exist_edges = {}\n",
    "\n",
    "for edge in raw_connection:\n",
    "    exist_edges[(edge[0], edge[1])] = 1\n",
    "\n",
    "# in order to prevent overfitting, we generate the same number of negative edge\n",
    "missing_edges = set()\n",
    "while(len(missing_edges) < 323932):\n",
    "    a = random.randint(1, 135143)\n",
    "    b = random.randint(1, 135143)\n",
    "    if a == b:\n",
    "        continue\n",
    "        \n",
    "    existance = exist_edges.get((a,b), -1)\n",
    "    if existance == -1:\n",
    "        try:\n",
    "            # if distance within 2, that means they share a common follower and very likely to be friends in real world or at least know each others\n",
    "            if nx.shortest_path_length(g, source=a, target=b) > 2:\n",
    "                missing_edges.add((a,b))\n",
    "            else:\n",
    "                continue\n",
    "        except:\n",
    "            missing_edges.add((a,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "323932"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(missing_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(missing_edges, open('data/missing_edges_final.p', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test Partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_data = pd.DataFrame(list(missing_edges), columns=['Source', 'Sink'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 765,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "323932"
      ]
     },
     "execution_count": 765,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 766,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "323932"
      ]
     },
     "execution_count": 766,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(negative_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#Trian test split \n",
    "#positive links and negative links seperatly because we need positive training data only for creating graph and for feature generation\n",
    "X_train_pos, X_test_pos, y_train_pos, y_test_pos  = train_test_split(data, np.ones(len(data)), test_size=0.2, random_state=90051)\n",
    "X_train_neg, X_test_neg, y_train_neg, y_test_neg  = train_test_split(negative_data, np.zeros(len(negative_data)), test_size=0.2, random_state=90051)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Number of nodes in the train data graph with edges 259145\n",
      "Number of nodes in the train data graph without edges 259145\n",
      "============================================================\n",
      "Number of nodes in the test data graph with edges 64787\n",
      "Number of nodes in the test data graph without edges 64787\n"
     ]
    }
   ],
   "source": [
    "# !TODO the data is not perfectly balanced, maybe fixed this later\n",
    "print('='*60)\n",
    "print(\"Number of nodes in the train data graph with edges\", y_train_pos.shape[0])\n",
    "print(\"Number of nodes in the train data graph without edges\", y_train_neg.shape[0])\n",
    "print('='*60)\n",
    "print(\"Number of nodes in the test data graph with edges\", y_test_pos.shape[0])\n",
    "print(\"Number of nodes in the test data graph without edges\", y_test_neg.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing header and saving\n",
    "X_train_pos.to_csv('data/train_pos.csv',header=False, index=False)\n",
    "X_test_pos.to_csv('data/test_pos.csv',header=False, index=False)\n",
    "X_train_neg.to_csv('data/train_neg.csv',header=False, index=False)\n",
    "X_test_neg.to_csv('data/test_neg.csv',header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = X_train_pos.append(X_train_neg, ignore_index=True)\n",
    "# y_train = np.concatenate((y_train_pos, y_train_neg))\n",
    "# X_test = X_test_pos.append(X_test_neg, ignore_index=True)\n",
    "# y_test = np.concatenate((y_test_pos, y_test_neg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: \n",
      "Type: DiGraph\n",
      "Number of nodes: 117429\n",
      "Number of edges: 259145\n",
      "Average in degree:   2.2068\n",
      "Average out degree:   2.2068\n"
     ]
    }
   ],
   "source": [
    "#generate train and test graph\n",
    "train_graph = nx.read_edgelist('data/train_pos.csv',delimiter=',',create_using=nx.DiGraph(),nodetype=int)\n",
    "print(nx.info(train_graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_followees(a, b, train_graph=g):\n",
    "    try:\n",
    "        if len(set(train_graph.successors(a))) == 0 or len(set(train_graph.successors(b))) == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            intersection = len(set(train_graph.successors(a)).intersection(set(train_graph.successors(b))))\n",
    "            union = len(set(train_graph.successors(a)).union(set(train_graph.successors(b))))\n",
    "            return intersection/union\n",
    "    except:\n",
    "        return 0\n",
    "    return sim\n",
    "\n",
    "def jaccard_followers(a,b, train_graph=g):\n",
    "    try:\n",
    "        if set(train_graph.predecessors(a)) == 0 or len(set(g.predecessors(b))) == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            intersection = len(set(train_graph.predecessors(a)).intersection(set(train_graph.predecessors(b))))\n",
    "            union = len(set(train_graph.predecessors(a)).union(set(train_graph.predecessors(b))))\n",
    "            return intersection/union\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "#for followees\n",
    "def cosine_followees(a, b, train_graph=g):\n",
    "    try:\n",
    "        if len(set(train_graph.successors(a))) == 0 or len(set(train_graph.successors(b))) == 0:\n",
    "            print(\"yes\")\n",
    "            return 0\n",
    "        else:\n",
    "            return (len(set(train_graph.successors(a)).intersection(set(train_graph.successors(b)))))/\\\n",
    "                                    (math.sqrt(len(set(train_graph.successors(a)))*len((set(train_graph.successors(b))))))\n",
    "    except:\n",
    "        return 0\n",
    "    \n",
    "def cosine_followers(a, b, train_graph=g):\n",
    "    try:\n",
    "        \n",
    "        if len(set(train_graph.predecessors(a))) == 0 or len(set(train_graph.predecessors(b))) == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            print(len(set(train_graph.predecessors(a)).intersection(set(train_graph.predecessors(b)))))\n",
    "            return (len(set(train_graph.predecessors(a)).intersection(set(train_graph.predecessors(b)))))/\\\n",
    "                                     (math.sqrt(len(set(train_graph.predecessors(a))))*(len(set(train_graph.predecessors(b)))))\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Source    4707515\n",
       "Sink      4277788\n",
       "Name: 3, dtype: int64"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_desire_train.iloc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asdf = 14\n",
    "cosine_followees(X_desire_train.iloc[asdf]['Source'], X_desire_train.iloc[asdf]['Sink'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def cosine_sim(a:set(), b:set()) -> float:\n",
    "    if (len(a) == 0 or len(b) == 0):\n",
    "        return 0\n",
    "    else:\n",
    "        return len(a.intersection(b))/(math.sqrt(len(a)*len(b)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_based_rec(a, b, graph=g):\n",
    "    try:\n",
    "        source_succ = set(g.successors(a))\n",
    "        other_users = set(g.predecessors(b))\n",
    "    except:\n",
    "        return 0\n",
    "    \n",
    "    # calculating the max similarity of all\n",
    "    max_sim = 0\n",
    "    for u in other_users:\n",
    "        temp = set(g.successors(u))\n",
    "        temp.remove(b)\n",
    "        curr_sim = cosine_sim(temp, source_succ)\n",
    "        if curr_sim > max_sim:\n",
    "            max_sim = curr_sim\n",
    "    return max_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def item_based_rec(a, b, graph=g):\n",
    "#     try:\n",
    "#         source_succ = set(g.successors(a))\n",
    "#     except:\n",
    "#         return 0\n",
    "    \n",
    "#     max_sim = 0\n",
    "#     for u in source_succ:\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min 8.362051873775734e-06\n",
      "max 0.00048134944932700383\n",
      "mean 8.515784005649403e-06\n"
     ]
    }
   ],
   "source": [
    "# caclulating the page rank for each node pair\n",
    "pr = nx.pagerank(train_graph, alpha=0.85)\n",
    "pickle.dump(pr,open('data/page_rank.p','wb'))\n",
    "# use the mean for all the data points which are part of the test dataset but are not in the training dataset\n",
    "mean_pr = float(sum(pr.values())) / len(pr)\n",
    "\n",
    "print('min',pr[min(pr, key=pr.get)])\n",
    "print('max',pr[max(pr, key=pr.get)])\n",
    "print('mean', mean_pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_shortest_path_length(a, b, train_graph=g):\n",
    "    p = 99\n",
    "    try:\n",
    "        # if the edge already exist, we first remove the edge which let our model better understand the graph\n",
    "        if train_graph.has_edge(a,b):\n",
    "            train_graph.remove_edge(a,b)\n",
    "            p= nx.shortest_path_length(train_graph,source=a,target=b)\n",
    "            train_graph.add_edge(a,b)\n",
    "        else:\n",
    "            p= nx.shortest_path_length(train_graph,source=a,target=b)\n",
    "        return p\n",
    "    except:\n",
    "        return 99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #getting weakly connected edges from graph \n",
    "# def belongs_to_same_wcc(a, b, train_graph=train_graph):\n",
    "#     wcc = list(nx.weakly_connected_components(train_graph))\n",
    "#     index = []\n",
    "#     # they must belongs are there is a path\n",
    "#     if train_graph.has_edge(b,a):\n",
    "#         return 1\n",
    "    \n",
    "#     if train_graph.has_edge(a,b):\n",
    "#         for i in wcc:\n",
    "#             if a in i:\n",
    "#                 index = i\n",
    "#                 break\n",
    "#         if b in index:\n",
    "#             train_graph.remove_edge(a,b)\n",
    "#             if compute_shortest_path_length(a,b) == -1:\n",
    "#                 train_graph.add_edge(a,b)\n",
    "#                 return 0\n",
    "#             else:\n",
    "#                 train_graph.add_edge(a,b)\n",
    "#                 return 1\n",
    "#         else:\n",
    "#             return 0\n",
    "#     else:\n",
    "#         for i in wcc:\n",
    "#             if a in i:\n",
    "#                 index = i\n",
    "#                 break\n",
    "#         if(b in index):\n",
    "#             return 1\n",
    "#         else:\n",
    "#             return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adar Index\n",
    "def calc_adar_in(a, b, train_graph=g):\n",
    "    sum = 0\n",
    "    try:\n",
    "        n=list(set(train_graph.successors(a)).intersection(set(train_graph.successors(b))))\n",
    "        if len(n)!=0:\n",
    "            for i in n:\n",
    "                sum=sum+(1/np.log10(len(list(train_graph.predecessors(i)))))\n",
    "            return sum\n",
    "        else:\n",
    "            return 0\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min 0.0028783732537377513\n",
      "max 0.008538168742251223\n",
      "mean 0.0029169324653439484\n"
     ]
    }
   ],
   "source": [
    "#Katz centrality of a node is a measure of centrality in a network\n",
    "katz = nx.katz.katz_centrality(train_graph,alpha=0.005,beta=1)\n",
    "pickle.dump(katz, open('data/katz.p','wb'))\n",
    "mean_katz = float(sum(katz.values())) / len(katz)\n",
    "\n",
    "print('min',katz[min(katz, key=katz.get)])\n",
    "print('max',katz[max(katz, key=katz.get)])\n",
    "print('mean', mean_katz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min 0.0\n",
      "max 0.07111477112379715\n",
      "mean 8.515784005654462e-06\n"
     ]
    }
   ],
   "source": [
    "#HITS\n",
    "hits = nx.hits(train_graph, max_iter=100, tol=1e-08, nstart=None, normalized=True)\n",
    "pickle.dump(hits, open('data/hits.p','wb'))\n",
    "mean_hits = float(sum(hits[0].values())) / len(hits[0])\n",
    "\n",
    "print('min',hits[0][min(hits[0], key=hits[0].get)])\n",
    "print('max',hits[0][max(hits[0], key=hits[0].get)])\n",
    "print('mean', mean_hits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def common_neighbours(a, b, graph=g):\n",
    "    try:\n",
    "        a_set = set(graph.successors(a)).union(graph.predecessors(a))\n",
    "        b_set = set(graph.successors(b)).union(graph.predecessors(b))\n",
    "    except:\n",
    "        return 0\n",
    "    \n",
    "    return len(a_set.intersection(b_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preferencial_attchment(a, b, graph=g):\n",
    "    try:\n",
    "        a_set = set(graph.successors(a)).union(graph.predecessors(a))\n",
    "        b_set = set(graph.successors(b)).union(graph.predecessors(b))\n",
    "    except:\n",
    "        return 0\n",
    "    \n",
    "    return len(a_set)*len(b_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try to reduce the sample size, TODO, might fix this later\n",
    "desire_train = 100000\n",
    "desire_test = 50000\n",
    "d_train_pos = sorted(random.sample(range(len(X_train_pos)), int(desire_train/2)))\n",
    "d_test_pos = sorted(random.sample(range(len(X_test_pos)), int(desire_test/2)))\n",
    "d_train_neg = sorted(random.sample(range(len(X_train_neg)), int(desire_train/2)))\n",
    "d_test_neg = sorted(random.sample(range(len(X_test_neg)), int(desire_test/2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shrink_df(df, label, num_list):\n",
    "    if num_list == -1:\n",
    "        return df, label\n",
    "    desire_dict = {\"Source\":[], \"Sink\":[]}\n",
    "    lb = []\n",
    "    for i in num_list:\n",
    "        desire_dict['Source'].append(df.iloc[i]['Source'])\n",
    "        desire_dict['Sink'].append(df.iloc[i]['Sink'])\n",
    "        lb.append(label[i])\n",
    "    return pd.DataFrame(data=desire_dict), np.array(lb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_desire_train_pos, y_desire_train_pos = shrink_df(X_train_pos, y_train_pos, d_train_pos)\n",
    "X_desire_train_neg, y_desire_train_neg = shrink_df(X_train_neg, y_train_neg, d_train_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_desire_test_pos, y_desire_test_pos = shrink_df(X_test_pos, y_test_pos, d_test_pos)\n",
    "X_desire_test_neg, y_desire_test_neg = shrink_df(X_test_neg, y_test_neg, d_test_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_desire_train = X_desire_train_pos.append(X_desire_train_neg, ignore_index=True)\n",
    "X_desire_test = X_desire_test_pos.append(X_desire_test_neg, ignore_index=True)\n",
    "\n",
    "y_desire_train = np.append(y_desire_train_pos, y_desire_train_neg)\n",
    "y_desire_test = np.append(y_desire_test_pos, y_desire_test_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000 100000 50000 50000\n"
     ]
    }
   ],
   "source": [
    "print(len(X_desire_train), len(y_desire_train), len(X_desire_test), len(y_desire_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split distribution data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "link = [[i[1], i[2]] for i in data]\n",
    "label = [i[3] for i in data]\n",
    "X_desire_train, X_desire_test, y_desire_train, y_desire_test = train_test_split(link, label, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16000 16000 4000 4000\n"
     ]
    }
   ],
   "source": [
    "print(len(X_desire_train), len(y_desire_train), len(X_desire_test), len(y_desire_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_desire_train = pd.DataFrame(X_desire_train, columns=['Source', 'Sink'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_desire_test = pd.DataFrame(X_desire_test, columns=['Source', 'Sink'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_features = pd.DataFrame()\n",
    "X_test_features = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#mapping jaccrd followers to train and test data\n",
    "X_train_features['jaccard_followers'] = X_desire_train.apply(lambda row:jaccard_followers(row['Source'], row['Sink']), axis=1)\n",
    "X_test_features['jaccard_followers'] = X_desire_test.apply(lambda row:jaccard_followers(row['Source'], row['Sink']),axis=1)\n",
    "\n",
    "#mapping jaccrd followees to train and test data\n",
    "X_train_features['jaccard_followees'] = X_desire_train.apply(lambda row:jaccard_followees(row['Source'], row['Sink']), axis=1)\n",
    "X_test_features['jaccard_followees'] = X_desire_test.apply(lambda row:jaccard_followees(row['Source'], row['Sink']), axis=1)\n",
    "\n",
    "# # #mapping jaccrd followers to train and test data\n",
    "# X_train_features['cosine_followers'] = X_desire_train.apply(lambda row:cosine_followers(row['Source'], row['Sink']), axis=1)\n",
    "# X_test_features['cosine_followers'] = X_desire_test.apply(lambda row:cosine_followers(row['Source'], row['Sink']), axis=1)\n",
    "\n",
    "# #mapping jaccrd followees to train and test data\n",
    "# X_train_features['cosine_followees'] = X_desire_train.apply(lambda row:cosine_followees(row['Source'], row['Sink']), axis=1)\n",
    "# X_test_features['cosine_followees'] = X_desire_test.apply(lambda row:cosine_followees(row['Source'], row['Sink']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-347-793b96eba9bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mX_train_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'user_base_rec'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_desire_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0muser_based_rec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Source'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Sink'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_test_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'user_base_rec'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_desire_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0muser_based_rec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Source'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Sink'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, broadcast, raw, reduce, result_type, args, **kwds)\u001b[0m\n\u001b[1;32m   6485\u001b[0m                          \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6486\u001b[0m                          kwds=kwds)\n\u001b[0;32m-> 6487\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6489\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapplymap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_empty_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    249\u001b[0m                                           \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m                                           \u001b[0mdummy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdummy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m                                           labels=labels)\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor_sliced\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/reduction.pyx\u001b[0m in \u001b[0;36mpandas._libs.reduction.reduce\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/reduction.pyx\u001b[0m in \u001b[0;36mpandas._libs.reduction.Reducer.get_result\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-347-793b96eba9bd>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mX_train_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'user_base_rec'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_desire_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0muser_based_rec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Source'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Sink'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_test_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'user_base_rec'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_desire_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0muser_based_rec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Source'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Sink'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-345-1479e2343a0f>\u001b[0m in \u001b[0;36muser_based_rec\u001b[0;34m(a, b, graph)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mmax_sim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mu\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mother_users\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuccessors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mtemp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mcurr_sim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcosine_sim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_succ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X_train_features['user_base_rec'] = X_desire_train.apply(lambda row: user_based_rec(row['Source'], row['Sink']), axis=1)\n",
    "X_test_features['user_base_rec'] = X_desire_test.apply(lambda row: user_based_rec(row['Source'], row['Sink']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_features_stage1(df_final):\n",
    "    #calculating # of followers followees for source and destination\n",
    "    #calculating intersection of followers and followees for source and destination\n",
    "    num_followers_s=[]\n",
    "    num_followees_s=[]\n",
    "    num_followers_d=[]\n",
    "    num_followees_d=[]\n",
    "    inter_followers=[]\n",
    "    inter_followees=[]\n",
    "    \n",
    "    for i, row in df_final.iterrows():\n",
    "        try:\n",
    "            s1 = set(g.predecessors(row['Source']))\n",
    "            s2 = set(g.successors(row['Sink']))\n",
    "        except:\n",
    "            s1 = set()\n",
    "            s2 = set()\n",
    "        try:\n",
    "            d1 = set(g.predecessors(row['Source']))\n",
    "            d2 = set(g.successors(row['Sink']))\n",
    "        except:\n",
    "            d1 = set()\n",
    "            d2 = set()\n",
    "        num_followers_s.append(len(s1))\n",
    "        num_followees_s.append(len(s2))\n",
    "\n",
    "        num_followers_d.append(len(d1))\n",
    "        num_followees_d.append(len(d2))\n",
    "\n",
    "        inter_followers.append(len(s1.intersection(d1)))\n",
    "        inter_followees.append(len(s2.intersection(d2)))\n",
    "    \n",
    "    return num_followers_s, num_followers_d, num_followees_s, num_followees_d, inter_followers, inter_followees\n",
    "\n",
    "X_train_features['num_followers_s'], X_train_features['num_followers_d'], \\\n",
    "X_train_features['num_followees_s'], X_train_features['num_followees_d'], \\\n",
    "X_train_features['inter_followers'], X_train_features['inter_followees'] = compute_features_stage1(X_desire_train)\n",
    "\n",
    "X_test_features['num_followers_s'], X_test_features['num_followers_d'], \\\n",
    "X_test_features['num_followees_s'], X_test_features['num_followees_d'], \\\n",
    "X_test_features['inter_followers'], X_test_features['inter_followees'] = compute_features_stage1(X_desire_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping adar index\n",
    "X_train_features['adar_index'] = X_desire_train.apply(lambda row: calc_adar_in(row['Source'], row['Sink']), axis=1)\n",
    "X_test_features['adar_index'] = X_desire_test.apply(lambda row: calc_adar_in(row['Source'], row['Sink']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_features['shortest_path'] = X_desire_train.apply(lambda row: compute_shortest_path_length(row['Source'], row['Sink']), axis=1)\n",
    "X_test_features['shortest_path'] = X_desire_test.apply(lambda row: compute_shortest_path_length(row['Source'], row['Sink']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 918,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_features['page_rank_s'] = X_desire_train['Source'].apply(lambda x:np.sqrt(pr.get(x, mean_pr)))\n",
    "X_train_features['page_rank_d'] = X_desire_train['Sink'].apply(lambda x:np.sqrt(pr.get(x, mean_pr)))\n",
    "X_test_features['page_rank_s'] = X_desire_test['Source'].apply(lambda x:np.sqrt(pr.get(x, mean_pr)))\n",
    "X_test_features['page_rank_d'] = X_desire_test['Sink'].apply(lambda x:np.sqrt(pr.get(x, mean_pr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Katz centrality score for source and destination in Train and test\n",
    "#if anything not there in train graph then adding mean katz score\n",
    "X_train_features['katz_s'] = X_desire_train['Source'].apply(lambda x: katz.get(x,mean_katz))\n",
    "X_train_features['katz_d'] = X_desire_train['Sink'].apply(lambda x: katz.get(x,mean_katz))\n",
    "X_test_features['katz_s'] = X_desire_test['Source'].apply(lambda x: katz.get(x,mean_katz))\n",
    "X_test_features['katz_d'] = X_desire_test['Sink'].apply(lambda x: katz.get(x,mean_katz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hits algorithm score for source and destination in Train and test\n",
    "#if anything not there in train graph then adding 0\n",
    "X_train_features['hubs_s'] = X_desire_train['Source'].apply(lambda x: hits[0].get(x,0))\n",
    "X_train_features['hubs_d'] = X_desire_train['Sink'].apply(lambda x: hits[0].get(x,0))\n",
    "X_test_features['hubs_s'] = X_desire_test['Source'].apply(lambda x: hits[0].get(x,0))\n",
    "X_test_features['hubs_d'] = X_desire_test['Sink'].apply(lambda x: hits[0].get(x,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_features['authorities_s'] = X_desire_train['Source'].apply(lambda x: hits[1].get(x,0))\n",
    "X_train_features['authorities_d'] = X_desire_train['Sink'].apply(lambda x: hits[1].get(x,0))\n",
    "X_test_features['authorities_s'] = X_desire_test['Source'].apply(lambda x: hits[1].get(x,0))\n",
    "X_test_features['authorities_d'] = X_desire_test['Sink'].apply(lambda x: hits[1].get(x,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate common neighbours\n",
    "X_train_features['c_nei'] = X_desire_train.apply(lambda row: common_neighbours(row['Source'], row['Sink']), axis=1)\n",
    "X_test_features['c_nei'] = X_desire_test.apply(lambda row: common_neighbours(row['Source'], row['Sink']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_features['prefer'] = X_desire_train.apply(lambda row: preferencial_attchment(row['Source'], row['Sink']), axis=1)\n",
    "X_test_features['prefer'] = X_desire_test.apply(lambda row: preferencial_attchment(row['Source'], row['Sink']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(X_train_features, open('data/X_train_features.p','wb'))\n",
    "pickle.dump(X_test_features, open('data/X_test_features.p','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 914,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_features = pickle.load(open('data/X_train_features.p','rb'))\n",
    "X_test_features = pickle.load(open('data/X_test_features.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_features.drop([\"shortest_path\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 920,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "scaler = Normalizer(norm='l1')\n",
    "\n",
    "scaler.fit(X_train_features)\n",
    "X_train_features = scaler.transform(X_train_features)\n",
    "\n",
    "scaler.fit(X_test_features)\n",
    "X_test_features = scaler.transform(X_test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jaccard_followers</th>\n",
       "      <th>jaccard_followees</th>\n",
       "      <th>cosine_followers</th>\n",
       "      <th>cosine_followees</th>\n",
       "      <th>num_followers_s</th>\n",
       "      <th>num_followers_d</th>\n",
       "      <th>num_followees_s</th>\n",
       "      <th>num_followees_d</th>\n",
       "      <th>inter_followers</th>\n",
       "      <th>inter_followees</th>\n",
       "      <th>adar_index</th>\n",
       "      <th>shortest_path</th>\n",
       "      <th>c_nei</th>\n",
       "      <th>prefer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>16000.000000</td>\n",
       "      <td>16000.000000</td>\n",
       "      <td>16000.000000</td>\n",
       "      <td>16000.000000</td>\n",
       "      <td>16000.00000</td>\n",
       "      <td>16000.00000</td>\n",
       "      <td>16000.000000</td>\n",
       "      <td>16000.000000</td>\n",
       "      <td>16000.00000</td>\n",
       "      <td>16000.000000</td>\n",
       "      <td>16000.000000</td>\n",
       "      <td>16000.000000</td>\n",
       "      <td>16000.000000</td>\n",
       "      <td>1.600000e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.030465</td>\n",
       "      <td>0.006258</td>\n",
       "      <td>0.012653</td>\n",
       "      <td>0.013610</td>\n",
       "      <td>91.49025</td>\n",
       "      <td>91.49025</td>\n",
       "      <td>1725.423000</td>\n",
       "      <td>1725.423000</td>\n",
       "      <td>91.49025</td>\n",
       "      <td>1725.423000</td>\n",
       "      <td>2.314580</td>\n",
       "      <td>8.810375</td>\n",
       "      <td>10.879563</td>\n",
       "      <td>8.845300e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.062404</td>\n",
       "      <td>0.027635</td>\n",
       "      <td>0.029386</td>\n",
       "      <td>0.051245</td>\n",
       "      <td>191.71842</td>\n",
       "      <td>191.71842</td>\n",
       "      <td>25227.490272</td>\n",
       "      <td>25227.490272</td>\n",
       "      <td>191.71842</td>\n",
       "      <td>25227.490272</td>\n",
       "      <td>46.312512</td>\n",
       "      <td>23.812845</td>\n",
       "      <td>88.529500</td>\n",
       "      <td>2.699787e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.00000</td>\n",
       "      <td>12.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.200000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.003735</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001058</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>35.00000</td>\n",
       "      <td>35.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>35.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.200000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.032967</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012033</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>92.00000</td>\n",
       "      <td>92.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>92.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.806000e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.683763</td>\n",
       "      <td>4841.00000</td>\n",
       "      <td>4841.00000</td>\n",
       "      <td>759391.000000</td>\n",
       "      <td>759391.000000</td>\n",
       "      <td>4841.00000</td>\n",
       "      <td>759391.000000</td>\n",
       "      <td>5368.793317</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>9644.000000</td>\n",
       "      <td>2.840350e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       jaccard_followers  jaccard_followees  cosine_followers  \\\n",
       "count       16000.000000       16000.000000      16000.000000   \n",
       "mean            0.030465           0.006258          0.012653   \n",
       "std             0.062404           0.027635          0.029386   \n",
       "min             0.000000           0.000000          0.000000   \n",
       "25%             0.000000           0.000000          0.000000   \n",
       "50%             0.003735           0.000000          0.001058   \n",
       "75%             0.032967           0.000000          0.012033   \n",
       "max             0.800000           0.500000          0.707107   \n",
       "\n",
       "       cosine_followees  num_followers_s  num_followers_d  num_followees_s  \\\n",
       "count      16000.000000      16000.00000      16000.00000     16000.000000   \n",
       "mean           0.013610         91.49025         91.49025      1725.423000   \n",
       "std            0.051245        191.71842        191.71842     25227.490272   \n",
       "min            0.000000          0.00000          0.00000         0.000000   \n",
       "25%            0.000000         12.00000         12.00000         0.000000   \n",
       "50%            0.000000         35.00000         35.00000         0.000000   \n",
       "75%            0.000000         92.00000         92.00000         0.000000   \n",
       "max            0.683763       4841.00000       4841.00000    759391.000000   \n",
       "\n",
       "       num_followees_d  inter_followers  inter_followees    adar_index  \\\n",
       "count     16000.000000      16000.00000     16000.000000  16000.000000   \n",
       "mean       1725.423000         91.49025      1725.423000      2.314580   \n",
       "std       25227.490272        191.71842     25227.490272     46.312512   \n",
       "min           0.000000          0.00000         0.000000      0.000000   \n",
       "25%           0.000000         12.00000         0.000000      0.000000   \n",
       "50%           0.000000         35.00000         0.000000      0.000000   \n",
       "75%           0.000000         92.00000         0.000000      0.000000   \n",
       "max      759391.000000       4841.00000    759391.000000   5368.793317   \n",
       "\n",
       "       shortest_path         c_nei        prefer  \n",
       "count   16000.000000  16000.000000  1.600000e+04  \n",
       "mean        8.810375     10.879563  8.845300e+05  \n",
       "std        23.812845     88.529500  2.699787e+07  \n",
       "min         2.000000      0.000000  0.000000e+00  \n",
       "25%         2.000000      0.000000  9.200000e+02  \n",
       "50%         2.000000      1.000000  7.200000e+03  \n",
       "75%         3.000000      7.000000  4.806000e+04  \n",
       "max        99.000000   9644.000000  2.840350e+09  "
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_features.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 921,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 1.74800551e-05, 8.23831024e-06],\n",
       "       [1.54408709e-02, 1.73492932e-04, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 1.89413210e-05, 1.11723070e-05],\n",
       "       [5.22159867e-03, 4.07937396e-05, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 1.55087695e-05, 7.55194136e-06],\n",
       "       ...,\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 5.02238595e-01, 4.97761405e-01],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 5.02263071e-01, 4.97736929e-01],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 5.00000000e-01, 5.00000000e-01]])"
      ]
     },
     "execution_count": 921,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xinyaoniu/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=90051, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr_clf = LogisticRegression(random_state=90051)\n",
    "lr_clf.fit(X_train_features, y_desire_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.53775"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_clf.score(X_test_features, y_desire_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xinyaoniu/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=3, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,\n",
       "                       oob_score=False, random_state=90051, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_clf = RandomForestClassifier(max_depth=3, random_state=90051, n_jobs=-1)\n",
    "rf_clf.fit(X_train_features, y_desire_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xinyaoniu/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-237-97d779dbaac6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mrf_grid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mrf_grid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_desire_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrf_grid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X_test' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "base = RandomForestClassifier(n_estimators=100)\n",
    "parameters = {\n",
    "    \"max_depth\":[5,7,9,11,13],\n",
    "    \"min_samples_leaf\":[1,3,5],\n",
    "    \"min_samples_split\":[2,4,6,8,10],\n",
    "    \"max_features\":[\"sqrt\", \"log2\"]\n",
    "}\n",
    "\n",
    "rf_grid = GridSearchCV(base, parameters, n_jobs=-1)\n",
    "rf_grid.fit(X_train_features, y_desire_train)\n",
    "print(rf_grid.score(X_test_features, y_desire_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.79"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_clf.score(X_test_features, y_desire_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.60063231, 0.39936769],\n",
       "       [0.37558417, 0.62441583],\n",
       "       [0.53451119, 0.46548881],\n",
       "       ...,\n",
       "       [0.31787412, 0.68212588],\n",
       "       [0.51343121, 0.48656879],\n",
       "       [0.73528877, 0.26471123]])"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_clf.predict_proba(X_test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "def evaluate_roc_auc(clf, features, labels):\n",
    "    predicted = clf.predict_proba(features)\n",
    "\n",
    "    # check which class corresponds to positive links\n",
    "    positive_column = list(clf.classes_).index(1)\n",
    "    return roc_auc_score(labels, predicted[:, positive_column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8421342128712425"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_roc_auc(rf_clf, X_test_features, y_desire_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 894,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.05, max_delta_step=0, max_depth=2,\n",
       "              min_child_weight=1, missing=None, monotone_constraints='()',\n",
       "              n_estimators=500, n_jobs=5, nthread=5, num_parallel_tree=1,\n",
       "              objective='binary:logistic', random_state=0, reg_alpha=0,\n",
       "              reg_lambda=1.0, scale_pos_weight=1, seed=0, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 894,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "#Building Model using best parameter\n",
    "tuned_params = {'max_depth': [1, 2, 3, 4, 5], 'learning_rate': [0.01, 0.05, 0.1], \n",
    "                'n_estimators': [100, 200, 300, 400, 500], \n",
    "                'reg_lambda': [0.001, 0.1, 1.0, 10.0, 100.0]}\n",
    "# clf = GridSearchCV(\n",
    "#     xgb.XGBClassifier(base_score=0.5, \n",
    "#                   booster='gbtree', \n",
    "#                   colsample_bylevel=1, \n",
    "#                   colsample_bytree=1, \n",
    "#                   gamma=0, \n",
    "#                   learning_rate=0.05, \n",
    "#                   max_delta_step=0,\n",
    "#                   max_depth=4, \n",
    "#                   min_child_weight=1, \n",
    "#                   missing=None, \n",
    "#                   n_estimators=500,\n",
    "#                   n_jobs=1, \n",
    "#                   nthread=None,\n",
    "#                   objective='binary:logistic', \n",
    "#                   random_state=0,\n",
    "#                   reg_alpha=0, \n",
    "#                   reg_lambda=1.0, \n",
    "#                   scale_pos_weight=1, \n",
    "#                   seed=None,\n",
    "#                   silent=False, \n",
    "#                   subsample=1), \n",
    "#     tuned_params, \n",
    "#     scoring = 'roc_auc', \n",
    "#     n_jobs=-1\n",
    "# )\n",
    "\n",
    "xgb_clf = xgb.XGBClassifier(base_score=0.5, \n",
    "                  booster='gbtree',\n",
    "                  colsample_bylevel=1, \n",
    "                  colsample_bytree=1,\n",
    "                  gamma=0,\n",
    "                  learning_rate=0.05,\n",
    "                  max_delta_step=0,\n",
    "                  max_depth=2,\n",
    "                  min_child_weight=1,\n",
    "                  missing=None,\n",
    "                  n_estimators=500,\n",
    "                  n_jobs=5,\n",
    "                  nthread=None,\n",
    "                  objective='binary:logistic',\n",
    "                  random_state=0,\n",
    "                  reg_alpha=0,\n",
    "                  reg_lambda=1.0,\n",
    "                  scale_pos_weight=1,\n",
    "                  seed=None,\n",
    "                  subsample=1)\n",
    "\n",
    "xgb_clf.fit(X_train_features, y_desire_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 895,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9513"
      ]
     },
     "execution_count": 895,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_clf.score(X_test_features, y_desire_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "voting = VotingClassifier(estimators=[('lr', lr_clf), ('xgb', clf), ('rf', rf_clf)], voting='soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xinyaoniu/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lr',\n",
       "                              LogisticRegression(C=1.0, class_weight=None,\n",
       "                                                 dual=False, fit_intercept=True,\n",
       "                                                 intercept_scaling=1,\n",
       "                                                 l1_ratio=None, max_iter=100,\n",
       "                                                 multi_class='warn',\n",
       "                                                 n_jobs=None, penalty='l2',\n",
       "                                                 random_state=90051,\n",
       "                                                 solver='warn', tol=0.0001,\n",
       "                                                 verbose=0, warm_start=False)),\n",
       "                             ('xgb',\n",
       "                              XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                            colsample_bylevel=1,\n",
       "                                            colsa...\n",
       "                                                     class_weight=None,\n",
       "                                                     criterion='gini',\n",
       "                                                     max_depth=3,\n",
       "                                                     max_features='auto',\n",
       "                                                     max_leaf_nodes=None,\n",
       "                                                     min_impurity_decrease=0.0,\n",
       "                                                     min_impurity_split=None,\n",
       "                                                     min_samples_leaf=1,\n",
       "                                                     min_samples_split=2,\n",
       "                                                     min_weight_fraction_leaf=0.0,\n",
       "                                                     n_estimators=10, n_jobs=-1,\n",
       "                                                     oob_score=False,\n",
       "                                                     random_state=90051,\n",
       "                                                     verbose=0,\n",
       "                                                     warm_start=False))],\n",
       "                 flatten_transform=True, n_jobs=None, voting='soft',\n",
       "                 weights=None)"
      ]
     },
     "execution_count": 532,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting.fit(X_train_features, y_desire_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.80916"
      ]
     },
     "execution_count": 533,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting.score(X_test_features, y_desire_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 749,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_clf = MLPClassifier(\n",
    "    max_iter=200,\n",
    "    early_stopping=True,\n",
    "    shuffle=True,\n",
    "    solver='adam',\n",
    "    activation='relu',\n",
    ").fit(X_train_features, y_desire_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 751,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8428827031999999"
      ]
     },
     "execution_count": 751,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_roc_auc(mlp_clf, X_test_features, y_desire_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [],
   "source": [
    "visual_train = X_train_features.copy()\n",
    "visual_train['label'] = y_desire_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shortest_path</th>\n",
       "      <th>c_nei</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>30249.000000</td>\n",
       "      <td>30249.000000</td>\n",
       "      <td>30249.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.306886</td>\n",
       "      <td>4.481470</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.536001</td>\n",
       "      <td>47.755137</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>4334.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       shortest_path         c_nei    label\n",
       "count   30249.000000  30249.000000  30249.0\n",
       "mean        2.306886      4.481470      1.0\n",
       "std         0.536001     47.755137      0.0\n",
       "min         2.000000      0.000000      1.0\n",
       "25%         2.000000      1.000000      1.0\n",
       "50%         2.000000      2.000000      1.0\n",
       "75%         3.000000      4.000000      1.0\n",
       "max         8.000000   4334.000000      1.0"
      ]
     },
     "execution_count": 579,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visual_train[(visual_train['shortest_path'] != 99) & (visual_train['label'] == 1)].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shortest_path</th>\n",
       "      <th>c_nei</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50000.0</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>99.0</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006324</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>99.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>99.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>99.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>99.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>99.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       shortest_path         c_nei    label\n",
       "count        50000.0  50000.000000  50000.0\n",
       "mean            99.0      0.000040      0.0\n",
       "std              0.0      0.006324      0.0\n",
       "min             99.0      0.000000      0.0\n",
       "25%             99.0      0.000000      0.0\n",
       "50%             99.0      0.000000      0.0\n",
       "75%             99.0      0.000000      0.0\n",
       "max             99.0      1.000000      0.0"
      ]
     },
     "execution_count": 581,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visual_train[(visual_train['shortest_path'] == 99) & (visual_train['label'] == 0)].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genereate Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Sink</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3563811</td>\n",
       "      <td>3600160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2052043</td>\n",
       "      <td>1401960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4517994</td>\n",
       "      <td>1690636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1660006</td>\n",
       "      <td>4349447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>581111</td>\n",
       "      <td>1882617</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Source     Sink\n",
       "0  3563811  3600160\n",
       "1  2052043  1401960\n",
       "2  4517994  1690636\n",
       "3  1660006  4349447\n",
       "4   581111  1882617"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sub = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: \n",
      "Type: DiGraph\n",
      "Number of nodes: 4842581\n",
      "Number of edges: 23888876\n",
      "Average in degree:   4.9331\n",
      "Average out degree:   4.9331\n"
     ]
    }
   ],
   "source": [
    "origial_graph = nx.read_edgelist('processed_train.csv',delimiter=',',create_using=nx.DiGraph(),nodetype=int)\n",
    "print(nx.info(origial_graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 811,
   "metadata": {},
   "outputs": [],
   "source": [
    "# caclulating the page rank for each node pair\n",
    "pr_original = nx.pagerank(origial_graph, alpha=0.85)\n",
    "pickle.dump(pr,open('data/page_rank_original.p','wb'))\n",
    "# use the mean for all the data points which are part of the test dataset but are not in the training dataset\n",
    "mean_pr_original = float(sum(pr.values())) / len(pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "581111"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_data['Source'][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.shortest_path_length(g,source=sub_data['Source'][100],target=sub_data['Sink'][100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mapping jaccrd followers to train and test data\n",
    "X_sub['jaccard_followers'] = sub_data.apply(\n",
    "    lambda row:jaccard_followers(row['Source'], row['Sink'], train_graph=g), \n",
    "    axis=1)\n",
    "\n",
    "#mapping jaccrd followees to train and test data\n",
    "X_sub['jaccard_followees'] = sub_data.apply(\n",
    "    lambda row:jaccard_followees(row['Source'], row['Sink'], train_graph=g), \n",
    "    axis=1)\n",
    "\n",
    "# #mapping jaccrd followers to train and test data\n",
    "# X_sub['cosine_followers'] = sub_data.apply(\n",
    "#     lambda row:cosine_followers(row['Source'], row['Sink'], train_graph=g),\n",
    "#     axis=1)\n",
    "\n",
    "# #mapping jaccrd followees to train and test data\n",
    "# X_sub['cosine_followees'] = sub_data.apply(\n",
    "#     lambda row:cosine_followees(row['Source'], row['Sink'], train_graph=g), \n",
    "#     axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sub['user_base_rec'] = sub_data.apply(lambda row: user_based_rec(row['Source'], row['Sink']), axis=1)\n",
    "X_sub['user_base_rec'] = sub_data.apply(lambda row: user_based_rec(row['Source'], row['Sink']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sub['num_followers_s'], X_sub['num_followers_d'], \\\n",
    "X_sub['num_followees_s'], X_sub['num_followees_d'], \\\n",
    "X_sub['inter_followers'], X_sub['inter_followees'] = compute_features_stage1(sub_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping adar index\n",
    "X_sub['adar_index'] = sub_data.apply(lambda row: calc_adar_in(row['Source'], row['Sink']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping wcc\n",
    "X_sub['same_wcc'] = sub_data.apply(lambda row: belongs_to_same_wcc(row['Source'], row['Sink'], train_graph=origial_graph), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sub['shortest_path'] = sub_data.apply(lambda row: compute_shortest_path_length(row['Source'], row['Sink']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 933,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sub['page_rank_s'] = sub_data['Source'].apply(lambda x:np.sqrt(pr_original.get(x, mean_pr_original)))\n",
    "X_sub['page_rank_d'] = sub_data['Sink'].apply(lambda x:np.sqrt(pr_original.get(x, mean_pr_original)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sub['katz_s'] = sub_data['Source'].apply(lambda x: katz.get(x,mean_katz))\n",
    "X_sub['katz_d'] = sub_data['Sink'].apply(lambda x: katz.get(x,mean_katz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sub['hubs_s'] = sub_data['Source'].apply(lambda x: hits[0].get(x,0))\n",
    "X_sub['hubs_d'] = sub_data['Sink'].apply(lambda x: hits[0].get(x,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sub['authorities_s'] = sub_data['Source'].apply(lambda x: hits[1].get(x,0))\n",
    "X_sub['authorities_d'] = sub_data['Sink'].apply(lambda x: hits[1].get(x,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate common neighbours\n",
    "X_sub['c_nei'] = sub_data.apply(lambda row: common_neighbours(row['Source'], row['Sink']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sub['prefer'] = sub_data.apply(lambda row: preferencial_attchment(row['Source'], row['Sink']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 14)"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_sub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jaccard_followers</th>\n",
       "      <th>jaccard_followees</th>\n",
       "      <th>cosine_followers</th>\n",
       "      <th>cosine_followees</th>\n",
       "      <th>num_followers_s</th>\n",
       "      <th>num_followers_d</th>\n",
       "      <th>num_followees_s</th>\n",
       "      <th>num_followees_d</th>\n",
       "      <th>inter_followers</th>\n",
       "      <th>inter_followees</th>\n",
       "      <th>adar_index</th>\n",
       "      <th>shortest_path</th>\n",
       "      <th>c_nei</th>\n",
       "      <th>prefer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.00000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2.000000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.033092</td>\n",
       "      <td>0.006961</td>\n",
       "      <td>0.017098</td>\n",
       "      <td>0.014244</td>\n",
       "      <td>90.873000</td>\n",
       "      <td>90.873000</td>\n",
       "      <td>1790.070500</td>\n",
       "      <td>1790.070500</td>\n",
       "      <td>90.873000</td>\n",
       "      <td>1790.070500</td>\n",
       "      <td>2.876330</td>\n",
       "      <td>4.12650</td>\n",
       "      <td>11.373000</td>\n",
       "      <td>9.659938e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.071817</td>\n",
       "      <td>0.032181</td>\n",
       "      <td>0.049803</td>\n",
       "      <td>0.055368</td>\n",
       "      <td>166.968887</td>\n",
       "      <td>166.968887</td>\n",
       "      <td>27168.890833</td>\n",
       "      <td>27168.890833</td>\n",
       "      <td>166.968887</td>\n",
       "      <td>27168.890833</td>\n",
       "      <td>51.706446</td>\n",
       "      <td>12.30834</td>\n",
       "      <td>100.078298</td>\n",
       "      <td>1.717118e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.265000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.004759</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001418</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.997000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.034830</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013931</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>5.273600e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.722897</td>\n",
       "      <td>2021.000000</td>\n",
       "      <td>2021.000000</td>\n",
       "      <td>759391.000000</td>\n",
       "      <td>759391.000000</td>\n",
       "      <td>2021.000000</td>\n",
       "      <td>759391.000000</td>\n",
       "      <td>2287.773260</td>\n",
       "      <td>99.00000</td>\n",
       "      <td>4361.000000</td>\n",
       "      <td>6.726816e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       jaccard_followers  jaccard_followees  cosine_followers  \\\n",
       "count        2000.000000        2000.000000       2000.000000   \n",
       "mean            0.033092           0.006961          0.017098   \n",
       "std             0.071817           0.032181          0.049803   \n",
       "min             0.000000           0.000000          0.000000   \n",
       "25%             0.000000           0.000000          0.000000   \n",
       "50%             0.004759           0.000000          0.001418   \n",
       "75%             0.034830           0.000000          0.013931   \n",
       "max             1.000000           0.545455          1.000000   \n",
       "\n",
       "       cosine_followees  num_followers_s  num_followers_d  num_followees_s  \\\n",
       "count       2000.000000      2000.000000      2000.000000      2000.000000   \n",
       "mean           0.014244        90.873000        90.873000      1790.070500   \n",
       "std            0.055368       166.968887       166.968887     27168.890833   \n",
       "min            0.000000         0.000000         0.000000         0.000000   \n",
       "25%            0.000000        12.000000        12.000000         0.000000   \n",
       "50%            0.000000        36.000000        36.000000         0.000000   \n",
       "75%            0.000000        96.000000        96.000000         0.000000   \n",
       "max            0.722897      2021.000000      2021.000000    759391.000000   \n",
       "\n",
       "       num_followees_d  inter_followers  inter_followees   adar_index  \\\n",
       "count      2000.000000      2000.000000      2000.000000  2000.000000   \n",
       "mean       1790.070500        90.873000      1790.070500     2.876330   \n",
       "std       27168.890833       166.968887     27168.890833    51.706446   \n",
       "min           0.000000         0.000000         0.000000     0.000000   \n",
       "25%           0.000000        12.000000         0.000000     0.000000   \n",
       "50%           0.000000        36.000000         0.000000     0.000000   \n",
       "75%           0.000000        96.000000         0.000000     0.000000   \n",
       "max      759391.000000      2021.000000    759391.000000  2287.773260   \n",
       "\n",
       "       shortest_path        c_nei        prefer  \n",
       "count     2000.00000  2000.000000  2.000000e+03  \n",
       "mean         4.12650    11.373000  9.659938e+05  \n",
       "std         12.30834   100.078298  1.717118e+07  \n",
       "min          2.00000     0.000000  0.000000e+00  \n",
       "25%          2.00000     0.000000  9.265000e+02  \n",
       "50%          2.00000     1.000000  7.997000e+03  \n",
       "75%          3.00000     7.000000  5.273600e+04  \n",
       "max         99.00000  4361.000000  6.726816e+08  "
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_sub.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 902,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.99502786e-01, 5.00497214e-01, 0.00000000e+00],\n",
       "       [4.94228732e-01, 5.05771268e-01, 0.00000000e+00],\n",
       "       [1.67105957e-04, 1.56184052e-04, 9.99676710e-01],\n",
       "       ...,\n",
       "       [5.00931526e-01, 4.99068474e-01, 0.00000000e+00],\n",
       "       [5.13765036e-01, 4.86234964e-01, 0.00000000e+00],\n",
       "       [5.00824145e-01, 4.99175855e-01, 0.00000000e+00]])"
      ]
     },
     "execution_count": 902,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 901,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00, 6.79672090e-01, 3.20327910e-01],\n",
       "       [9.98053542e-01, 1.22431258e-03, 7.22145833e-04],\n",
       "       [9.95603011e-01, 2.95705944e-03, 1.43992980e-03],\n",
       "       ...,\n",
       "       [0.00000000e+00, 5.02238595e-01, 4.97761405e-01],\n",
       "       [0.00000000e+00, 5.02263071e-01, 4.97736929e-01],\n",
       "       [0.00000000e+00, 5.00000000e-01, 5.00000000e-01]])"
      ]
     },
     "execution_count": 901,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 937,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_sub = scaler.transform(X_sub)\n",
    "scaler.fit(X_sub)\n",
    "X_sub = scaler.transform(X_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_sub = rf_clf.predict_proba(X_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.72832292, 0.27167708],\n",
       "       [0.72832292, 0.27167708],\n",
       "       [0.43019957, 0.56980043],\n",
       "       [0.37190545, 0.62809455],\n",
       "       [0.72832292, 0.27167708],\n",
       "       [0.72832292, 0.27167708],\n",
       "       [0.47614173, 0.52385827],\n",
       "       [0.74777607, 0.25222393],\n",
       "       [0.74777607, 0.25222393],\n",
       "       [0.72832292, 0.27167708],\n",
       "       [0.74777607, 0.25222393],\n",
       "       [0.74777607, 0.25222393],\n",
       "       [0.21483233, 0.78516767],\n",
       "       [0.51343121, 0.48656879],\n",
       "       [0.73528877, 0.26471123]])"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_sub[0:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "871"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(rf_clf.predict(X_sub))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(data={\"Id\":range(1,len(y_sub)+1), \"Predicted\":[x[1] for x in y_sub]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('submissioin_dis_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 804,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.215807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.215798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.254232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.436486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.218776</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  Predicted\n",
       "0   1   0.215807\n",
       "1   2   0.215798\n",
       "2   3   0.254232\n",
       "3   4   0.436486\n",
       "4   5   0.218776"
      ]
     },
     "execution_count": 804,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 805,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.350379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.350379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.997903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.980240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.350379</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  Predicted\n",
       "0   1   0.350379\n",
       "1   2   0.350379\n",
       "2   3   0.997903\n",
       "3   4   0.980240\n",
       "4   5   0.350379"
      ]
     },
     "execution_count": 805,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_one.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 810,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c_nei</th>\n",
       "      <th>page_rank_s</th>\n",
       "      <th>page_rank_d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.002918</td>\n",
       "      <td>0.002918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.002918</td>\n",
       "      <td>0.002918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.002918</td>\n",
       "      <td>0.002918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0.002918</td>\n",
       "      <td>0.002918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.002918</td>\n",
       "      <td>0.002918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0.002946</td>\n",
       "      <td>0.002918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0.003998</td>\n",
       "      <td>0.002918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0.006267</td>\n",
       "      <td>0.002918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0.002918</td>\n",
       "      <td>0.002918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0.002918</td>\n",
       "      <td>0.002967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0.004003</td>\n",
       "      <td>0.002918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0.002918</td>\n",
       "      <td>0.002918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4</td>\n",
       "      <td>0.003989</td>\n",
       "      <td>0.002918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0.003014</td>\n",
       "      <td>0.002918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0.004280</td>\n",
       "      <td>0.002918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>11</td>\n",
       "      <td>0.002918</td>\n",
       "      <td>0.008555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>0.002918</td>\n",
       "      <td>0.002918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>0.003631</td>\n",
       "      <td>0.002918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0.002892</td>\n",
       "      <td>0.002918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2</td>\n",
       "      <td>0.002918</td>\n",
       "      <td>0.003025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>0.002918</td>\n",
       "      <td>0.002918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>6</td>\n",
       "      <td>0.002918</td>\n",
       "      <td>0.007452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>0.002918</td>\n",
       "      <td>0.002918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>0.002905</td>\n",
       "      <td>0.002918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>6</td>\n",
       "      <td>0.002918</td>\n",
       "      <td>0.002918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>0.002918</td>\n",
       "      <td>0.002918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>0.002892</td>\n",
       "      <td>0.002918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>0.002918</td>\n",
       "      <td>0.002918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>0.002918</td>\n",
       "      <td>0.002918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>0.002918</td>\n",
       "      <td>0.002918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970</th>\n",
       "      <td>2</td>\n",
       "      <td>0.003309</td>\n",
       "      <td>0.002918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1971</th>\n",
       "      <td>26</td>\n",
       "      <td>0.006518</td>\n",
       "      <td>0.002918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1972</th>\n",
       "      <td>7</td>\n",
       "      <td>0.002918</td>\n",
       "      <td>0.002918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1973</th>\n",
       "      <td>0</td>\n",
       "      <td>0.003702</td>\n",
       "      <td>0.002991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1974</th>\n",
       "      <td>53</td>\n",
       "      <td>0.002892</td>\n",
       "      <td>0.002918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1975</th>\n",
       "      <td>0</td>\n",
       "      <td>0.002918</td>\n",
       "      <td>0.002918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1976</th>\n",
       "      <td>0</td>\n",
       "      <td>0.002918</td>\n",
       "      <td>0.002918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1977</th>\n",
       "      <td>0</td>\n",
       "      <td>0.002918</td>\n",
       "      <td>0.002918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>0</td>\n",
       "      <td>0.002918</td>\n",
       "      <td>0.004118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979</th>\n",
       "      <td>1</td>\n",
       "      <td>0.003078</td>\n",
       "      <td>0.002918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980</th>\n",
       "      <td>38</td>\n",
       "      <td>0.002918</td>\n",
       "      <td>0.005163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>0</td>\n",
       "      <td>0.002918</td>\n",
       "      <td>0.002918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1982</th>\n",
       "      <td>1</td>\n",
       "      <td>0.003699</td>\n",
       "      <td>0.002918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1983</th>\n",
       "      <td>0</td>\n",
       "      <td>0.002918</td>\n",
       "      <td>0.004080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984</th>\n",
       "      <td>2</td>\n",
       "      <td>0.002918</td>\n",
       "      <td>0.002918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985</th>\n",
       "      <td>3</td>\n",
       "      <td>0.002918</td>\n",
       "      <td>0.002918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986</th>\n",
       "      <td>33</td>\n",
       "      <td>0.003523</td>\n",
       "      <td>0.015676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987</th>\n",
       "      <td>1</td>\n",
       "      <td>0.002892</td>\n",
       "      <td>0.002918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988</th>\n",
       "      <td>3</td>\n",
       "      <td>0.002918</td>\n",
       "      <td>0.002918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989</th>\n",
       "      <td>4</td>\n",
       "      <td>0.002918</td>\n",
       "      <td>0.002892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990</th>\n",
       "      <td>0</td>\n",
       "      <td>0.002918</td>\n",
       "      <td>0.002918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991</th>\n",
       "      <td>1</td>\n",
       "      <td>0.002918</td>\n",
       "      <td>0.002918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992</th>\n",
       "      <td>0</td>\n",
       "      <td>0.002918</td>\n",
       "      <td>0.002918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993</th>\n",
       "      <td>15</td>\n",
       "      <td>0.002918</td>\n",
       "      <td>0.002918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>9</td>\n",
       "      <td>0.002892</td>\n",
       "      <td>0.005094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>0</td>\n",
       "      <td>0.002918</td>\n",
       "      <td>0.002892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>1</td>\n",
       "      <td>0.002918</td>\n",
       "      <td>0.002918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>0</td>\n",
       "      <td>0.002918</td>\n",
       "      <td>0.002918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>0</td>\n",
       "      <td>0.002892</td>\n",
       "      <td>0.002918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>0</td>\n",
       "      <td>0.002918</td>\n",
       "      <td>0.002918</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      c_nei  page_rank_s  page_rank_d\n",
       "0         0     0.002918     0.002918\n",
       "1         0     0.002918     0.002918\n",
       "2         3     0.002918     0.002918\n",
       "3         2     0.002918     0.002918\n",
       "4         0     0.002918     0.002918\n",
       "5         0     0.002946     0.002918\n",
       "6         1     0.003998     0.002918\n",
       "7         1     0.006267     0.002918\n",
       "8         0     0.002918     0.002918\n",
       "9         0     0.002918     0.002967\n",
       "10        0     0.004003     0.002918\n",
       "11        0     0.002918     0.002918\n",
       "12        4     0.003989     0.002918\n",
       "13        0     0.003014     0.002918\n",
       "14        0     0.004280     0.002918\n",
       "15       11     0.002918     0.008555\n",
       "16        1     0.002918     0.002918\n",
       "17        0     0.003631     0.002918\n",
       "18        0     0.002892     0.002918\n",
       "19        2     0.002918     0.003025\n",
       "20        0     0.002918     0.002918\n",
       "21        6     0.002918     0.007452\n",
       "22        0     0.002918     0.002918\n",
       "23        0     0.002905     0.002918\n",
       "24        6     0.002918     0.002918\n",
       "25        0     0.002918     0.002918\n",
       "26        1     0.002892     0.002918\n",
       "27        0     0.002918     0.002918\n",
       "28        0     0.002918     0.002918\n",
       "29        0     0.002918     0.002918\n",
       "...     ...          ...          ...\n",
       "1970      2     0.003309     0.002918\n",
       "1971     26     0.006518     0.002918\n",
       "1972      7     0.002918     0.002918\n",
       "1973      0     0.003702     0.002991\n",
       "1974     53     0.002892     0.002918\n",
       "1975      0     0.002918     0.002918\n",
       "1976      0     0.002918     0.002918\n",
       "1977      0     0.002918     0.002918\n",
       "1978      0     0.002918     0.004118\n",
       "1979      1     0.003078     0.002918\n",
       "1980     38     0.002918     0.005163\n",
       "1981      0     0.002918     0.002918\n",
       "1982      1     0.003699     0.002918\n",
       "1983      0     0.002918     0.004080\n",
       "1984      2     0.002918     0.002918\n",
       "1985      3     0.002918     0.002918\n",
       "1986     33     0.003523     0.015676\n",
       "1987      1     0.002892     0.002918\n",
       "1988      3     0.002918     0.002918\n",
       "1989      4     0.002918     0.002892\n",
       "1990      0     0.002918     0.002918\n",
       "1991      1     0.002918     0.002918\n",
       "1992      0     0.002918     0.002918\n",
       "1993     15     0.002918     0.002918\n",
       "1994      9     0.002892     0.005094\n",
       "1995      0     0.002918     0.002892\n",
       "1996      1     0.002918     0.002918\n",
       "1997      0     0.002918     0.002918\n",
       "1998      0     0.002892     0.002918\n",
       "1999      0     0.002918     0.002918\n",
       "\n",
       "[2000 rows x 3 columns]"
      ]
     },
     "execution_count": 810,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 795,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_one = pd.read_csv(\"submissioin_one_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 802,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_list = []\n",
    "for i in range(len(result_one)):\n",
    "    if abs(result_one.iloc[i]['Predicted'] - result.iloc[i]['Predicted']) >= 0.5:\n",
    "        diff_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 803,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "495"
      ]
     },
     "execution_count": 803,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(diff_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
