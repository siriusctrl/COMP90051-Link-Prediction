{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "fe = []\n",
    "with open(\"train.txt\", \"r\") as f:\n",
    "    for raw_line in f:\n",
    "        line = raw_line.strip().split(\"\\t\")\n",
    "        fe.append(len(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df(filename=\"train.txt\"):\n",
    "    data = {'Source':[], 'Sink':[]}\n",
    "    with open(filename, \"r\") as f:\n",
    "        for raw_line in f:\n",
    "            line = raw_line.strip().split(\"\\t\")\n",
    "            data['Source'] += [line[0]]*(len(line)-1)\n",
    "            data['Sink'] += line[1:]\n",
    "    pd_data = pd.DataFrame(data=data)\n",
    "#     pd_data[['Source', 'Sink']] = pd_data[['Source', 'Sink']].apply(pd.to_numeric)\n",
    "    pd_data = pd_data.drop_duplicates(keep=False)\n",
    "    return pd_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_sub():\n",
    "    with open('test-public.txt', 'r') as f:\n",
    "        # skip the header\n",
    "        f.readline()\n",
    "        data = {'Source':[], 'Sink':[]}\n",
    "        for raw_line in f:\n",
    "            line = raw_line.strip().split(\"\\t\")\n",
    "            data['Source'].append(int(line[1]))\n",
    "            data['Sink'].append(int(line[2]))\n",
    "        return pd.DataFrame(data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"processed_train_f_reduced.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Sink</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4762204</td>\n",
       "      <td>4058810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4762204</td>\n",
       "      <td>757117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4762204</td>\n",
       "      <td>1165800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4762204</td>\n",
       "      <td>479394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4762204</td>\n",
       "      <td>3446558</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Source     Sink\n",
       "0  4762204  4058810\n",
       "1  4762204   757117\n",
       "2  4762204  1165800\n",
       "3  4762204   479394\n",
       "4  4762204  3446558"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(323932, 2)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"processed_train.csv\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_data = read_sub()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Sink</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3563811</td>\n",
       "      <td>3600160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2052043</td>\n",
       "      <td>1401960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4517994</td>\n",
       "      <td>1690636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1660006</td>\n",
       "      <td>4349447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>581111</td>\n",
       "      <td>1882617</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Source     Sink\n",
       "0  3563811  3600160\n",
       "1  2052043  1401960\n",
       "2  4517994  1690636\n",
       "3  1660006  4349447\n",
       "4   581111  1882617"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 2)"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_nodes = set(sub_data['Source'].value_counts().keys()).union(sub_data['Sink'].value_counts().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_df = data[(data['Source'].isin(sub_nodes)) | (data['Sink'].isin(sub_nodes))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5037682, 2)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = reduced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"processed_train_reduced.csv\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualising using networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g = nx.read_edgelist('processed_train.csv',delimiter=',',create_using=nx.DiGraph(),nodetype=int)\n",
    "g = nx.from_pandas_edgelist(data, \"Source\", \"Sink\", create_using=nx.DiGraph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: \n",
      "Type: DiGraph\n",
      "Number of nodes: 135143\n",
      "Number of edges: 323932\n",
      "Average in degree:   2.3970\n",
      "Average out degree:   2.3970\n"
     ]
    }
   ],
   "source": [
    "print(nx.info(g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "indegree_dist = list(dict(g.in_degree()).values())\n",
    "indegree_dist.sort()\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(indegree_dist)\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('# Of Followers')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90 percentile value is 5.0\n",
      "91 percentile value is 5.0\n",
      "92 percentile value is 5.0\n",
      "93 percentile value is 6.0\n",
      "94 percentile value is 6.0\n",
      "95 percentile value is 7.0\n",
      "96 percentile value is 8.0\n",
      "97 percentile value is 9.0\n",
      "98 percentile value is 11.0\n",
      "99 percentile value is 17.0\n",
      "100 percentile value is 513.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,11):\n",
    "    print(90+i,'percentile value is',np.percentile(indegree_dist, 90+i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.1 percentile value is 17.0\n",
      "99.2 percentile value is 19.0\n",
      "99.3 percentile value is 20.0\n",
      "99.4 percentile value is 22.0\n",
      "99.5 percentile value is 24.0\n",
      "99.6 percentile value is 27.4320000000007\n",
      "99.7 percentile value is 32.0\n",
      "99.8 percentile value is 41.0\n",
      "99.9 percentile value is 70.0\n",
      "100.0 percentile value is 513.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(10,110,10):\n",
    "    print(99+(i/100),'percentile value is',np.percentile(indegree_dist,99+(i/100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of persons who have no followers 2126 and % is 1.5731484427606313\n"
     ]
    }
   ],
   "source": [
    "print('# of persons who have no followers' ,sum(np.array(indegree_dist)==0),'and % is',\n",
    "        sum(np.array(indegree_dist)==0)*100/len(indegree_dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "outdegree_dist = list(dict(g.out_degree()).values())\n",
    "outdegree_dist.sort()\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(outdegree_dist)\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('# Of Followee')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.1 percentile value is 9.0\n",
      "99.2 percentile value is 10.0\n",
      "99.3 percentile value is 12.0\n",
      "99.4 percentile value is 16.0\n",
      "99.5 percentile value is 19.29000000000815\n",
      "99.6 percentile value is 25.0\n",
      "99.7 percentile value is 35.0\n",
      "99.8 percentile value is 53.0\n",
      "99.9 percentile value is 130.57400000002235\n",
      "100.0 percentile value is 16663.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(10,110,10):\n",
    "    print(99+(i/100),'percentile value is',np.percentile(outdegree_dist, 99+(i/100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.9 percentile value is 130.57400000002235\n",
      "99.91 percentile value is 150.11660000003758\n",
      "99.92 percentile value is 192.772799999977\n",
      "99.93 percentile value is 283.0\n",
      "99.94 percentile value is 367.7847999999649\n",
      "99.95 percentile value is 450.1450000000186\n",
      "99.96 percentile value is 992.9103999985382\n",
      "99.97 percentile value is 1957.8700000006938\n",
      "99.98 percentile value is 2699.630799999868\n",
      "99.99 percentile value is 5250.934399997117\n",
      "100.0 percentile value is 16663.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(900,1010,10):\n",
    "    print(99+(i/1000),'percentile value is',np.percentile(outdegree_dist, 99+(i/1000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of persons those are not following anyone are 132537 and % is 98.07167222867629\n"
     ]
    }
   ],
   "source": [
    "print('# of persons those are not following anyone are', sum(np.array(outdegree_dist)==0),'and % is',\n",
    "        sum(np.array(outdegree_dist)==0)*100/len(outdegree_dist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Negative Data preparing and Train-validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: \n",
      "Type: DiGraph\n",
      "Number of nodes: 135143\n",
      "Number of edges: 323932\n",
      "Average in degree:   2.3970\n",
      "Average out degree:   2.3970\n"
     ]
    }
   ],
   "source": [
    "print(nx.info(g))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate random missing edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import csv\n",
    "# getting the processed connection\n",
    "raw_connection = csv.reader(open('processed_train.csv', 'r'))\n",
    "\n",
    "exist_edges = {}\n",
    "\n",
    "for edge in raw_connection:\n",
    "    exist_edges[(edge[0], edge[1])] = 1\n",
    "\n",
    "# in order to prevent overfitting, we generate the same number of negative edge\n",
    "missing_edges = set()\n",
    "while(len(missing_edges) < 323932):\n",
    "    a = random.randint(1, 135143)\n",
    "    b = random.randint(1, 135143)\n",
    "    if a == b:\n",
    "        continue\n",
    "        \n",
    "    existance = exist_edges.get((a,b), -1)\n",
    "    if existance == -1:\n",
    "        try:\n",
    "            # if distance within 2, that means they share a common follower and very likely to be friends in real world or at least know each others\n",
    "            if nx.shortest_path_length(g, source=a, target=b) > 2:\n",
    "                missing_edges.add((a,b))\n",
    "            else:\n",
    "                continue\n",
    "        except:\n",
    "            missing_edges.add((a,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "323932"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(missing_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(missing_edges, open('data/missing_edges_final.p', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test Partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_data = pd.DataFrame(list(missing_edges), columns=['Source', 'Sink'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "323932"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "323932"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(negative_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#Trian test split \n",
    "#positive links and negative links seperatly because we need positive training data only for creating graph and for feature generation\n",
    "X_train_pos, X_test_pos, y_train_pos, y_test_pos  = train_test_split(data, np.ones(len(data)), test_size=0.2, random_state=90051)\n",
    "X_train_neg, X_test_neg, y_train_neg, y_test_neg  = train_test_split(negative_data, np.zeros(len(negative_data)), test_size=0.2, random_state=90051)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Number of nodes in the train data graph with edges 259145\n",
      "Number of nodes in the train data graph without edges 259145\n",
      "============================================================\n",
      "Number of nodes in the test data graph with edges 64787\n",
      "Number of nodes in the test data graph without edges 64787\n"
     ]
    }
   ],
   "source": [
    "# !TODO the data is not perfectly balanced, maybe fixed this later\n",
    "print('='*60)\n",
    "print(\"Number of nodes in the train data graph with edges\", y_train_pos.shape[0])\n",
    "print(\"Number of nodes in the train data graph without edges\", y_train_neg.shape[0])\n",
    "print('='*60)\n",
    "print(\"Number of nodes in the test data graph with edges\", y_test_pos.shape[0])\n",
    "print(\"Number of nodes in the test data graph without edges\", y_test_neg.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing header and saving\n",
    "X_train_pos.to_csv('data/train_pos.csv',header=False, index=False)\n",
    "X_test_pos.to_csv('data/test_pos.csv',header=False, index=False)\n",
    "X_train_neg.to_csv('data/train_neg.csv',header=False, index=False)\n",
    "X_test_neg.to_csv('data/test_neg.csv',header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_pos.append(X_train_neg, ignore_index=True)\n",
    "y_train = np.concatenate((y_train_pos, y_train_neg))\n",
    "X_test = X_test_pos.append(X_test_neg, ignore_index=True)\n",
    "y_test = np.concatenate((y_test_pos, y_test_neg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: \n",
      "Type: DiGraph\n",
      "Number of nodes: 117429\n",
      "Number of edges: 259145\n",
      "Average in degree:   2.2068\n",
      "Average out degree:   2.2068\n"
     ]
    }
   ],
   "source": [
    "#generate train and test graph\n",
    "train_graph = nx.read_edgelist('data/train_pos.csv',delimiter=',',create_using=nx.DiGraph(),nodetype=int)\n",
    "print(nx.info(train_graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_followees(a, b, train_graph=train_graph):\n",
    "    try:\n",
    "        if len(set(train_graph.successors(a))) == 0 or len(set(train_graph.successors(b))) == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            intersection = len(set(train_graph.successors(a)).intersection(set(train_graph.successors(b))))\n",
    "            union = len(set(train_graph.successors(a)).union(set(train_graph.successors(b))))\n",
    "            return intersection/union\n",
    "    except:\n",
    "        return 0\n",
    "    return sim\n",
    "\n",
    "def jaccard_followers(a,b, train_graph=train_graph):\n",
    "    try:\n",
    "        if set(train_graph.predecessors(a)) == 0 or len(set(g.predecessors(b))) == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            intersection = len(set(train_graph.predecessors(a)).intersection(set(train_graph.predecessors(b))))\n",
    "            union = len(set(train_graph.predecessors(a)).union(set(train_graph.predecessors(b))))\n",
    "            return intersection/union\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for followees\n",
    "def cosine_followees(a, b, train_graph=train_graph):\n",
    "    try:\n",
    "        if len(set(train_graph.successors(a))) == 0 or len(set(train_graph.successors(b))) == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return (len(set(train_graph.successors(a)).intersection(set(train_graph.successors(b)))))/\\\n",
    "                                    (math.sqrt(len(set(train_graph.successors(a)))*len((set(train_graph.successors(b))))))\n",
    "    except:\n",
    "        return 0\n",
    "    \n",
    "def cosine_followers(a, b, train_graph=train_graph):\n",
    "    try:\n",
    "        \n",
    "        if len(set(train_graph.predecessors(a))) == 0 or len(set(train_graph.predecessors(b))) == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return (len(set(train_graph.predecessors(a)).intersection(set(train_graph.predecessors(b)))))/\\\n",
    "                                     (math.sqrt(len(set(train_graph.predecessors(a))))*(len(set(train_graph.predecessors(b)))))\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min 8.362051873775734e-06\n",
      "max 0.00048134944932700383\n",
      "mean 8.515784005649403e-06\n"
     ]
    }
   ],
   "source": [
    "# caclulating the page rank for each node pair\n",
    "pr = nx.pagerank(train_graph, alpha=0.85)\n",
    "pickle.dump(pr,open('data/page_rank.p','wb'))\n",
    "# use the mean for all the data points which are part of the test dataset but are not in the training dataset\n",
    "mean_pr = float(sum(pr.values())) / len(pr)\n",
    "\n",
    "print('min',pr[min(pr, key=pr.get)])\n",
    "print('max',pr[max(pr, key=pr.get)])\n",
    "print('mean', mean_pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_shortest_path_length(a, b, train_graph=train_graph):\n",
    "    p = -1\n",
    "    try:\n",
    "        # if the edge already exist, we first remove the edge which let our model better understand the graph\n",
    "        if train_graph.has_edge(a,b):\n",
    "            train_graph.remove_edge(a,b)\n",
    "            p= nx.shortest_path_length(train_graph,source=a,target=b)\n",
    "            train_graph.add_edge(a,b)\n",
    "        else:\n",
    "            p= nx.shortest_path_length(train_graph,source=a,target=b)\n",
    "        return p\n",
    "    except:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting weakly connected edges from graph \n",
    "def belongs_to_same_wcc(a, b, train_graph=train_graph):\n",
    "    wcc = list(nx.weakly_connected_components(train_graph))\n",
    "    index = []\n",
    "    # they must belongs are there is a path\n",
    "    if train_graph.has_edge(b,a):\n",
    "        return 1\n",
    "    \n",
    "    if train_graph.has_edge(a,b):\n",
    "        for i in wcc:\n",
    "            if a in i:\n",
    "                index = i\n",
    "                break\n",
    "        if b in index:\n",
    "            train_graph.remove_edge(a,b)\n",
    "            if compute_shortest_path_length(a,b) == -1:\n",
    "                train_graph.add_edge(a,b)\n",
    "                return 0\n",
    "            else:\n",
    "                train_graph.add_edge(a,b)\n",
    "                return 1\n",
    "        else:\n",
    "            return 0\n",
    "    else:\n",
    "        for i in wcc:\n",
    "            if a in i:\n",
    "                index = i\n",
    "                break\n",
    "        if(b in index):\n",
    "            return 1\n",
    "        else:\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adar Index\n",
    "def calc_adar_in(a, b, train_graph=train_graph):\n",
    "    sum = 0\n",
    "    try:\n",
    "        n=list(set(train_graph.successors(a)).intersection(set(train_graph.successors(b))))\n",
    "        if len(n)!=0:\n",
    "            for i in n:\n",
    "                sum=sum+(1/np.log10(len(list(train_graph.predecessors(i)))))\n",
    "            return sum\n",
    "        else:\n",
    "            return 0\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test whether they are mutual followers\n",
    "def follows_back(a, b, train_graph=train_graph):\n",
    "    if train_graph.has_edge(b,a):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min 0.0028783732537377513\n",
      "max 0.008538168742251223\n",
      "mean 0.0029169324653439484\n"
     ]
    }
   ],
   "source": [
    "#Katz centrality of a node is a measure of centrality in a network\n",
    "katz = nx.katz.katz_centrality(train_graph,alpha=0.005,beta=1)\n",
    "pickle.dump(katz, open('data/katz.p','wb'))\n",
    "mean_katz = float(sum(katz.values())) / len(katz)\n",
    "\n",
    "print('min',katz[min(katz, key=katz.get)])\n",
    "print('max',katz[max(katz, key=katz.get)])\n",
    "print('mean', mean_katz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min 0.0\n",
      "max 0.07111477112379715\n",
      "mean 8.515784005654462e-06\n"
     ]
    }
   ],
   "source": [
    "#HITS\n",
    "hits = nx.hits(train_graph, max_iter=100, tol=1e-08, nstart=None, normalized=True)\n",
    "pickle.dump(hits, open('data/hits.p','wb'))\n",
    "mean_hits = float(sum(hits[0].values())) / len(hits[0])\n",
    "\n",
    "print('min',hits[0][min(hits[0], key=hits[0].get)])\n",
    "print('max',hits[0][max(hits[0], key=hits[0].get)])\n",
    "print('mean', mean_hits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try to reduce the sample size, TODO, might fix this later\n",
    "desire_train = 100000\n",
    "desire_test = 50000\n",
    "d_train_pos = sorted(random.sample(range(len(X_train_pos)), int(desire_train/2)))\n",
    "d_test_pos = sorted(random.sample(range(len(X_test_pos)), int(desire_test/2)))\n",
    "d_train_neg = sorted(random.sample(range(len(X_train_neg)), int(desire_train/2)))\n",
    "d_test_neg = sorted(random.sample(range(len(X_test_neg)), int(desire_test/2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shrink_df(df, label, num_list):\n",
    "    if num_list == -1:\n",
    "        return df, label\n",
    "    desire_dict = {\"Source\":[], \"Sink\":[]}\n",
    "    lb = []\n",
    "    for i in num_list:\n",
    "        desire_dict['Source'].append(df.iloc[i]['Source'])\n",
    "        desire_dict['Sink'].append(df.iloc[i]['Sink'])\n",
    "        lb.append(label[i])\n",
    "    return pd.DataFrame(data=desire_dict), np.array(lb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_desire_train_pos, y_desire_train_pos = shrink_df(X_train_pos, y_train_pos, d_train_pos)\n",
    "X_desire_train_neg, y_desire_train_neg = shrink_df(X_train_neg, y_train_neg, d_train_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_desire_test_pos, y_desire_test_pos = shrink_df(X_test_pos, y_test_pos, d_test_pos)\n",
    "X_desire_test_neg, y_desire_test_neg = shrink_df(X_test_neg, y_test_neg, d_test_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_desire_train = X_desire_train_pos.append(X_desire_train_neg, ignore_index=True)\n",
    "X_desire_test = X_desire_test_pos.append(X_desire_test_neg, ignore_index=True)\n",
    "\n",
    "y_desire_train = np.append(y_desire_train_pos, y_desire_train_neg)\n",
    "y_desire_test = np.append(y_desire_test_pos, y_desire_test_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000 100000 50000 50000\n"
     ]
    }
   ],
   "source": [
    "print(len(X_desire_train), len(y_desire_train), len(X_desire_test), len(y_desire_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_features = pd.DataFrame()\n",
    "X_test_features = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#mapping jaccrd followers to train and test data\n",
    "X_train_features['jaccard_followers'] = X_desire_train.apply(lambda row:jaccard_followers(row['Source'], row['Sink']), axis=1)\n",
    "X_test_features['jaccard_followers'] = X_desire_test.apply(lambda row:jaccard_followers(row['Source'], row['Sink']),axis=1)\n",
    "\n",
    "#mapping jaccrd followees to train and test data\n",
    "X_train_features['jaccard_followees'] = X_desire_train.apply(lambda row:jaccard_followees(row['Source'], row['Sink']), axis=1)\n",
    "X_test_features['jaccard_followees'] = X_desire_test.apply(lambda row:jaccard_followees(row['Source'], row['Sink']), axis=1)\n",
    "\n",
    "#mapping jaccrd followers to train and test data\n",
    "X_train_features['cosine_followers'] = X_desire_train.apply(lambda row:cosine_followers(row['Source'], row['Sink']), axis=1)\n",
    "X_test_features['cosine_followers'] = X_desire_test.apply(lambda row:cosine_followers(row['Source'], row['Sink']), axis=1)\n",
    "\n",
    "#mapping jaccrd followees to train and test data\n",
    "X_train_features['cosine_followees'] = X_desire_train.apply(lambda row:cosine_followees(row['Source'], row['Sink']), axis=1)\n",
    "X_test_features['cosine_followees'] = X_desire_test.apply(lambda row:cosine_followees(row['Source'], row['Sink']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_features_stage1(df_final):\n",
    "    #calculating # of followers followees for source and destination\n",
    "    #calculating intersection of followers and followees for source and destination\n",
    "    num_followers_s=[]\n",
    "    num_followees_s=[]\n",
    "    num_followers_d=[]\n",
    "    num_followees_d=[]\n",
    "    inter_followers=[]\n",
    "    inter_followees=[]\n",
    "    \n",
    "    for i, row in df_final.iterrows():\n",
    "        try:\n",
    "            s1 = set(train_graph.predecessors(row['Source']))\n",
    "            s2 = set(train_graph.successors(row['Sink']))\n",
    "        except:\n",
    "            s1 = set()\n",
    "            s2 = set()\n",
    "        try:\n",
    "            d1 = set(train_graph.predecessors(row['Source']))\n",
    "            d2 = set(train_graph.successors(row['Sink']))\n",
    "        except:\n",
    "            d1 = set()\n",
    "            d2 = set()\n",
    "        num_followers_s.append(len(s1))\n",
    "        num_followees_s.append(len(s2))\n",
    "\n",
    "        num_followers_d.append(len(d1))\n",
    "        num_followees_d.append(len(d2))\n",
    "\n",
    "        inter_followers.append(len(s1.intersection(d1)))\n",
    "        inter_followees.append(len(s2.intersection(d2)))\n",
    "    \n",
    "    return num_followers_s, num_followers_d, num_followees_s, num_followees_d, inter_followers, inter_followees\n",
    "\n",
    "X_train_features['num_followers_s'], X_train_features['num_followers_d'], \\\n",
    "X_train_features['num_followees_s'], X_train_features['num_followees_d'], \\\n",
    "X_train_features['inter_followers'], X_train_features['inter_followees'] = compute_features_stage1(X_desire_train)\n",
    "\n",
    "X_test_features['num_followers_s'], X_test_features['num_followers_d'], \\\n",
    "X_test_features['num_followees_s'], X_test_features['num_followees_d'], \\\n",
    "X_test_features['inter_followers'], X_test_features['inter_followees'] = compute_features_stage1(X_desire_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping adar index\n",
    "X_train_features['adar_index'] = X_desire_train.apply(lambda row: calc_adar_in(row['Source'], row['Sink']), axis=1)\n",
    "X_test_features['adar_index'] = X_desire_test.apply(lambda row: calc_adar_in(row['Source'], row['Sink']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping followback\n",
    "X_train_features['follows_back'] = X_desire_train.apply(lambda row: follows_back(row['Source'], row['Sink']), axis=1)\n",
    "X_test_features['follows_back'] = X_desire_test.apply(lambda row: follows_back(row['Source'], row['Sink']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping wcc\n",
    "X_train_features['same_wcc'] = X_desire_train.apply(lambda row: belongs_to_same_wcc(row['Source'], row['Sink']), axis=1)\n",
    "X_test_features['same_wcc'] = X_desire_test.apply(lambda row: belongs_to_same_wcc(row['Source'], row['Sink']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_features['shortest_path'] = X_desire_train.apply(lambda row: compute_shortest_path_length(row['Source'], row['Sink']), axis=1)\n",
    "X_test_features['shortest_path'] = X_desire_test.apply(lambda row: compute_shortest_path_length(row['Source'], row['Sink']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_features['page_rank_s'] = X_desire_train['Source'].apply(lambda x:pr.get(x, mean_pr))\n",
    "X_train_features['page_rank_d'] = X_desire_train['Sink'].apply(lambda x:pr.get(x, mean_pr))\n",
    "X_test_features['page_rank_s'] = X_desire_test['Source'].apply(lambda x:pr.get(x, mean_pr))\n",
    "X_test_features['page_rank_d'] = X_desire_test['Sink'].apply(lambda x:pr.get(x, mean_pr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Katz centrality score for source and destination in Train and test\n",
    "#if anything not there in train graph then adding mean katz score\n",
    "X_train_features['katz_s'] = X_desire_train['Source'].apply(lambda x: katz.get(x,mean_katz))\n",
    "X_train_features['katz_d'] = X_desire_train['Sink'].apply(lambda x: katz.get(x,mean_katz))\n",
    "X_test_features['katz_s'] = X_desire_test['Source'].apply(lambda x: katz.get(x,mean_katz))\n",
    "X_test_features['katz_d'] = X_desire_test['Sink'].apply(lambda x: katz.get(x,mean_katz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hits algorithm score for source and destination in Train and test\n",
    "#if anything not there in train graph then adding 0\n",
    "X_train_features['hubs_s'] = X_desire_train['Source'].apply(lambda x: hits[0].get(x,0))\n",
    "X_train_features['hubs_d'] = X_desire_train['Sink'].apply(lambda x: hits[0].get(x,0))\n",
    "X_test_features['hubs_s'] = X_desire_test['Source'].apply(lambda x: hits[0].get(x,0))\n",
    "X_test_features['hubs_d'] = X_desire_test['Sink'].apply(lambda x: hits[0].get(x,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_features['authorities_s'] = X_desire_train['Source'].apply(lambda x: hits[1].get(x,0))\n",
    "X_train_features['authorities_d'] = X_desire_train['Sink'].apply(lambda x: hits[1].get(x,0))\n",
    "X_test_features['authorities_s'] = X_desire_test['Source'].apply(lambda x: hits[1].get(x,0))\n",
    "X_test_features['authorities_d'] = X_desire_test['Sink'].apply(lambda x: hits[1].get(x,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(X_train_features, open('data/X_train_features.p','wb'))\n",
    "pickle.dump(X_test_features, open('data/X_test_features.p','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_features.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xinyaoniu/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=90051, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr_clf = LogisticRegression(random_state=90051)\n",
    "lr_clf.fit(X_train_features, y_desire_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82922"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_clf.score(X_test_features, y_desire_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xinyaoniu/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=3, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,\n",
       "                       oob_score=False, random_state=90051, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_clf = RandomForestClassifier(max_depth=3, random_state=90051, n_jobs=-1)\n",
    "rf_clf.fit(X_train_features, y_desire_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82988"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_clf.score(X_test_features, y_desire_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.41354897, 0.58645103],\n",
       "       [0.41354897, 0.58645103],\n",
       "       [0.41354897, 0.58645103],\n",
       "       ...,\n",
       "       [1.        , 0.        ],\n",
       "       [0.7156832 , 0.2843168 ],\n",
       "       [0.65911074, 0.34088926]])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_clf.predict_proba(X_test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "def evaluate_roc_auc(clf, features, labels):\n",
    "    predicted = clf.predict_proba(features)\n",
    "\n",
    "    # check which class corresponds to positive links\n",
    "    positive_column = list(clf.classes_).index(1)\n",
    "    return roc_auc_score(labels, predicted[:, positive_column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8300563056"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_roc_auc(lr_clf, X_test_features, y_desire_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.05, max_delta_step=0, max_depth=4,\n",
       "              min_child_weight=1, missing=None, monotone_constraints='()',\n",
       "              n_estimators=500, n_jobs=5, nthread=5, num_parallel_tree=1,\n",
       "              objective='binary:logistic', random_state=0, reg_alpha=0,\n",
       "              reg_lambda=1.0, scale_pos_weight=1, seed=0, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "#Building Model using best parameter\n",
    "tuned_params = {'max_depth': [1, 2, 3, 4, 5], 'learning_rate': [0.01, 0.05, 0.1], \n",
    "                'n_estimators': [100, 200, 300, 400, 500], \n",
    "                'reg_lambda': [0.001, 0.1, 1.0, 10.0, 100.0]}\n",
    "# clf = GridSearchCV(\n",
    "#     xgb.XGBClassifier(base_score=0.5, \n",
    "#                   booster='gbtree', \n",
    "#                   colsample_bylevel=1, \n",
    "#                   colsample_bytree=1, \n",
    "#                   gamma=0, \n",
    "#                   learning_rate=0.05, \n",
    "#                   max_delta_step=0,\n",
    "#                   max_depth=4, \n",
    "#                   min_child_weight=1, \n",
    "#                   missing=None, \n",
    "#                   n_estimators=500,\n",
    "#                   n_jobs=1, \n",
    "#                   nthread=None,\n",
    "#                   objective='binary:logistic', \n",
    "#                   random_state=0,\n",
    "#                   reg_alpha=0, \n",
    "#                   reg_lambda=1.0, \n",
    "#                   scale_pos_weight=1, \n",
    "#                   seed=None,\n",
    "#                   silent=False, \n",
    "#                   subsample=1), \n",
    "#     tuned_params, \n",
    "#     scoring = 'roc_auc', \n",
    "#     n_jobs=-1\n",
    "# )\n",
    "\n",
    "xgb_clf = xgb.XGBClassifier(base_score=0.5, \n",
    "                  booster='gbtree',\n",
    "                  colsample_bylevel=1, \n",
    "                  colsample_bytree=1,\n",
    "                  gamma=0,\n",
    "                  learning_rate=0.05,\n",
    "                  max_delta_step=0,\n",
    "                  max_depth=4,\n",
    "                  min_child_weight=1,\n",
    "                  missing=None,\n",
    "                  n_estimators=500,\n",
    "                  n_jobs=5,\n",
    "                  nthread=None,\n",
    "                  objective='binary:logistic',\n",
    "                  random_state=0,\n",
    "                  reg_alpha=0,\n",
    "                  reg_lambda=1.0,\n",
    "                  scale_pos_weight=1,\n",
    "                  seed=None,\n",
    "                  subsample=1)\n",
    "\n",
    "xgb_clf.fit(X_train_features, y_desire_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7848"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_clf.score(X_test_features, y_desire_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "voting = VotingClassifier(estimators=[('lr', lr_clf), ('xgb', clf), ('rf', rf_clf)], voting='soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xinyaoniu/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lr',\n",
       "                              LogisticRegression(C=1.0, class_weight=None,\n",
       "                                                 dual=False, fit_intercept=True,\n",
       "                                                 intercept_scaling=1,\n",
       "                                                 l1_ratio=None, max_iter=100,\n",
       "                                                 multi_class='warn',\n",
       "                                                 n_jobs=None, penalty='l2',\n",
       "                                                 random_state=90051,\n",
       "                                                 solver='warn', tol=0.0001,\n",
       "                                                 verbose=0, warm_start=False)),\n",
       "                             ('xgb',\n",
       "                              XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                            colsample_bylevel=1,\n",
       "                                            colsa...\n",
       "                                                     class_weight=None,\n",
       "                                                     criterion='gini',\n",
       "                                                     max_depth=5,\n",
       "                                                     max_features='auto',\n",
       "                                                     max_leaf_nodes=None,\n",
       "                                                     min_impurity_decrease=0.0,\n",
       "                                                     min_impurity_split=None,\n",
       "                                                     min_samples_leaf=1,\n",
       "                                                     min_samples_split=2,\n",
       "                                                     min_weight_fraction_leaf=0.0,\n",
       "                                                     n_estimators=10, n_jobs=-1,\n",
       "                                                     oob_score=False,\n",
       "                                                     random_state=90051,\n",
       "                                                     verbose=0,\n",
       "                                                     warm_start=False))],\n",
       "                 flatten_transform=True, n_jobs=None, voting='soft',\n",
       "                 weights=None)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting.fit(X_train_features, y_desire_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7848"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting.score(X_test_features, y_desire_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genereate Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Sink</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3563811</td>\n",
       "      <td>3600160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2052043</td>\n",
       "      <td>1401960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4517994</td>\n",
       "      <td>1690636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1660006</td>\n",
       "      <td>4349447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>581111</td>\n",
       "      <td>1882617</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Source     Sink\n",
       "0  3563811  3600160\n",
       "1  2052043  1401960\n",
       "2  4517994  1690636\n",
       "3  1660006  4349447\n",
       "4   581111  1882617"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_data['Source'] = sub_data['Source'].apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_data['Sink'] = sub_data['Sink'].apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sub = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: \n",
      "Type: DiGraph\n",
      "Number of nodes: 4842581\n",
      "Number of edges: 23888876\n",
      "Average in degree:   4.9331\n",
      "Average out degree:   4.9331\n"
     ]
    }
   ],
   "source": [
    "origial_graph = nx.read_edgelist('processed_train.csv',delimiter=',',create_using=nx.DiGraph(),nodetype=int)\n",
    "print(nx.info(origial_graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "581111"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(sub_data['Source'][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.shortest_path_length(origial_graph,source=sub_data['Source'][100],target=sub_data['Sink'][100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mapping jaccrd followers to train and test data\n",
    "X_sub['jaccard_followers'] = sub_data.apply(\n",
    "    lambda row:jaccard_followers(row['Source'], row['Sink'], train_graph=origial_graph), \n",
    "    axis=1)\n",
    "\n",
    "#mapping jaccrd followees to train and test data\n",
    "X_sub['jaccard_followees'] = sub_data.apply(\n",
    "    lambda row:jaccard_followees(row['Source'], row['Sink'], train_graph=origial_graph), \n",
    "    axis=1)\n",
    "\n",
    "#mapping jaccrd followers to train and test data\n",
    "X_sub['cosine_followers'] = sub_data.apply(\n",
    "    lambda row:cosine_followers(row['Source'], row['Sink'], train_graph=origial_graph),\n",
    "    axis=1)\n",
    "\n",
    "#mapping jaccrd followees to train and test data\n",
    "X_sub['cosine_followees'] = sub_data.apply(\n",
    "    lambda row:cosine_followees(row['Source'], row['Sink'], train_graph=origial_graph), \n",
    "    axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sub['num_followers_s'], X_sub['num_followers_d'], \\\n",
    "X_sub['num_followees_s'], X_sub['num_followees_d'], \\\n",
    "X_sub['inter_followers'], X_sub['inter_followees'] = compute_features_stage1(sub_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping followback\n",
    "X_sub['follows_back'] = sub_data.apply(lambda row: follows_back(row['Source'], row['Sink'], train_graph=origial_graph), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping adar index\n",
    "X_sub['adar_index'] = sub_data.apply(lambda row: calc_adar_in(row['Source'], row['Sink'], train_graph=origial_graph), axis=1)\n",
    "\n",
    "# mapping wcc\n",
    "X_sub['same_wcc'] = sub_data.apply(lambda row: belongs_to_same_wcc(row['Source'], row['Sink'], train_graph=origial_graph), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sub['shortest_path'] = sub_data.apply(lambda row: compute_shortest_path_length(row['Source'], row['Sink'], train_graph=origial_graph), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sub['page_rank_s'] = sub_data['Source'].apply(lambda x:pr.get(x, mean_pr))\n",
    "X_sub['page_rank_d'] = sub_data['Sink'].apply(lambda x:pr.get(x, mean_pr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sub['katz_s'] = sub_data['Source'].apply(lambda x: katz.get(x,mean_katz))\n",
    "X_sub['katz_d'] = sub_data['Sink'].apply(lambda x: katz.get(x,mean_katz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sub['hubs_s'] = sub_data['Source'].apply(lambda x: hits[0].get(x,0))\n",
    "X_sub['hubs_d'] = sub_data['Sink'].apply(lambda x: hits[0].get(x,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sub['authorities_s'] = sub_data['Source'].apply(lambda x: hits[1].get(x,0))\n",
    "X_sub['authorities_d'] = sub_data['Sink'].apply(lambda x: hits[1].get(x,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jaccard_followers</th>\n",
       "      <th>jaccard_followees</th>\n",
       "      <th>cosine_followers</th>\n",
       "      <th>cosine_followees</th>\n",
       "      <th>num_followers_s</th>\n",
       "      <th>num_followers_d</th>\n",
       "      <th>num_followees_s</th>\n",
       "      <th>num_followees_d</th>\n",
       "      <th>inter_followers</th>\n",
       "      <th>inter_followees</th>\n",
       "      <th>shortest_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.008018</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.026316</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.001347</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.016000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.028249</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.014905</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006726</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.049632</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004444</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>85</td>\n",
       "      <td>85</td>\n",
       "      <td>27</td>\n",
       "      <td>85</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.153627</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.006164</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.021978</td>\n",
       "      <td>0.002433</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    jaccard_followers  jaccard_followees  cosine_followers  cosine_followees  \\\n",
       "0            0.000000           0.000000                 0                 0   \n",
       "1            0.000000           0.000000                 0                 0   \n",
       "2            0.000000           0.000000                 0                 0   \n",
       "3            0.000000           0.000000                 0                 0   \n",
       "4            0.000000           0.000000                 0                 0   \n",
       "5            0.000000           0.000000                 0                 0   \n",
       "6            0.000000           0.000000                 0                 0   \n",
       "7            0.000000           0.000000                 0                 0   \n",
       "8            0.000000           0.000000                 0                 0   \n",
       "9            0.000000           0.000000                 0                 0   \n",
       "10           0.000000           0.000000                 0                 0   \n",
       "11           0.000000           0.000000                 0                 0   \n",
       "12           0.000000           0.000000                 0                 0   \n",
       "13           0.000000           0.000000                 0                 0   \n",
       "14           0.000000           0.000000                 0                 0   \n",
       "15           0.008018           0.000000                 0                 0   \n",
       "16           0.000000           0.000000                 0                 0   \n",
       "17           0.000000           0.000000                 0                 0   \n",
       "18           0.000000           0.000000                 0                 0   \n",
       "19           0.026316           0.000000                 0                 0   \n",
       "20           0.000000           0.000000                 0                 0   \n",
       "21           0.001347           0.000049                 0                 0   \n",
       "22           0.000000           0.000000                 0                 0   \n",
       "23           0.000000           0.000000                 0                 0   \n",
       "24           0.000000           0.000000                 0                 0   \n",
       "25           0.000000           0.000000                 0                 0   \n",
       "26           0.000000           0.000000                 0                 0   \n",
       "27           0.000000           0.000000                 0                 0   \n",
       "28           0.000000           0.000000                 0                 0   \n",
       "29           0.000000           0.000000                 0                 0   \n",
       "..                ...                ...               ...               ...   \n",
       "70           0.000000           0.000000                 0                 0   \n",
       "71           0.000000           0.000000                 0                 0   \n",
       "72           0.000000           0.000000                 0                 0   \n",
       "73           0.000000           0.000000                 0                 0   \n",
       "74           0.000000           0.000000                 0                 0   \n",
       "75           0.016000           0.000000                 0                 0   \n",
       "76           0.000000           0.000000                 0                 0   \n",
       "77           0.000000           0.000000                 0                 0   \n",
       "78           0.000000           0.000000                 0                 0   \n",
       "79           0.000000           0.000000                 0                 0   \n",
       "80           0.000000           0.000000                 0                 0   \n",
       "81           0.000000           0.000000                 0                 0   \n",
       "82           0.028249           0.000000                 0                 0   \n",
       "83           0.000000           0.000000                 0                 0   \n",
       "84           0.000000           0.000000                 0                 0   \n",
       "85           0.000000           0.000000                 0                 0   \n",
       "86           0.000000           0.000000                 0                 0   \n",
       "87           0.014905           0.000000                 0                 0   \n",
       "88           0.000000           0.000000                 0                 0   \n",
       "89           0.000000           0.006726                 0                 0   \n",
       "90           0.000000           0.000000                 0                 0   \n",
       "91           0.049632           0.000000                 0                 0   \n",
       "92           0.000000           0.000000                 0                 0   \n",
       "93           0.041667           0.000000                 0                 0   \n",
       "94           0.000000           0.004444                 0                 0   \n",
       "95           0.000000           0.000000                 0                 0   \n",
       "96           0.153627           0.000000                 0                 0   \n",
       "97           0.006164           0.000061                 0                 0   \n",
       "98           0.000000           0.000000                 0                 0   \n",
       "99           0.021978           0.002433                 0                 0   \n",
       "\n",
       "    num_followers_s  num_followers_d  num_followees_s  num_followees_d  \\\n",
       "0                 0                0                0                0   \n",
       "1                 0                0                0                0   \n",
       "2                 0                0                0                0   \n",
       "3                 0                0                0                0   \n",
       "4                 0                0                0                0   \n",
       "5                 0                0                0                0   \n",
       "6                 0                0                0                0   \n",
       "7                 0                0                0                0   \n",
       "8                 0                0                0                0   \n",
       "9                 0                0                0                0   \n",
       "10                0                0                0                0   \n",
       "11                0                0                0                0   \n",
       "12                0                0                0                0   \n",
       "13                0                0                0                0   \n",
       "14                0                0                0                0   \n",
       "15                0                0                0                0   \n",
       "16                0                0                0                0   \n",
       "17                0                0                0                0   \n",
       "18                0                0                0                0   \n",
       "19                0                0                0                0   \n",
       "20                0                0                0                0   \n",
       "21                0                0                0                0   \n",
       "22                0                0                0                0   \n",
       "23                0                0                0                0   \n",
       "24                0                0                0                0   \n",
       "25                0                0                0                0   \n",
       "26                0                0                0                0   \n",
       "27                0                0                0                0   \n",
       "28                0                0                0                0   \n",
       "29                0                0                0                0   \n",
       "..              ...              ...              ...              ...   \n",
       "70                0                0                0                0   \n",
       "71                0                0                0                0   \n",
       "72                0                0                0                0   \n",
       "73                0                0                0                0   \n",
       "74                0                0                0                0   \n",
       "75                0                0                0                0   \n",
       "76                0                0                0                0   \n",
       "77                0                0                0                0   \n",
       "78                0                0                0                0   \n",
       "79                0                0                0                0   \n",
       "80                0                0                0                0   \n",
       "81                0                0                0                0   \n",
       "82               19               19                0                0   \n",
       "83                0                0                0                0   \n",
       "84                0                0                0                0   \n",
       "85                0                0                0                0   \n",
       "86                6                6                0                0   \n",
       "87                9                9                0                0   \n",
       "88                0                0                0                0   \n",
       "89                0                0                0                0   \n",
       "90                0                0                0                0   \n",
       "91               68               68                0                0   \n",
       "92                0                0                0                0   \n",
       "93                0                0                0                0   \n",
       "94               27               27               85               85   \n",
       "95                0                0                0                0   \n",
       "96               41               41                0                0   \n",
       "97                0                0                0                0   \n",
       "98                0                0                0                0   \n",
       "99                0                0                0                0   \n",
       "\n",
       "    inter_followers  inter_followees  shortest_path  \n",
       "0                 0                0              4  \n",
       "1                 0                0              3  \n",
       "2                 0                0              2  \n",
       "3                 0                0              2  \n",
       "4                 0                0              3  \n",
       "5                 0                0              4  \n",
       "6                 0                0              2  \n",
       "7                 0                0              3  \n",
       "8                 0                0              3  \n",
       "9                 0                0              3  \n",
       "10                0                0              3  \n",
       "11                0                0              3  \n",
       "12                0                0              2  \n",
       "13                0                0             -1  \n",
       "14                0                0              3  \n",
       "15                0                0              2  \n",
       "16                0                0              2  \n",
       "17                0                0              4  \n",
       "18                0                0              3  \n",
       "19                0                0              2  \n",
       "20                0                0              5  \n",
       "21                0                0              2  \n",
       "22                0                0              3  \n",
       "23                0                0              4  \n",
       "24                0                0              2  \n",
       "25                0                0              3  \n",
       "26                0                0              4  \n",
       "27                0                0              3  \n",
       "28                0                0              3  \n",
       "29                0                0              3  \n",
       "..              ...              ...            ...  \n",
       "70                0                0              2  \n",
       "71                0                0              3  \n",
       "72                0                0              3  \n",
       "73                0                0              2  \n",
       "74                0                0              3  \n",
       "75                0                0              2  \n",
       "76                0                0              4  \n",
       "77                0                0              2  \n",
       "78                0                0              2  \n",
       "79                0                0              3  \n",
       "80                0                0              4  \n",
       "81                0                0              3  \n",
       "82               19                0              2  \n",
       "83                0                0              2  \n",
       "84                0                0              3  \n",
       "85                0                0              2  \n",
       "86                6                0              3  \n",
       "87                9                0              2  \n",
       "88                0                0              3  \n",
       "89                0                0              2  \n",
       "90                0                0              4  \n",
       "91               68                0              2  \n",
       "92                0                0              3  \n",
       "93                0                0              2  \n",
       "94               27               85              2  \n",
       "95                0                0              3  \n",
       "96               41                0              2  \n",
       "97                0                0              2  \n",
       "98                0                0              4  \n",
       "99                0                0              2  \n",
       "\n",
       "[100 rows x 11 columns]"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_sub.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_sub = rf_clf.predict_proba(X_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.14431031, 0.85568969],\n",
       "       [0.14431031, 0.85568969],\n",
       "       [0.14431031, 0.85568969],\n",
       "       ...,\n",
       "       [0.14431031, 0.85568969],\n",
       "       [0.14431031, 0.85568969],\n",
       "       [0.14431031, 0.85568969]])"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1974.0"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(lr_clf.predict(X_sub))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 11 features per sample; expecting 22",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-297-96fa84bbd821>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvoting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_sub\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/voting.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'estimators_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvoting\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'soft'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m             \u001b[0mmaj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# 'hard' voting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/voting.py\u001b[0m in \u001b[0;36m_predict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    318\u001b[0m                                  \" voting=%r\" % self.voting)\n\u001b[1;32m    319\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'estimators_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m         avg = np.average(self._collect_probas(X), axis=0,\n\u001b[0m\u001b[1;32m    321\u001b[0m                          weights=self._weights_not_none)\n\u001b[1;32m    322\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mavg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/voting.py\u001b[0m in \u001b[0;36m_collect_probas\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_collect_probas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m         \u001b[0;34m\"\"\"Collect results from clf.predict calls. \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_predict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/voting.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_collect_probas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m         \u001b[0;34m\"\"\"Collect results from clf.predict calls. \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_predict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1652\u001b[0m                                                 self.solver == 'liblinear')))\n\u001b[1;32m   1653\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0movr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1654\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict_proba_lr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1655\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1656\u001b[0m             \u001b[0mdecision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/base.py\u001b[0m in \u001b[0;36m_predict_proba_lr\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[0mmulticlass\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mhandled\u001b[0m \u001b[0mby\u001b[0m \u001b[0mnormalizing\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mover\u001b[0m \u001b[0mall\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m         \"\"\"\n\u001b[0;32m--> 303\u001b[0;31m         \u001b[0mprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    304\u001b[0m         \u001b[0mexpit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m             raise ValueError(\"X has %d features per sample; expecting %d\"\n\u001b[0;32m--> 270\u001b[0;31m                              % (X.shape[1], n_features))\n\u001b[0m\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m         scores = safe_sparse_dot(X, self.coef_.T,\n",
      "\u001b[0;31mValueError\u001b[0m: X has 11 features per sample; expecting 22"
     ]
    }
   ],
   "source": [
    "voting.predict(X_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(data={\"Id\":range(1,len(y_sub)+1), \"Predicted\":[x[1] for x in y_sub]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('submissioin_all_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
