{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import pickle\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df(filename=\"train.txt\"):\n",
    "    data = {'Source':[], 'Sink':[]}\n",
    "    with open(filename, \"r\") as f:\n",
    "        for raw_line in f:\n",
    "            line = raw_line.strip().split(\"\\t\")\n",
    "            data['Source'] += [line[0]]*(len(line)-1)\n",
    "            data['Sink'] += line[1:]\n",
    "    pd_data = pd.DataFrame(data=data)\n",
    "    pd_data[['Source', 'Sink']] = pd_data[['Source', 'Sink']].apply(pd.to_numeric)\n",
    "    pd_data = pd_data.drop_duplicates(keep=False)\n",
    "    return pd_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_sub():\n",
    "    with open('test-public.txt', 'r') as f:\n",
    "        # skip the header\n",
    "        f.readline()\n",
    "        data = {'Source':[], 'Sink':[]}\n",
    "        for raw_line in f:\n",
    "            line = raw_line.strip().split(\"\\t\")\n",
    "            data['Source'].append(int(line[1]))\n",
    "            data['Sink'].append(int(line[2]))\n",
    "        return pd.DataFrame(data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = create_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23888876, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"to_processed_train.csv\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: \n",
      "Type: Graph\n",
      "Number of nodes: 4842581\n",
      "Number of edges: 23358551\n",
      "Average degree:   9.6471\n"
     ]
    }
   ],
   "source": [
    "G = nx.read_edgelist('to_processed_train.csv',delimiter=',',create_using=nx.Graph(),nodetype=int)\n",
    "print(nx.info(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = nx.read_edgelist('processed_train.csv',delimiter=',',create_using=nx.DiGraph(),nodetype=int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: \n",
      "Type: DiGraph\n",
      "Number of nodes: 3084179\n",
      "Number of edges: 8350000\n",
      "Average in degree:   2.7074\n",
      "Average out degree:   2.7074\n"
     ]
    }
   ],
   "source": [
    "print(nx.info(g))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"new_data/train-mix.p\", \"rb\") as f:\n",
    "    train_mix = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "link = [[i[1], i[2]] for i in train_mix]\n",
    "label = [i[3] for i in train_mix]\n",
    "X_desire_train, X_desire_test, y_desire_train, y_desire_test = train_test_split(link, label, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16000 16000 4000 4000\n"
     ]
    }
   ],
   "source": [
    "print(len(X_desire_train), len(y_desire_train), len(X_desire_test), len(y_desire_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Sink</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1655093</td>\n",
       "      <td>812186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3974423</td>\n",
       "      <td>3289673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3848803</td>\n",
       "      <td>4263818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4382293</td>\n",
       "      <td>2614161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2497970</td>\n",
       "      <td>4539763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>646475</td>\n",
       "      <td>1640325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>1591102</td>\n",
       "      <td>351452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>1669475</td>\n",
       "      <td>4624407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>3466523</td>\n",
       "      <td>3765415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>1677231</td>\n",
       "      <td>1025673</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Source     Sink\n",
       "0     1655093   812186\n",
       "1     3974423  3289673\n",
       "2     3848803  4263818\n",
       "3     4382293  2614161\n",
       "4     2497970  4539763\n",
       "...       ...      ...\n",
       "3995   646475  1640325\n",
       "3996  1591102   351452\n",
       "3997  1669475  4624407\n",
       "3998  3466523  3765415\n",
       "3999  1677231  1025673\n",
       "\n",
       "[4000 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_features = pd.DataFrame()\n",
    "X_test_features = pd.DataFrame()\n",
    "X_desire_train = pd.DataFrame(X_desire_train, columns=['Source', 'Sink'])\n",
    "X_desire_test = pd.DataFrame(X_desire_test, columns=['Source', 'Sink'])\n",
    "X_desire_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(2712039, 218222): 0.48248525325073366,\n",
       " (3296670, 3092525): 0.06423439460626545,\n",
       " (1569537, 281790): 0.1881782469302815,\n",
       " (3750582, 528038): 0.06808569838994395,\n",
       " (3253990, 3008062): 0.14736310918744813,\n",
       " (4126485, 2978899): 0.017931948989144783,\n",
       " (2353654, 1863046): 0.25851310324167864,\n",
       " (1227313, 109141): 0.1623700001988141,\n",
       " (685695, 2410046): 0.2768087433726595,\n",
       " (3262992, 2677316): 0.03367833706857019,\n",
       " (2323088, 2309976): 0.09396398230865341,\n",
       " (2466503, 4800253): 0.014925967280514044,\n",
       " (878044, 2541835): 0.0,\n",
       " (4672710, 3783690): 0.0007120511703484632,\n",
       " (2806975, 1202129): 0.04558103047994419,\n",
       " (3079468, 3325422): 0.0,\n",
       " (10090, 545853): 0.0,\n",
       " (4550069, 3248447): 0.0,\n",
       " (4786270, 3205531): 0.02025670009319049,\n",
       " (2198488, 1971518): 0.19662171063331382,\n",
       " (3063001, 1659272): 0.0,\n",
       " (3869033, 2572933): 0.34671057824608065,\n",
       " (1896126, 2402775): 0.07933180134909378,\n",
       " (3063973, 1380739): 0.17817532123357485,\n",
       " (3228493, 1304921): 0.0,\n",
       " (3545321, 3708550): 0.06866532857850899,\n",
       " (1550614, 2349803): 0.010293583715766382,\n",
       " (2052207, 2055238): 0.3267856517048452,\n",
       " (2360726, 3050762): 0.11808636819001554,\n",
       " (4749438, 4346941): 0.22022630744011137,\n",
       " (2595454, 1577010): 0.30464330316379,\n",
       " (4696379, 428622): 0.2285678072411286,\n",
       " (4559284, 3591170): 0.033967970821971914,\n",
       " (325545, 803867): 0.2357097751165964,\n",
       " (1548012, 1298591): 0.38809100615821285,\n",
       " (100639, 3143645): 0.1138907371853154,\n",
       " (4114881, 2871646): 0.09955237406423625,\n",
       " (2876743, 807559): 0.0,\n",
       " (4515999, 3607613): 0.07758514944580866,\n",
       " (1192930, 974940): 0.0066340307156979835,\n",
       " (3764262, 2425664): 0.1797123832006996,\n",
       " (664929, 3323416): 0.009902363474399318,\n",
       " (3082645, 3806368): 0.31355886923588694,\n",
       " (1983211, 243063): 0.3016528625320593,\n",
       " (3896176, 2201609): 0.4424491412118933,\n",
       " (4504242, 368295): 0.0822197229765233,\n",
       " (2340628, 682428): 0.4047557235200707,\n",
       " (858760, 4100269): 0.0,\n",
       " (738642, 1262811): 0.0,\n",
       " (3991826, 1270191): 0.04831612929229921,\n",
       " (910449, 3683087): 0.0,\n",
       " (2817995, 2305236): 0.014880716823983607,\n",
       " (96454, 3546780): 0.03663045917134581,\n",
       " (3449911, 1569677): 0.05636836811395511,\n",
       " (2235511, 3421387): 0.011695959054698384,\n",
       " (3541291, 2870635): 0.0838690249104385,\n",
       " (1796453, 3064823): 0.00022461073762612227,\n",
       " (4563998, 4588237): 0.08172632417759607,\n",
       " (2480191, 356075): 0.01215897436719315,\n",
       " (141109, 431846): 0.14993949920581784,\n",
       " (2927288, 2072911): 0.18867611023589598,\n",
       " (3868073, 4858318): 0.1597023918162122,\n",
       " (2523384, 4663715): 0.0,\n",
       " (227767, 158839): 0.0,\n",
       " (828134, 4128172): 0.13100491243186757,\n",
       " (2290838, 2236408): 0.4723564494344538,\n",
       " (111846, 342360): 0.0051345285663616565,\n",
       " (1858539, 3115802): 0.30561792872655735,\n",
       " (4845206, 4657888): 0.24364309632448594,\n",
       " (2831778, 1849930): 0.003261296074302345,\n",
       " (2056790, 3584489): 0.3695948788754326,\n",
       " (4466614, 2876919): 0.0,\n",
       " (2249093, 4228143): 0.2767927985997889,\n",
       " (4688495, 3665764): 0.013392041954893082,\n",
       " (3710532, 3174430): 0.10442584751047138,\n",
       " (1855133, 1506995): 0.03999466590732194,\n",
       " (661981, 1060603): 0.0,\n",
       " (348913, 4753948): 0.25714814879949727,\n",
       " (3830515, 1520075): 0.28244065283576353,\n",
       " (3894464, 1434512): 0.19334326615532785,\n",
       " (4628214, 1446824): 0.07299649143856342,\n",
       " (1248469, 3976845): 0.024501328719275763,\n",
       " (2261361, 2305236): 0.008263959356158123,\n",
       " (1715863, 478620): 0.029874994582536275,\n",
       " (3958979, 2846594): 0.156260089294151,\n",
       " (3188415, 2241399): 0.005982786573440441,\n",
       " (1377457, 660442): 0.06689114922661749,\n",
       " (4126094, 174993): 0.022778829920228248,\n",
       " (964645, 2502874): 0.0,\n",
       " (519265, 3644915): 0.14506600169609635,\n",
       " (2132225, 3546338): 0.06603331715069263,\n",
       " (4494198, 3468090): 0.23848322544260941,\n",
       " (862958, 1117004): 0.02571712316480197,\n",
       " (4535241, 3207182): 0.12318801093551476,\n",
       " (4704619, 3441326): 0.34126701078187516,\n",
       " (2870581, 2498565): 0.1735694588309202,\n",
       " (721058, 159304): 0.0006695761977660286,\n",
       " (1785168, 558447): 0.3788030257733398,\n",
       " (3041732, 411381): 0.5517821235416585,\n",
       " (931276, 4438922): 0.11880663562242667,\n",
       " (1149494, 4238657): 0.2430497232772191,\n",
       " (948375, 4539182): 0.17187276989736697,\n",
       " (3964281, 649773): 0.39703180299252705,\n",
       " (1183989, 4512746): 0.32943319438591395,\n",
       " (4122296, 1012912): 0.09140883779194102,\n",
       " (4664934, 4590696): 0.4678929563582012,\n",
       " (2636494, 2882867): 0.0,\n",
       " (4036898, 2334352): 0.09280659423093163,\n",
       " (3702505, 4287053): 0.0,\n",
       " (4030539, 354904): 0.26155875181843236,\n",
       " (3193509, 3415302): 0.2104636051865533,\n",
       " (1849859, 1143064): 0.5708430468593709,\n",
       " (3939453, 612137): 0.4341483615998537,\n",
       " (1968010, 761882): 0.09950022729517899,\n",
       " (1277656, 1637866): 0.2602969438925558,\n",
       " (3738041, 1863473): 0.11363540400864407,\n",
       " (4477971, 2889351): 0.24739426555732177,\n",
       " (1144424, 2938082): 0.0,\n",
       " (1205985, 3596031): 0.017871644501179264,\n",
       " (3438895, 2381484): 0.07839118578927455,\n",
       " (2947681, 1259739): 0.37182980877998145,\n",
       " (370461, 1502188): 0.23301338864436416,\n",
       " (3719447, 489020): 0.09011391495756227,\n",
       " (2745713, 4688624): 0.00483627517646972,\n",
       " (1027375, 498731): 0.7959826591151409,\n",
       " (3289311, 3452465): 0.1466562530648209,\n",
       " (2731550, 2723775): 0.24887262702889382,\n",
       " (271405, 426698): 0.07234171657187462,\n",
       " (1854367, 611061): 0.0,\n",
       " (3997113, 3032851): 0.08922678418942692,\n",
       " (34959, 4079721): 0.10118291330040471,\n",
       " (2816061, 2650856): 0.0006367965744885306,\n",
       " (1475692, 3473360): 0.7309313570384888,\n",
       " (3675752, 1868981): 0.2876760128159357,\n",
       " (4452758, 1885679): 0.020267600038139443,\n",
       " (4524886, 2132264): 0.03409075473777242,\n",
       " (3430861, 956200): 0.3989065039390294,\n",
       " (3138039, 532681): 0.1757688085475916,\n",
       " (4406687, 1943495): 0.1974475196762428,\n",
       " (4581618, 2809671): 0.7381028857008661,\n",
       " (344933, 1659017): 0.49083535613180046,\n",
       " (3768366, 585432): 0.1437959854294221,\n",
       " (3337206, 1108647): 0.024298723451242614,\n",
       " (664229, 193201): 0.0,\n",
       " (3301573, 3676786): 0.0676558548293361,\n",
       " (1440188, 8009): 0.13644579330607942,\n",
       " (209406, 1150006): 0.01542223342654584,\n",
       " (3338112, 810989): 0.15603968705799792,\n",
       " (3562014, 3517211): 0.21384393498269155,\n",
       " (4721904, 4482910): 0.11082039344393821,\n",
       " (1434628, 2053601): 0.0,\n",
       " (3674727, 1365101): 0.016321278551943392,\n",
       " (636238, 1965119): 0.0,\n",
       " (757158, 1257475): 0.09355350292571077,\n",
       " (2895783, 3220070): 0.14535413178801543,\n",
       " (2418923, 3420953): 0.14023306201122698,\n",
       " (2557201, 4382821): 0.09926158569727149,\n",
       " (3999324, 2318728): 0.0578655140813984,\n",
       " (3086050, 3468711): 0.08120158649298272,\n",
       " (3530488, 2609786): 0.01888579544305422,\n",
       " (2822272, 3361377): 0.13863076157098495,\n",
       " (774332, 2890514): 0.24491162635883465,\n",
       " (2094874, 2635670): 0.2874692261423004,\n",
       " (320791, 3638272): 0.11547803503572275,\n",
       " (2005731, 4183784): 0.4690802593594581,\n",
       " (791133, 1516853): 0.3204180142874729,\n",
       " (1136748, 2508204): 0.017312296659407218,\n",
       " (636814, 572045): 0.2580619924852232,\n",
       " (1341129, 3906058): 0.02828966820715615,\n",
       " (4104749, 492529): 0.006909778077022911,\n",
       " (953685, 4853234): 0.17997377390697522,\n",
       " (331680, 1773106): 0.0156333908691606,\n",
       " (3750005, 3494785): 0.042387184053157,\n",
       " (3849956, 151400): 0.007053331654213128,\n",
       " (1769172, 3595339): 0.04957695597232398,\n",
       " (4149007, 277940): 0.46123695260069164,\n",
       " (544337, 4064111): 0.08791375728979105,\n",
       " (990798, 1590102): 0.33027867210422945,\n",
       " (1532833, 841970): 0.2851739965595021,\n",
       " (1735116, 4482044): 0.5573058388394638,\n",
       " (2679186, 3798753): 0.10920393761939909,\n",
       " (548444, 2720793): 0.10107091685249106,\n",
       " (2745294, 972718): 0.22899639784622214,\n",
       " (1450580, 2398454): 0.0684074460351451,\n",
       " (2427458, 3644561): 0.04665368619563201,\n",
       " (1538119, 644454): 0.0,\n",
       " (3542727, 4051480): 0.17406869124686514,\n",
       " (1621495, 1637631): 0.24584327409578655,\n",
       " (276502, 20142): 0.3855241239097091,\n",
       " (1824229, 4023353): 0.27734217793749244,\n",
       " (3534145, 2841692): 0.00019878931177944866,\n",
       " (41381, 4042849): 0.043301424681327,\n",
       " (529610, 4651870): 0.43134255949670364,\n",
       " (1859935, 2098014): 0.18876884399869256,\n",
       " (3103500, 1536879): 0.1830853779750587,\n",
       " (4396708, 703635): 0.07471173402410922,\n",
       " (3025589, 460427): 0.013315542538282115,\n",
       " (1603718, 2119741): 0.0,\n",
       " (2405987, 308675): 0.08603509884936576,\n",
       " (2732741, 4448289): 0.15907542508235187,\n",
       " (2305776, 3361377): 0.11144319840710368,\n",
       " (2698027, 3499646): 0.19115676239113635,\n",
       " (306486, 3379951): 0.00125441074571501,\n",
       " (283814, 2879491): 0.032651559408049674,\n",
       " (2169091, 1135276): 0.07468150042769185,\n",
       " (4107699, 2339156): 0.1999392638815946,\n",
       " (4067167, 4801349): 0.0,\n",
       " (2823179, 4043655): 0.40114747684845764,\n",
       " (648920, 2030613): 0.5220134494855913,\n",
       " (3933749, 2154287): 0.4213690449600518,\n",
       " (1363650, 19486): 0.04776544946102422,\n",
       " (3169810, 3187980): 0.0,\n",
       " (2119707, 4558297): 0.4174090076891599,\n",
       " (4246803, 1893694): 0.11180339887498948,\n",
       " (2598661, 1662597): 0.05242753008440362,\n",
       " (3597029, 230371): 0.07623273330369998,\n",
       " (790034, 2183241): 0.03174663747539133,\n",
       " (3412320, 2310300): 0.34696495273647193,\n",
       " (1108996, 3315242): 0.006427565733170043,\n",
       " (2931617, 2822869): 0.0,\n",
       " (4526466, 2500921): 0.34657186269386464,\n",
       " (3549558, 3454887): 0.128743113306112,\n",
       " (4318559, 2709048): 0.05317417298545356,\n",
       " (2001034, 3694133): 0.0,\n",
       " (4382293, 3106083): 0.003978003237619408,\n",
       " (87671, 2486871): 0.1369025422211316,\n",
       " (905589, 65503): 0.017728348484481453,\n",
       " (3663048, 399114): 0.17332401068359538,\n",
       " (3612075, 1881676): 0.021794087541918958,\n",
       " (211698, 3130534): 0.18116158105886865,\n",
       " (1400189, 1116087): 0.08997286651331657,\n",
       " (174919, 1239603): 0.012282050258733567,\n",
       " (502123, 1947032): 0.039950240633502956,\n",
       " (2280871, 4604510): 0.04517613981025188,\n",
       " (4807007, 1454832): 0.07960086714004683,\n",
       " (904266, 3433117): 0.32779889171941146,\n",
       " (3572035, 4367399): 0.01566802949499457,\n",
       " (4283503, 1501807): 0.26177309071416344,\n",
       " (2014013, 1904026): 0.020882597738469722,\n",
       " (3835444, 1423665): 0.0006319554233095167,\n",
       " (3240200, 4510121): 0.4268163092725502,\n",
       " (2404411, 4737915): 0.11438669220779525,\n",
       " (3913728, 3268825): 0.0,\n",
       " (2735008, 60764): 0.0,\n",
       " (744963, 3138602): 0.02225044832203062,\n",
       " (154018, 4591592): 0.20985583572374844,\n",
       " (2214183, 3556708): 0.09930329641669346,\n",
       " (3560665, 4353566): 0.1932070503589689,\n",
       " (2798422, 3178986): 0.05633561933449674,\n",
       " (3415302, 4184215): 0.4479635113525395,\n",
       " (2499945, 2727221): 0.07478081233843976,\n",
       " (1398781, 4192795): 0.019830531745894248,\n",
       " (4256729, 2361238): 0.12688590439064693,\n",
       " (4204066, 1619546): 0.1304686163512766,\n",
       " (2439328, 687777): 0.19522251465951057,\n",
       " (1001107, 2261703): 0.017220132949127227,\n",
       " (562587, 1870064): 0.046665498875300165,\n",
       " (3024475, 2851690): 0.19765102573170454,\n",
       " (3157597, 2541906): 0.5486061612766754,\n",
       " (4579906, 1640481): 0.06958435907958783,\n",
       " (3153229, 958397): 0.3942824489290297,\n",
       " (3643389, 3889343): 0.058877089824988536,\n",
       " (4421155, 1285506): 0.06263739309263755,\n",
       " (3750964, 51940): 0.2512311102274462,\n",
       " (2782196, 1171914): 0.3500094740592467,\n",
       " (3768601, 1716351): 0.32427098522378095,\n",
       " (128346, 1786214): 0.25536254984543494,\n",
       " (2400396, 4286305): 0.0970228105997437,\n",
       " (3135952, 3016443): 0.059487838100473804,\n",
       " (429180, 978816): 0.3415615919126168,\n",
       " (3788402, 986064): 0.13018455445512112,\n",
       " (2102496, 2841640): 0.22315586660036474,\n",
       " (4006577, 3140859): 0.07485190888920942,\n",
       " (4011873, 4404409): 0.06144714520424435,\n",
       " (1378976, 275550): 0.01519223590853219,\n",
       " (4357934, 582589): 0.08690477494447683,\n",
       " (4219851, 1846393): 0.0026967545101479907,\n",
       " (4819999, 3294915): 0.415728591018497,\n",
       " (3805937, 71463): 0.0,\n",
       " (2797039, 2635539): 0.1361474738049236,\n",
       " (4130935, 4086085): 0.17237155747989388,\n",
       " (1916291, 3085172): 0.02573224165710171,\n",
       " (1702465, 3294477): 0.24392194582214197,\n",
       " (1130891, 3794253): 0.08086852115330405,\n",
       " (4372315, 4427690): 0.07183794092252455,\n",
       " (2289911, 4408067): 0.0633100159766566,\n",
       " (445900, 4054310): 0.09714699133881002,\n",
       " (184734, 2075254): 0.34857353108694406,\n",
       " (1917899, 4196604): 0.22650095309654353,\n",
       " (554693, 3888666): 0.16513410920856786,\n",
       " (2120963, 4738096): 0.3567038176722061,\n",
       " (704605, 4190014): 0.417006520945655,\n",
       " (4293257, 4034783): 0.0,\n",
       " (2784572, 3681348): 0.27358221961912754,\n",
       " (2843837, 1859013): 0.005102181418202708,\n",
       " (10760, 74464): 0.3140412659551902,\n",
       " (359005, 2921313): 0.04660688885988703,\n",
       " (1580988, 151067): 0.052123521181711374,\n",
       " (4734055, 2412735): 0.10253005060643192,\n",
       " (609071, 3521825): 0.00479637539980382,\n",
       " (276502, 2788886): 0.0932701543879481,\n",
       " (836970, 1551315): 0.3356104726067862,\n",
       " (1380763, 1607274): 0.09372860333599278,\n",
       " (10760, 4476321): 0.11390972663697778,\n",
       " (537144, 46961): 0.11919191784267703,\n",
       " (4517979, 1965202): 0.003083510018276406,\n",
       " (4052781, 854252): 0.0,\n",
       " (435601, 1412124): 0.08115666555176912,\n",
       " (1054833, 769539): 0.6549128070238229,\n",
       " (3315192, 643713): 0.02240059752522819,\n",
       " (3389066, 4199055): 0.2254470228051886,\n",
       " (4331537, 4629010): 0.0,\n",
       " (3433344, 643394): 0.02290117660864042,\n",
       " (800218, 2519795): 0.09228087481979272,\n",
       " (1830324, 2337656): 0.053975441697387765,\n",
       " (2798710, 417121): 0.0,\n",
       " (848387, 1739703): 0.1720400633367876,\n",
       " (4615258, 1024144): 0.3963063773102768,\n",
       " (1516853, 933542): 0.15474817057917423,\n",
       " (3568594, 335244): 0.13720008547389087,\n",
       " (245479, 2023721): 0.23868660925921445,\n",
       " (4164891, 2339186): 0.002464996346777404,\n",
       " (1271555, 442085): 0.026771552199738667,\n",
       " (4591147, 856430): 0.03732308295482603,\n",
       " (526124, 2291110): 0.0,\n",
       " (2358233, 2066264): 0.0884742432259223,\n",
       " (3655780, 237454): 0.26830339574087486,\n",
       " (708118, 3278543): 0.3063744982473333,\n",
       " (18535, 4778345): 0.5307400009476391,\n",
       " (567581, 3647183): 0.0,\n",
       " (1953803, 3518924): 0.0,\n",
       " (525299, 468317): 0.42422967949851587,\n",
       " (366638, 4259455): 0.21316339795456765,\n",
       " (4649465, 4195362): 0.07460543223854531,\n",
       " (2111786, 4694487): 0.002190113435458956,\n",
       " (1340835, 3104446): 0.4177915358107829,\n",
       " (1613971, 4027429): 0.2861968780170854,\n",
       " (188824, 4406363): 0.0,\n",
       " (3302125, 967833): 0.1892035640991731,\n",
       " (735443, 2781648): 0.03914533871665728,\n",
       " (4693927, 3387774): 0.3718072563310726,\n",
       " (3502422, 452542): 0.0,\n",
       " (788982, 4861862): 0.003351503034505558,\n",
       " (2031699, 1713769): 0.20664855361645756,\n",
       " (3881953, 3937176): 0.10548838682157938,\n",
       " (4243769, 2433251): 0.08511419865600106,\n",
       " (2568123, 173316): 0.27869305976113223,\n",
       " (487430, 4291867): 0.0,\n",
       " (415955, 1716140): 0.05472254552269818,\n",
       " (2976362, 1260504): 0.04859986359237025,\n",
       " (3657859, 31748): 0.22804633402309388,\n",
       " (3444248, 2341514): 0.019365933204102955,\n",
       " (1064989, 3658342): 0.2567650766014453,\n",
       " (3658381, 1064609): 0.22111334660465604,\n",
       " (944927, 856483): 0.0,\n",
       " (1518778, 4791638): 0.08128622598963867,\n",
       " (3422787, 3490423): 0.0004674871249279836,\n",
       " (3344330, 4207203): 0.6751441243721559,\n",
       " (3036800, 21214): 0.04179324201951655,\n",
       " (3887538, 1001400): 0.09883443000417232,\n",
       " (4231768, 3711670): 0.26733809157225047,\n",
       " (487430, 432595): 0.06446595576553338,\n",
       " (1564140, 2796902): 0.005989342993980965,\n",
       " (3582815, 2192473): 0.006698807316533316,\n",
       " (2198862, 4814130): 0.05471100885362926,\n",
       " (4827780, 1406960): 0.10552985278198934,\n",
       " (3171852, 2399106): 0.38029579327407514,\n",
       " (3804962, 185896): 0.12701428094995862,\n",
       " (2940588, 4816073): 0.0,\n",
       " (3656459, 4556517): 0.04602617107863141,\n",
       " (3124755, 873482): 0.07351809986520974,\n",
       " (573715, 503182): 0.04616824296071157,\n",
       " (3072924, 3724421): 0.5329466466178935,\n",
       " (2106653, 1524486): 0.3842852670892554,\n",
       " (2998788, 3754296): 0.1445063387631104,\n",
       " (24581, 3481448): 0.20607903347812223,\n",
       " (1128304, 1601983): 0.046381583483584246,\n",
       " (3138162, 3871692): 0.0654548837599659,\n",
       " (3559385, 2737018): 0.15388282280988297,\n",
       " (3537558, 254928): 0.0448819509611737,\n",
       " (4024076, 4326109): 0.13038144069325414,\n",
       " (3937562, 3641133): 0.335124703090237,\n",
       " (3993347, 29521): 0.4928050273237485,\n",
       " (1739906, 321360): 0.0,\n",
       " (2454128, 3076728): 0.14100737400293142,\n",
       " (2723674, 1107850): 0.056157322519703984,\n",
       " (4229194, 2361442): 0.0007267639577990564,\n",
       " (2692967, 84235): 0.09949415829629492,\n",
       " (1452488, 3402731): 0.09810943233357616,\n",
       " (283907, 2137758): 0.019224678464444558,\n",
       " (4429303, 4089788): 0.064717543938779,\n",
       " (1495135, 33041): 0.03730890394494082,\n",
       " (3837805, 1444218): 0.09829457177273168,\n",
       " (3337583, 3230065): 0.09027800815171488,\n",
       " (1209329, 3860382): 0.1811020282863494,\n",
       " (3305012, 4407107): 0.0027892926647512376,\n",
       " (1037166, 4428619): 0.14495161855183744,\n",
       " (2144252, 530491): 0.3239728350377449,\n",
       " (1354327, 4327061): 0.052294960223184826,\n",
       " (948581, 3189389): 0.13747191095192496,\n",
       " (226040, 3562222): 0.003546220701216887,\n",
       " (3102854, 1113234): 0.17384742289637245,\n",
       " (3169539, 3098037): 0.0,\n",
       " (3949998, 3084181): 0.0,\n",
       " (1156616, 1434943): 0.20627145275350056,\n",
       " (276263, 4434192): 0.6024139858035102,\n",
       " (2426592, 3288594): 0.07547201692447966,\n",
       " (1923250, 2455051): 0.18643821275081382,\n",
       " (2287051, 1399036): 0.021110206604425703,\n",
       " (1934306, 1613948): 0.4714045207910316,\n",
       " (154306, 2753860): 0.1368603511833683,\n",
       " (4488963, 2294164): 0.09018894882472343,\n",
       " (30224, 3805395): 0.005424118101053041,\n",
       " (3585026, 84957): 0.007484499592006706,\n",
       " (1447717, 1677406): 0.18025588972675793,\n",
       " (1957489, 1064609): 0.20838599824219659,\n",
       " (767491, 3170426): 0.07079400678733072,\n",
       " (4157653, 414356): 0.39845778041218693,\n",
       " (3845119, 259566): 0.18605224810757734,\n",
       " (2361283, 1101129): 0.06484838582887706,\n",
       " (4593929, 4349502): 0.021912832689300728,\n",
       " (1281156, 4588546): 0.01272376940016832,\n",
       " (3063587, 3048500): 0.25660579290813457,\n",
       " (83832, 2646157): 0.017162291209541707,\n",
       " (4463084, 3031742): 0.0016775167668491105,\n",
       " (2849535, 2611346): 0.014975964297310934,\n",
       " (1545237, 4713233): 0.5993507099270231,\n",
       " (1457770, 1698037): 0.4114109974100331,\n",
       " (3603006, 528525): 0.0002605364676954107,\n",
       " (3270543, 810239): 0.10672049144936825,\n",
       " (815321, 1769439): 0.0038115044999155624,\n",
       " (3298332, 4541363): 0.11953006380647307,\n",
       " (688738, 210010): 0.0,\n",
       " (3477478, 1356099): 0.027265456007137086,\n",
       " (2127715, 3771684): 0.09851879891670376,\n",
       " (2802612, 2067894): 0.19132709218245686,\n",
       " (2227051, 3622487): 0.0,\n",
       " (4680544, 2861968): 0.0,\n",
       " (4259308, 2635670): 0.4051079545449763,\n",
       " (1819017, 576259): 0.19931196664443318,\n",
       " (2525373, 3525135): 0.08453607707211293,\n",
       " (1296871, 3652028): 0.2658198046110226,\n",
       " (1124237, 2150915): 0.04300653707217916,\n",
       " (1196347, 873): 0.009940897147939873,\n",
       " (1764733, 730151): 0.25460666259132886,\n",
       " (3867477, 2473696): 0.14425278623311763,\n",
       " (4697417, 575944): 0.34066331486453083,\n",
       " (3672836, 4271149): 0.008288419251782923,\n",
       " (4714238, 1821849): 0.010079239861263104,\n",
       " (4208653, 299740): 0.1156877900173676,\n",
       " (4379662, 287241): 0.02437624238196763,\n",
       " (1945087, 4602809): 0.00838638775145943,\n",
       " (3597614, 4412703): 0.25215040483331597,\n",
       " (2342879, 4522433): 0.07296495206364906,\n",
       " (447838, 4520863): 0.07061180224933773,\n",
       " (3958395, 2801896): 0.8344052395337218,\n",
       " (3493764, 2616927): 0.1848053177386433,\n",
       " (3852439, 677759): 0.274477789729639,\n",
       " (2495476, 2089299): 0.05025018780494354,\n",
       " (2176616, 3443775): 0.0022523430193173133,\n",
       " (3253453, 445562): 0.359341942410547,\n",
       " (1343937, 4564180): 0.04693923619169199,\n",
       " (1810398, 834153): 0.0,\n",
       " (3861523, 4762874): 0.03805806968715255,\n",
       " (4623773, 4684188): 0.12351164647887301,\n",
       " (2802662, 4170916): 0.03449786470852133,\n",
       " (2757448, 4062558): 0.0,\n",
       " (3622518, 3051044): 0.21255780729678395,\n",
       " (1243612, 3091780): 0.09342734736167439,\n",
       " (1894869, 1171914): 0.21894688707717602,\n",
       " (302379, 808735): 0.19235528043066621,\n",
       " (3880783, 734399): 0.004612968258268789,\n",
       " (723690, 1708965): 0.0,\n",
       " (4157541, 3727625): 0.2933870011260438,\n",
       " (2406444, 2789545): 0.0,\n",
       " (893343, 3590181): 0.019345833530988545,\n",
       " (390919, 711936): 0.2014358242663521,\n",
       " (3277539, 2173241): 0.17035648297705833,\n",
       " (2294757, 4587463): 0.06524972401647315,\n",
       " (2636494, 4202601): 0.3344728847838798,\n",
       " (792179, 1516101): 0.11658331011176556,\n",
       " (2521113, 4177235): 0.1539454964475856,\n",
       " (4355667, 1617819): 0.09386797068103117,\n",
       " (864581, 1618916): 0.03994295720190186,\n",
       " (696405, 1008749): 0.01879382774250463,\n",
       " (3521265, 1638639): 0.05579894731429115,\n",
       " (2221664, 2748266): 0.0,\n",
       " (777122, 597759): 0.046868473837698196,\n",
       " (4414533, 4341953): 0.32131607368313586,\n",
       " (1941231, 2319029): 0.0,\n",
       " (1832467, 4468670): 0.2580913751799793,\n",
       " (1270675, 453550): 0.0,\n",
       " (165834, 4463845): 0.052999292192125194,\n",
       " (3707339, 4212980): 0.060929664790417615,\n",
       " (4514762, 2916918): 0.1613302113553991,\n",
       " (4548776, 3753555): 0.13060623901190954,\n",
       " (3115851, 4328783): 0.0,\n",
       " (2409175, 3869320): 0.09212574801722787,\n",
       " (3190366, 1254588): 0.0019443558966528232,\n",
       " (3021570, 4839623): 0.05839279404726389,\n",
       " (408965, 1827009): 0.4620065156370102,\n",
       " (4758376, 1230099): 0.06997717759111069,\n",
       " (2826186, 825635): 0.344971441817741,\n",
       " (912470, 3979720): 0.0,\n",
       " (2892834, 4038309): 0.18640122338278914,\n",
       " (1734440, 4268522): 0.15641473114596777,\n",
       " (3051623, 4737291): 0.08995084752117298,\n",
       " (785950, 1348398): 0.12559522467040288,\n",
       " (1557635, 1728847): 0.2005667711019184,\n",
       " (4728394, 2749085): 0.04845534620686242,\n",
       " (985610, 2459106): 0.2170235452148825,\n",
       " (1013469, 1602955): 0.0,\n",
       " (2207325, 1925125): 0.09933407614199774,\n",
       " (3853107, 4104517): 0.10291160595443484,\n",
       " (242107, 2049219): 0.012640035420718761,\n",
       " (1968186, 3228865): 0.012389131551419429,\n",
       " (1828358, 4349860): 0.30692721315692834,\n",
       " (986710, 1456984): 0.04565672871534469,\n",
       " (3856945, 1686589): 0.016736649240759627,\n",
       " (1590220, 1293360): 0.006431071331940159,\n",
       " (4596817, 1914251): 0.17725613290766465,\n",
       " (3465982, 3217208): 0.0688190694735446,\n",
       " (103101, 485105): 0.08554880332828844,\n",
       " (1488661, 1853195): 0.19540347521461207,\n",
       " (1443534, 2841085): 0.5419657315049926,\n",
       " (3907500, 4368766): 0.26396394158339104,\n",
       " (4365016, 1650637): 0.17623329570993904,\n",
       " (694259, 2451482): 0.2424557777461069,\n",
       " (3840932, 3893268): 0.0855091792155544,\n",
       " (3134099, 557877): 0.28540849188455675,\n",
       " (1653356, 1817806): 0.1076654207907223,\n",
       " (4754912, 1080728): 0.06881419146360483,\n",
       " (706424, 3177275): 0.19635069661128476,\n",
       " (2923569, 3667617): 0.04363634844828405,\n",
       " (4065415, 2494274): 0.35721593409021524,\n",
       " (2260684, 2313365): 0.0,\n",
       " (510777, 722821): 0.0,\n",
       " (927066, 3367061): 0.0206282793303242,\n",
       " (2663965, 861873): 0.11649771973507039,\n",
       " (3405370, 2316276): 0.12010142834710241,\n",
       " (2087605, 4451501): 0.27141766429559633,\n",
       " (3379919, 342627): 0.2517913580688226,\n",
       " (157174, 1698047): 0.13439662317731635,\n",
       " (451621, 1893852): 0.05661723916492465,\n",
       " (3971971, 2982832): 0.3368062098102943,\n",
       " (4394985, 4592289): 0.013000562317069848,\n",
       " (4714238, 710313): 0.27383405566480046,\n",
       " (2881471, 714422): 0.061728461005303444,\n",
       " (497944, 1308410): 0.009183264430023685,\n",
       " (2042396, 1089444): 0.19256074293581105,\n",
       " (3154830, 306684): 0.023062299864336975,\n",
       " (72385, 4528097): 0.0,\n",
       " (2747503, 883836): 0.16408612768577727,\n",
       " (3333907, 2720143): 0.0915165570397059,\n",
       " (1716384, 434003): 0.01236897657721071,\n",
       " (1463080, 906453): 0.15342531430676168,\n",
       " (2995131, 4340791): 0.010556630596728605,\n",
       " (1460845, 4505799): 0.1398641072270712,\n",
       " (4104158, 4573553): 0.0017963039248119275,\n",
       " (1763368, 234000): 0.0013448773399320365,\n",
       " (3335643, 3865179): 0.2804640958370482,\n",
       " (4494198, 3370297): 0.11105024989269521,\n",
       " (293537, 224637): 0.0030405427982230174,\n",
       " (2355600, 3162022): 0.04000569665025348,\n",
       " (1092203, 3779056): 0.05595801360089521,\n",
       " (4421155, 1650875): 0.19887118569436324,\n",
       " (2856337, 4466763): 0.09660976121097249,\n",
       " (2397711, 4010687): 0.012311928133847926,\n",
       " (585971, 3513478): 0.0,\n",
       " (4680040, 1304): 0.20054345186993053,\n",
       " (1573878, 2620253): 0.5419919802371628,\n",
       " (1124524, 253556): 0.3740456111993879,\n",
       " (2112557, 4134234): 0.2743800571706711,\n",
       " (1669303, 4380017): 0.10466522243417552,\n",
       " (2749438, 3416287): 0.1647972309113163,\n",
       " (2084646, 752713): 0.021117331509487712,\n",
       " (1072715, 2924033): 0.0006022625531701755,\n",
       " (634629, 2771739): 0.250431480728353,\n",
       " (809365, 3794083): 0.5316495320198301,\n",
       " (3987684, 1673877): 0.09800112988265272,\n",
       " (4424048, 4524008): 0.17673267277423732,\n",
       " (689195, 4544373): 9.064931387172624e-05,\n",
       " (232893, 1957695): 0.162526699251655,\n",
       " (2201746, 1281003): 0.16550372479701025,\n",
       " (3944761, 1829039): 0.07373578833523056,\n",
       " (1616492, 3270964): 0.2727184511797044,\n",
       " (1992776, 2262639): 0.028813448862390168,\n",
       " (1670258, 1999779): 0.18297153307667205,\n",
       " (3065912, 432490): 0.0,\n",
       " (437628, 2381140): 0.01010867656878517,\n",
       " (2354912, 3413134): 0.08988699632815987,\n",
       " (1652970, 774771): 0.11364328890700495,\n",
       " (820259, 4784779): 0.015641439720199473,\n",
       " (2133963, 2962391): 0.1698386485302318,\n",
       " (791866, 3431937): 0.002885664445440699,\n",
       " (1237857, 1628): 0.0,\n",
       " (2323088, 4794039): 0.06241828137763676,\n",
       " (25053, 2582645): 0.007167104760906283,\n",
       " (657592, 1890534): 0.1933432837745638,\n",
       " (2279458, 2553293): 0.02360324386493433,\n",
       " (4308267, 1306260): 0.03797889221748933,\n",
       " (3075881, 4008986): 0.021199416352859785,\n",
       " (2362801, 4390630): 0.03174342119472754,\n",
       " (1399174, 1515149): 0.34535819955688524,\n",
       " (1870557, 2887240): 0.05989629856786678,\n",
       " (3178117, 1182789): 0.0,\n",
       " (4553813, 2417949): 0.490889510683583,\n",
       " (1119006, 2401551): 0.0,\n",
       " (2458987, 1032137): 0.10178472524939346,\n",
       " (2742587, 332625): 0.10860207495828345,\n",
       " (2082038, 1777063): 0.021992529370614227,\n",
       " (1996648, 2576743): 0.2165155222409989,\n",
       " (1685063, 1136395): 0.4099530867541063,\n",
       " (1109797, 1463609): 0.08527501274077408,\n",
       " (4829839, 3485095): 0.06655428189433886,\n",
       " (2855917, 3271110): 0.05617081250844565,\n",
       " (2186509, 2167581): 0.0,\n",
       " (1211495, 784376): 0.22808801165631842,\n",
       " (2627004, 2152890): 0.007068998608042751,\n",
       " (3151610, 581535): 0.20360282947810823,\n",
       " (2468110, 1523034): 0.012375371282194311,\n",
       " (4550082, 3280389): 0.17743684336799412,\n",
       " (1159144, 243669): 0.09634463780362838,\n",
       " (4411145, 1193523): 0.1325100856783926,\n",
       " (565240, 532927): 0.08957583124025534,\n",
       " (576214, 1293517): 0.2405197379633627,\n",
       " (4512746, 1909254): 0.01772356104909769,\n",
       " (2945040, 425267): 0.01621257414195292,\n",
       " (3359949, 4387641): 0.052041409203605886,\n",
       " (1055480, 1163700): 0.30277978902389563,\n",
       " (1272800, 3275233): 0.13767605505606684,\n",
       " (2808935, 59603): 0.10384592424934903,\n",
       " (2707066, 3548457): 0.17566100280848296,\n",
       " (2433279, 2460017): 0.014882353561686119,\n",
       " (668677, 4418088): 0.013466381415445717,\n",
       " (3645402, 444212): 0.13879767504853888,\n",
       " (3503400, 1888495): 0.49842226674333395,\n",
       " (3736991, 4056937): 0.25717224993682,\n",
       " (2385769, 789354): 0.1517026680042787,\n",
       " (3461531, 475566): 0.14878674659032734,\n",
       " (2074981, 1837687): 0.33785300762025505,\n",
       " (2355232, 2019066): 0.11952681604146054,\n",
       " (1652970, 1468762): 0.08929391494363521,\n",
       " (1337914, 626235): 0.3721994356611641,\n",
       " (4096036, 2484386): 0.009129729179827028,\n",
       " (2732471, 1136680): 0.0829818624391656,\n",
       " (2614690, 1185706): 0.3776915179251686,\n",
       " (721203, 2930489): 0.08493771375422784,\n",
       " (813324, 2635467): 0.0,\n",
       " (1392192, 3833173): 0.07518518817059912,\n",
       " (4759132, 40502): 0.00018769952567078516,\n",
       " (1821035, 4277916): 0.014008203482075073,\n",
       " (3503811, 4191410): 0.25245967682684856,\n",
       " (2955972, 2126740): 0.15727747268329748,\n",
       " (311243, 3282101): 0.10491297540858859,\n",
       " (1051530, 2470714): 0.014241143975462887,\n",
       " (2482351, 1003983): 0.19430028674842395,\n",
       " (4821448, 2403466): 0.007048849511489758,\n",
       " (3605841, 1513830): 0.5416182954394391,\n",
       " (2191555, 2534205): 0.30970048879682605,\n",
       " (4189798, 3996838): 0.04246148651622438,\n",
       " (3656894, 3935730): 0.10117304804416148,\n",
       " (1034735, 3476049): 0.0051615103611474195,\n",
       " (4074044, 4356781): 0.2683847353907831,\n",
       " (2520647, 3265660): 0.03931538337438392,\n",
       " (3777846, 4556195): 0.28144885505325684,\n",
       " (2179466, 4855854): 0.3030219892595624,\n",
       " (3409126, 4569520): 0.0,\n",
       " (1115665, 3934499): 0.13505458518829794,\n",
       " (2601211, 4090877): 0.04936144485070988,\n",
       " (410659, 3937455): 0.2835742217125004,\n",
       " (2742921, 840004): 0.11040049708739437,\n",
       " (3361377, 2763056): 0.07766078328623684,\n",
       " (917487, 4600270): 0.015893980735934607,\n",
       " (4779576, 3180382): 0.1699442634608216,\n",
       " (735870, 60980): 0.09593713018251113,\n",
       " (1048446, 1563071): 0.0,\n",
       " (2417949, 820811): 0.019910823108698572,\n",
       " (1306885, 3877812): 0.012846609953038468,\n",
       " (1060254, 3958716): 0.49762533699431105,\n",
       " (1190760, 434643): 0.012592423067072003,\n",
       " (4200115, 1666342): 0.0,\n",
       " (2627004, 4723755): 0.3875778627625399,\n",
       " (1645166, 398987): 0.07089626311728899,\n",
       " (3907031, 292639): 0.17476525111927232,\n",
       " (2624527, 2467847): 0.0004215288508980711,\n",
       " (3640261, 190719): 0.03880970662886502,\n",
       " (2542968, 1070518): 0.20392720428502253,\n",
       " (109148, 1134983): 0.19060046633327865,\n",
       " (3781164, 2652629): 0.0,\n",
       " (4721599, 4684761): 0.00942572963978936,\n",
       " (556945, 1857888): 0.05704465348713507,\n",
       " (3282190, 1602957): 0.1619779327504761,\n",
       " (3935241, 4156836): 0.25038593558779315,\n",
       " (2383388, 3352327): 0.029332692278216388,\n",
       " (3622028, 696891): 0.3091088271267481,\n",
       " (372245, 265277): 0.0,\n",
       " (317300, 449637): 0.07433601681001933,\n",
       " (3002029, 2672578): 0.06811289188487403,\n",
       " (2971546, 4099597): 0.3224235168267184,\n",
       " (232646, 1796543): 0.07355111476135875,\n",
       " (849013, 4027460): 0.08869549704621553,\n",
       " (2465843, 1099835): 0.08545862268546808,\n",
       " (1928413, 4014826): 0.0604818535670047,\n",
       " (579196, 3374521): 0.01197632787148726,\n",
       " (1499272, 797456): 0.04639894257130941,\n",
       " (1331164, 3050360): 0.02079823932250003,\n",
       " (4714568, 1882591): 0.0,\n",
       " (1106963, 4089079): 0.005997531308934341,\n",
       " (819769, 4539259): 0.1208787749364843,\n",
       " (2483796, 724503): 0.010378150867673838,\n",
       " (2269765, 561318): 0.12776283829701024,\n",
       " (3943758, 1462795): 0.15030038285026362,\n",
       " (1700044, 4782074): 0.19772734088170332,\n",
       " (3396719, 2379154): 0.4511099104799219,\n",
       " (1082649, 631981): 0.053176308364732555,\n",
       " (457963, 3582391): 0.04751651722388169,\n",
       " (1499960, 1092569): 0.19481029613523446,\n",
       " (2072729, 95467): 0.029865856000792612,\n",
       " (4451491, 1473363): 0.22710974891453228,\n",
       " (3655779, 2194939): 0.04304498322746659,\n",
       " (4170965, 1652913): 0.10266073984719458,\n",
       " (1068855, 1782927): 0.04123301498597148,\n",
       " (4447516, 2746808): 0.09305109388307883,\n",
       " (2115313, 3115867): 0.15323885487591413,\n",
       " (2858448, 4657888): 0.09891294246456976,\n",
       " (4126109, 259027): 0.0,\n",
       " (2850118, 558375): 0.1907868965684339,\n",
       " (2989104, 1839680): 0.011638726329950912,\n",
       " (1354066, 4108715): 0.3763987192868521,\n",
       " (3481139, 1327933): 0.5402933349583364,\n",
       " (3340807, 746711): 0.4808176687799421,\n",
       " (1582404, 1793537): 0.48701022418245427,\n",
       " (1476977, 139835): 0.13145573583837,\n",
       " (453639, 3569179): 0.18578828078096993,\n",
       " (4445029, 2780940): 0.26821587503196564,\n",
       " (4125527, 2595392): 0.21995454085838825,\n",
       " (857872, 4514416): 0.13911122542829193,\n",
       " (1900278, 1446646): 0.33555239775340673,\n",
       " (998554, 3335592): 0.21679312245417579,\n",
       " (2667980, 2610722): 0.21604188398467536,\n",
       " (3935305, 115299): 0.0008076838360679185,\n",
       " (3116124, 2258762): 0.1735219336510615,\n",
       " (2093894, 2175204): 0.0,\n",
       " (3296364, 2127964): 0.17065536049376703,\n",
       " (315254, 2663161): 0.8178604756084237,\n",
       " (4785837, 3501374): 0.13403953398047383,\n",
       " (4214338, 4822471): 0.19509125991958928,\n",
       " (4201339, 3862937): 0.07508408276748901,\n",
       " (1020529, 4756061): 0.11832988327114792,\n",
       " (3992121, 3590546): 0.18850700165128642,\n",
       " (3689767, 872451): 0.03221187993192651,\n",
       " (207140, 4696176): 0.17516385079595845,\n",
       " (4361636, 2894149): 0.1615543873144171,\n",
       " (1639837, 4484920): 0.19643444326188866,\n",
       " (3361771, 362836): 0.07964049966729828,\n",
       " (1332811, 158772): 0.08351303904021024,\n",
       " (4359964, 3435754): 0.3133697090262883,\n",
       " (4696176, 2589127): 0.03718829381410377,\n",
       " (3145562, 19458): 0.08369464293833546,\n",
       " (2202417, 720158): 0.3304334872086448,\n",
       " (1572270, 74874): 0.21771823718179728,\n",
       " (607378, 2543437): 0.35397023571696135,\n",
       " (2052485, 4132521): 0.3032262809689283,\n",
       " (2055544, 4865595): 0.10424494947557877,\n",
       " (4027517, 782912): 0.35969321590351794,\n",
       " (2144504, 1461794): 0.015976440559535614,\n",
       " (1124524, 2654333): 0.08154819701843886,\n",
       " (2843837, 3820618): 0.03077452888310919,\n",
       " (2899964, 2257508): 0.05270136229365011,\n",
       " (1650297, 4378194): 0.10149606517839745,\n",
       " (4297315, 1307649): 0.39770171955029887,\n",
       " (1645456, 1436216): 0.09401236830469785,\n",
       " (2011253, 1530328): 0.00021400026438638328,\n",
       " (301061, 1325177): 0.050993886666890004,\n",
       " (2536472, 4461539): 0.08525477952341748,\n",
       " (2631989, 981464): 0.3553467884810862,\n",
       " (3879351, 2467847): 0.5108452953497562,\n",
       " (3453581, 1878239): 0.0,\n",
       " (1037213, 801537): 0.09512909529422887,\n",
       " (1494665, 1711932): 0.19282693535281978,\n",
       " (289355, 2287786): 0.047367673162340425,\n",
       " (232226, 3671566): 0.054339831656184154,\n",
       " (2885874, 4445730): 0.05116621171467096,\n",
       " (3960049, 1351669): 0.19421555496563833,\n",
       " (2101653, 941843): 0.11379151118420863,\n",
       " (1017643, 1423603): 0.11060714417499015,\n",
       " (122526, 4432670): 0.046635894054522314,\n",
       " (3508290, 1582613): 0.4500966765530306,\n",
       " (2836920, 1908260): 0.09667851236144193,\n",
       " (1984394, 4271213): 0.014215240213667414,\n",
       " (1222244, 1340422): 0.1171518967692857,\n",
       " (2906472, 3727220): 0.00570900008954548,\n",
       " (4030322, 958447): 0.0001306396461541902,\n",
       " (1995760, 1198567): 0.0028320693527050965,\n",
       " (15030, 2898673): 0.06957844613819485,\n",
       " (2352946, 1139041): 0.023148614707835198,\n",
       " (3949049, 4280395): 0.002546751023455954,\n",
       " (3736779, 108536): 0.0366569768530592,\n",
       " (1669142, 783172): 0.0,\n",
       " (2111602, 1228259): 0.18984177237111585,\n",
       " (3505472, 3891054): 0.023350988092039515,\n",
       " (1961629, 1849099): 0.05806129052718916,\n",
       " (1669303, 2734931): 0.038222390636041416,\n",
       " (4386120, 2339400): 0.6086753067588134,\n",
       " (1304675, 3702208): 0.03289758474798854,\n",
       " (4527062, 1218003): 0.039942789829937736,\n",
       " (80085, 2121425): 0.36053229636378475,\n",
       " (2040305, 2603856): 0.031740439756918745,\n",
       " (1900542, 4613341): 0.07341154015208781,\n",
       " (3683411, 294336): 0.19121176826781203,\n",
       " (2010948, 416281): 0.35637435055312205,\n",
       " (2344789, 530436): 0.3526736968243802,\n",
       " (1960138, 1720129): 0.21622345312213684,\n",
       " (3628741, 3480441): 0.07154943944398899,\n",
       " (1950255, 3551398): 0.12678271859009613,\n",
       " (4468670, 1794702): 0.0844374029274607,\n",
       " (1342228, 2720352): 0.19103809226823018,\n",
       " (1518778, 608403): 0.12149842920967434,\n",
       " (4633132, 203156): 0.1476663376865388,\n",
       " (4044128, 2286140): 0.15635142312430264,\n",
       " (1907579, 2339218): 0.09678080896164233,\n",
       " (2868678, 1339753): 0.1386055300775648,\n",
       " (1558178, 1880724): 0.28634932381128,\n",
       " (3069376, 4366991): 0.30739514475735463,\n",
       " (2820018, 1294991): 0.0,\n",
       " (418191, 4346746): 0.1402923199991891,\n",
       " (546566, 835680): 0.0408894983104676,\n",
       " (4714561, 3859526): 0.18279366764953736,\n",
       " (1027375, 302051): 0.06933469460219767,\n",
       " (1241955, 2885618): 0.020810530838164594,\n",
       " (2635029, 2826966): 0.2645771592785609,\n",
       " (2099164, 2571295): 0.05856163186573958,\n",
       " (1088985, 2284762): 0.07279675038852766,\n",
       " (768238, 2146030): 0.0,\n",
       " (3023958, 3306560): 0.4479820646707291,\n",
       " (3521995, 4432502): 0.00010790446726136255,\n",
       " (3254690, 1032410): 0.07228195647596733,\n",
       " (271967, 2640584): 0.1401281100339856,\n",
       " (808735, 2658383): 0.2954120639219623,\n",
       " (2322925, 1627800): 0.12503445632417678,\n",
       " (1407397, 1671897): 0.253821647105094,\n",
       " (2570528, 2019503): 0.0069184088309395,\n",
       " (1627275, 1960723): 0.10609411424823957,\n",
       " (1846344, 2337463): 0.09939090887521816,\n",
       " (4360799, 2699138): 0.07404340664247891,\n",
       " (1901834, 2657284): 0.1829631579381604,\n",
       " (3056035, 912277): 0.05530832555601131,\n",
       " (404434, 1865990): 0.10129958909968723,\n",
       " (1242199, 553041): 0.10710984493913826,\n",
       " (3660943, 2928365): 0.0,\n",
       " (3311052, 3618703): 0.17285296675752376,\n",
       " (1291388, 2914837): 0.06258913760476399,\n",
       " (601351, 3236049): 0.0,\n",
       " (4411870, 4842726): 0.5165235110781468,\n",
       " (4479954, 4464108): 0.3390502185792143,\n",
       " (3514277, 4271970): 0.49156447056806996,\n",
       " (2075355, 4556182): 0.0064345178501595225,\n",
       " (4460693, 1864132): 0.0052447728382404545,\n",
       " (3585698, 1027190): 0.011257722343527041,\n",
       " (4622190, 3709892): 0.0,\n",
       " (1036596, 4748716): 0.129325076168737,\n",
       " (530260, 3635915): 0.1526174039661975,\n",
       " (2842893, 2191951): 0.08582703105305543,\n",
       " (1803990, 3454055): 0.10948238670099092,\n",
       " (2572933, 807241): 0.10438367751331444,\n",
       " (3116723, 694306): 0.3180400647006079,\n",
       " (1224568, 1681229): 0.0,\n",
       " (2433609, 1737846): 0.08046938300009872,\n",
       " (2420785, 1551038): 0.03554730529965957,\n",
       " (2080350, 116813): 0.04208458296283365,\n",
       " (4426113, 4381050): 0.00047293115222067747,\n",
       " (110570, 3778155): 0.06279805245183145,\n",
       " (1923509, 4847446): 0.19445484677600877,\n",
       " (3854832, 579196): 0.3950942920956757,\n",
       " (2649949, 765601): 0.16661773770080177,\n",
       " (1131765, 1394863): 0.12874350525094735,\n",
       " (3959182, 3946195): 0.1459869602758083,\n",
       " (411170, 4447768): 0.0,\n",
       " (2055544, 3143068): 0.002042669500708206,\n",
       " (4448612, 1766895): 0.002562663651753247,\n",
       " (2929195, 3412237): 0.015471078695948033,\n",
       " (481540, 4382316): 0.0,\n",
       " (698430, 1194471): 0.0,\n",
       " (777451, 3336957): 0.0,\n",
       " (963272, 1317046): 0.0,\n",
       " (4305610, 3196673): 0.0036607936147591245,\n",
       " (4135223, 1256131): 0.1639745843579719,\n",
       " (2683658, 2179377): 0.0,\n",
       " (4298480, 4598255): 0.15106876836803895,\n",
       " (4458089, 3937795): 0.058060000499755265,\n",
       " (1679934, 2835186): 0.06506770256997729,\n",
       " (339838, 636774): 0.0004618165154455943,\n",
       " (2245586, 4394592): 0.5083750576450149,\n",
       " (4079785, 1355516): 0.36295535661704403,\n",
       " (22096, 42503): 0.020093692572544904,\n",
       " (4517347, 1856296): 0.18985522298829557,\n",
       " (1405177, 1384448): 0.15731196082051774,\n",
       " (1417019, 3444289): 0.07579009618934276,\n",
       " (2470160, 1197692): 0.00044760955418546907,\n",
       " (1062967, 995428): 0.0002262816313869704,\n",
       " (3268695, 3505189): 0.13290676871360896,\n",
       " (4336001, 3639495): 0.05763346889367284,\n",
       " (3768919, 2100397): 0.001790354728683049,\n",
       " (258220, 738648): 0.32775237766102594,\n",
       " (3992126, 1091480): 0.010185564552564435,\n",
       " (1667496, 4129346): 0.5161896749122892,\n",
       " (3480840, 213789): 0.028440330131012555,\n",
       " (1825054, 173152): 0.1310022214569715,\n",
       " (2190474, 3438576): 0.39084769227495963,\n",
       " (2307868, 1894353): 0.09044015186280768,\n",
       " (1461076, 3544413): 0.0,\n",
       " (3649132, 3818736): 0.006678593298511748,\n",
       " (1741347, 909326): 0.04527879296138623,\n",
       " (2027870, 2660220): 0.06992470858223392,\n",
       " (728300, 3878753): 0.7797618163127998,\n",
       " (1546600, 4011921): 0.19246859553991194,\n",
       " (1360763, 2293561): 0.05327560041793795,\n",
       " (3324691, 886546): 0.2591037202647382,\n",
       " (4708835, 176658): 0.019878193294316997,\n",
       " (882198, 3423748): 0.1955921410765506,\n",
       " (1180524, 882012): 0.19046644765763665,\n",
       " (3108039, 2537384): 0.06441528736300357,\n",
       " (4109330, 1251196): 0.3538400487012475,\n",
       " (776128, 1378204): 0.49370161712335286,\n",
       " (3708361, 4180276): 0.43020226311190823,\n",
       " (3701625, 4777290): 0.1775137485752064,\n",
       " (1434628, 4731849): 0.27485007561606517,\n",
       " (575903, 1786429): 0.00014057957592979991,\n",
       " (2476185, 3141995): 0.06871928392276581,\n",
       " (4233503, 4777129): 0.12116806792417653,\n",
       " (4085773, 3703196): 0.0,\n",
       " (4176998, 1446325): 0.18389819920918568,\n",
       " (484158, 1188411): 0.15448541932508061,\n",
       " (3501136, 4555562): 0.09851326506326802,\n",
       " (3171695, 3056605): 0.0039263649750121005,\n",
       " (2903143, 497013): 0.11646091967689419,\n",
       " (2189866, 4854370): 0.045221826030952525,\n",
       " (167943, 590756): 0.6574303618601735,\n",
       " (1964672, 4845357): 0.05035298169172179,\n",
       " (1440362, 3633252): 0.009914386644889837,\n",
       " (3013612, 1993229): 0.3887987467840148,\n",
       " (1915221, 1488541): 0.044673694851503035,\n",
       " (2281149, 2300372): 0.040839653630991346,\n",
       " (2236210, 3913118): 0.01975911003254714,\n",
       " (3812277, 582399): 0.03647520034577661,\n",
       " (974940, 4653363): 2.6811483130868995e-05,\n",
       " (4603640, 2992123): 0.03211964041898531,\n",
       " (4230350, 2150039): 0.0462368321501682,\n",
       " (2164338, 2114204): 0.009138086721435824,\n",
       " (1951838, 2525437): 0.0,\n",
       " (490494, 1504623): 0.0,\n",
       " (2604966, 2244465): 0.2529722631003019,\n",
       " (83832, 3459318): 0.3601042063113652,\n",
       " (4485782, 4348185): 0.1014383644955855,\n",
       " (4670994, 3075802): 0.0,\n",
       " (4098476, 1754809): 0.053574200453500156,\n",
       " (4092605, 3887847): 0.0075697367732688765,\n",
       " (376238, 3853383): 0.1607545890566041,\n",
       " (883836, 1981318): 0.2301667415517011,\n",
       " (2021578, 443048): 0.0,\n",
       " (85156, 2449784): 0.19015264532257176,\n",
       " (420825, 4299489): 0.531209436671967,\n",
       " (73621, 1536016): 0.06121499287225889,\n",
       " (2059077, 2729087): 0.06813711922947999,\n",
       " (2893869, 2163070): 0.35379109886805576,\n",
       " (2414533, 4319648): 0.027147926035552373,\n",
       " (3359924, 4808664): 0.007057853047329554,\n",
       " (580293, 4166801): 0.0023798767638221465,\n",
       " (3056533, 4057943): 0.002278718480874323,\n",
       " (3334595, 3455843): 0.340159579556531,\n",
       " (575745, 333573): 0.19235745588586223,\n",
       " (4798284, 1861462): 0.06265837358070814,\n",
       " (1253998, 2818687): 0.021225519645764437,\n",
       " (3655915, 2306703): 0.1703830915917715,\n",
       " (21944, 744279): 0.139907757590155,\n",
       " (3455734, 355149): 0.249837091005499,\n",
       " (2169223, 1829372): 0.009905079733713806,\n",
       " (185943, 2541179): 0.3387037603242932,\n",
       " (1311397, 3071143): 0.005049019645502699,\n",
       " (3375235, 2165408): 0.2267536191290426,\n",
       " (962054, 3751205): 0.17002588245388836,\n",
       " (827277, 2173286): 0.0970580405716595,\n",
       " (2385751, 3282614): 0.02731724250511505,\n",
       " (173152, 2830312): 0.14465025112015648,\n",
       " (2119707, 1323039): 0.458402511745174,\n",
       " (628351, 3558319): 0.03486916941873865,\n",
       " (4816186, 3416537): 0.47541115484769203,\n",
       " (4780751, 866805): 0.014550279406165895,\n",
       " (33342, 3608368): 0.2734327476420599,\n",
       " (1115665, 313907): 0.014897481102896386,\n",
       " (580520, 1870780): 0.013515603492423117,\n",
       " (3820906, 3685989): 0.283034085846748,\n",
       " (4291779, 2559521): 0.0,\n",
       " (3979261, 2749001): 0.012190215647293298,\n",
       " (651342, 2886438): 0.05162971661927345,\n",
       " (2495706, 1377428): 0.037060413129964484,\n",
       " (1950255, 3516889): 0.14937251199998627,\n",
       " (2063726, 449493): 0.19192946270684644,\n",
       " (4670994, 4471184): 0.15182962976980371,\n",
       " ...}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"new_data/cosin_dict_add_self_t10.p\", \"rb\") as f:\n",
    "    cosin_dict = pickle.load(f)\n",
    "cosin_dict\n",
    "# (4030539, 354904) in cosin_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(209445, 230750) in cosin_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"new_data/sub_cosin_dict_add_sm_t10.p\", \"rb\") as f:\n",
    "    sub_cosin_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"new_data/random_walk_train.p\", \"rb\") as f:\n",
    "    random_walk_train = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"new_data/random_walk_sub.p\", \"rb\") as f:\n",
    "    random_walk_sub = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_followees(a, b, train_graph=g):\n",
    "    try:\n",
    "        if len(set(train_graph.successors(a))) == 0 or len(set(train_graph.successors(b))) == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            intersection = len(set(train_graph.successors(a)).intersection(set(train_graph.successors(b))))\n",
    "            union = len(set(train_graph.successors(a)).union(set(train_graph.successors(b))))\n",
    "            return intersection/union\n",
    "    except:\n",
    "        return 0\n",
    "    return sim\n",
    "\n",
    "def jaccard_followers(a,b, train_graph=g):\n",
    "    try:\n",
    "        if set(train_graph.predecessors(a)) == 0 or len(set(g.predecessors(b))) == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            intersection = len(set(train_graph.predecessors(a)).intersection(set(train_graph.predecessors(b))))\n",
    "            union = len(set(train_graph.predecessors(a)).union(set(train_graph.predecessors(b))))\n",
    "            return intersection/union\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "#for followees\n",
    "def cosine_followees(a, b, train_graph=g):\n",
    "    try:\n",
    "        if len(set(train_graph.successors(a))) == 0 or len(set(train_graph.successors(b))) == 0:\n",
    "            print(\"yes\")\n",
    "            return 0\n",
    "        else:\n",
    "            return (len(set(train_graph.successors(a)).intersection(set(train_graph.successors(b)))))/\\\n",
    "                                    (math.sqrt(len(set(train_graph.successors(a)))*len((set(train_graph.successors(b))))))\n",
    "    except:\n",
    "        return 0\n",
    "    \n",
    "def cosine_followers(a, b, train_graph=g):\n",
    "    try:\n",
    "        \n",
    "        if len(set(train_graph.predecessors(a))) == 0 or len(set(train_graph.predecessors(b))) == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            print(len(set(train_graph.predecessors(a)).intersection(set(train_graph.predecessors(b)))))\n",
    "            return (len(set(train_graph.predecessors(a)).intersection(set(train_graph.predecessors(b)))))/\\\n",
    "                                     (math.sqrt(len(set(train_graph.predecessors(a))))*(len(set(train_graph.predecessors(b)))))\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_shortest_path_length(a, b, train_graph=G):\n",
    "    p = 99\n",
    "    try:\n",
    "        # if the edge already exist, we first remove the edge which let our model better understand the graph\n",
    "        if train_graph.has_edge(a,b):\n",
    "            train_graph.remove_edge(a,b)\n",
    "            p= nx.shortest_path_length(train_graph,source=a,target=b)\n",
    "            train_graph.add_edge(a,b)\n",
    "        else:\n",
    "            p= nx.shortest_path_length(train_graph,source=a,target=b)\n",
    "        return p\n",
    "    except:\n",
    "        return 99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preferencial_attchment(a, b, graph=g):\n",
    "    try:\n",
    "        a_set = set(graph.successors(a)).union(graph.predecessors(a))\n",
    "        b_set = set(graph.successors(b)).union(graph.predecessors(b))\n",
    "    except:\n",
    "        return 0\n",
    "    return len(a_set)*len(b_set)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sorensen(a, b, graph=g):\n",
    "    try:\n",
    "        a_set = set(graph.successors(a)).union(graph.predecessors(a))\n",
    "        b_set = set(graph.successors(b)).union(graph.predecessors(b))\n",
    "    except:\n",
    "        return 0\n",
    "    \n",
    "    return 2 * len(a_set & b_set) / (len(a_set) + len(b_set))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hub_depressed(a, b, graph=g):\n",
    "    try:\n",
    "        s1 = set(graph.successors(a)).union(set(graph.predecessors(a)))\n",
    "        s2 = set(graph.successors(b)).union(set(graph.predecessors(b)))\n",
    "        neighbour = len(s1.intersection(s2))\n",
    "    except:\n",
    "        neighbour = 0\n",
    "        \n",
    "    if neighbour == 0:\n",
    "        return 0\n",
    "    \n",
    "    anext = 0\n",
    "    bnext = 0\n",
    "    try:\n",
    "        anext = len(list(graph.successors(a)))\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        bnext = len(list(graph.successors(b)))\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    min_two = min(anext, bnext)\n",
    "    \n",
    "    if min_two == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return neighbour/min_two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hub_promoted(a, b, graph=g):\n",
    "    try:\n",
    "#         neighbour = len(set(graph.successors(a)).intersection(graph.successors(b)))\n",
    "        s1 = set(graph.successors(a)).union(set(graph.predecessors(a)))\n",
    "        s2 = set(graph.successors(b)).union(set(graph.predecessors(b)))\n",
    "        neighbour = len(s1.intersection(s2))\n",
    "    except:\n",
    "        neighbour = 0\n",
    "        \n",
    "    if neighbour == 0:\n",
    "        return 0\n",
    "    \n",
    "    anext = 0\n",
    "    bnext = 0\n",
    "    try:\n",
    "        anext = len(list(graph.successors(a)))\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        bnext = len(list(graph.successors(b)))\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    max_two = max(anext, bnext)\n",
    "    \n",
    "    if max_two == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return neighbour/max_two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lhn(nei, pre):\n",
    "    if nei == 0 or pre == 0:\n",
    "        return 0\n",
    "    return nei/pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def common_neighbours(a, b, graph=g):\n",
    "    try:\n",
    "        a_set = set(graph.successors(a)).union(graph.predecessors(a))\n",
    "        b_set = set(graph.successors(b)).union(graph.predecessors(b))\n",
    "    except:\n",
    "        return 0\n",
    "    \n",
    "    return len(a_set.intersection(b_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_features['jaccard_followers'] = X_desire_train.apply(lambda row:jaccard_followers(row['Source'], row['Sink']), axis=1)\n",
    "X_test_features['jaccard_followers'] = X_desire_test.apply(lambda row:jaccard_followers(row['Source'], row['Sink']),axis=1)\n",
    "\n",
    "#mapping jaccrd followees to train and test data\n",
    "X_train_features['jaccard_followees'] = X_desire_train.apply(lambda row:jaccard_followees(row['Source'], row['Sink']), axis=1)\n",
    "X_test_features['jaccard_followees'] = X_desire_test.apply(lambda row:jaccard_followees(row['Source'], row['Sink']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_features['cosin_rec'] = X_desire_train.apply(lambda row: cosin_dict[(row['Source'], row['Sink'])], axis=1)\n",
    "X_test_features['cosin_rec'] = X_desire_test.apply(lambda row: cosin_dict[(row['Source'], row['Sink'])], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_features_stage1(df_final):\n",
    "    #calculating # of followers followees for source and destination\n",
    "    #calculating intersection of followers and followees for source and destination\n",
    "    num_followers_s=[]\n",
    "    num_followees_s=[]\n",
    "    num_followers_d=[]\n",
    "    num_followees_d=[]\n",
    "    inter_followers=[]\n",
    "    inter_followees=[]\n",
    "    \n",
    "    for i, row in df_final.iterrows():\n",
    "        try:\n",
    "            s1 = set(g.predecessors(row['Source']))\n",
    "            s2 = set(g.predecessors(row['Sink']))\n",
    "        except:\n",
    "            s1 = set()\n",
    "            s2 = set()\n",
    "            \n",
    "        try:\n",
    "            d1 = set(g.successors(row['Source']))\n",
    "            d2 = set(g.successors(row['Sink']))\n",
    "        except:\n",
    "            d1 = set()\n",
    "            d2 = set()\n",
    "\n",
    "        num_followers_s.append(len(s1))\n",
    "        num_followees_s.append(len(d1))\n",
    "\n",
    "        num_followers_d.append(len(s2))\n",
    "        num_followees_d.append(len(d2))\n",
    "        \n",
    "        inter_followers.append(len(s1.intersection(s2)))\n",
    "        inter_followees.append(len(d1.intersection(d2)))\n",
    "\n",
    "    return num_followers_s, num_followers_d, num_followees_s, num_followees_d,inter_followers,inter_followees\n",
    "\n",
    "X_train_features['num_followers_s'], X_train_features['num_followers_d'], \\\n",
    "X_train_features['num_followees_s'], X_train_features['num_followees_d'], \\\n",
    "X_train_features['inter_followers'], X_train_features['inter_followees'] = compute_features_stage1(X_desire_train)\n",
    "\n",
    "X_test_features['num_followers_s'], X_test_features['num_followers_d'], \\\n",
    "X_test_features['num_followees_s'], X_test_features['num_followees_d'], \\\n",
    "X_test_features['inter_followers'], X_test_features['inter_followees'] = compute_features_stage1(X_desire_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_features['shortest_path'] = X_desire_train.apply(lambda row: compute_shortest_path_length(row['Source'], row['Sink']), axis=1)\n",
    "X_test_features['shortest_path'] = X_desire_test.apply(lambda row: compute_shortest_path_length(row['Source'], row['Sink']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_features['c_nei'] = X_desire_train.apply(lambda row: common_neighbours(row['Source'], row['Sink']), axis=1)\n",
    "X_test_features['c_nei'] = X_desire_test.apply(lambda row: common_neighbours(row['Source'], row['Sink']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_features['flow2'] = X_desire_train.apply(lambda row: random_walk_train.get((row['Source'], row['Sink']), [0])[0], axis=1)\n",
    "X_test_features['flow2'] = X_desire_test.apply(lambda row: random_walk_train.get((row['Source'], row['Sink']), [0])[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_features['flow3'] = X_desire_train.apply(lambda row: random_walk_train.get((row['Source'], row['Sink']), [0,0])[1], axis=1)\n",
    "X_test_features['flow3'] = X_desire_test.apply(lambda row: random_walk_train.get((row['Source'], row['Sink']), [0,0])[1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_features['prefer'] = X_desire_train.apply(lambda row: preferencial_attchment(row['Source'], row['Sink']), axis=1)\n",
    "X_test_features['prefer'] = X_desire_test.apply(lambda row: preferencial_attchment(row['Source'], row['Sink']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_features['sor'] = X_desire_train.apply(lambda row: sorensen(row['Source'], row['Sink']), axis=1)\n",
    "X_test_features['sor'] = X_desire_test.apply(lambda row: sorensen(row['Source'], row['Sink']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:22<00:00, 11.21s/it]\n"
     ]
    }
   ],
   "source": [
    "mappings = [\n",
    "    hub_depressed, \n",
    "    hub_promoted\n",
    "]\n",
    "\n",
    "for f in tqdm(mappings, position=0, leave=True):\n",
    "    X_train_features[f.__name__] = X_desire_train.apply(lambda row: f(row['Source'], row['Sink']), axis=1)\n",
    "    X_test_features[f.__name__] = X_desire_test.apply(lambda row:f(row['Source'], row['Sink']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_features['lhn'] = X_train_features.apply(lambda row: lhn(row['c_nei'], row['prefer']), axis=1)\n",
    "X_test_features['lhn'] = X_test_features.apply(lambda row: lhn(row['c_nei'], row['prefer']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Sink</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4856212</td>\n",
       "      <td>2230237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1939867</td>\n",
       "      <td>1524883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4162561</td>\n",
       "      <td>323165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3581859</td>\n",
       "      <td>1150700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3096420</td>\n",
       "      <td>3628285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15995</th>\n",
       "      <td>296722</td>\n",
       "      <td>2326908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15996</th>\n",
       "      <td>1442657</td>\n",
       "      <td>711848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15997</th>\n",
       "      <td>3349730</td>\n",
       "      <td>649471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15998</th>\n",
       "      <td>4131768</td>\n",
       "      <td>572832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15999</th>\n",
       "      <td>4107537</td>\n",
       "      <td>4064905</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Source     Sink\n",
       "0      4856212  2230237\n",
       "1      1939867  1524883\n",
       "2      4162561   323165\n",
       "3      3581859  1150700\n",
       "4      3096420  3628285\n",
       "...        ...      ...\n",
       "15995   296722  2326908\n",
       "15996  1442657   711848\n",
       "15997  3349730   649471\n",
       "15998  4131768   572832\n",
       "15999  4107537  4064905\n",
       "\n",
       "[16000 rows x 2 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_desire_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_neighbours(4710933,1771100,g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NX features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def res_allo_index(a,b,graph=G):\n",
    "    a = nx.resource_allocation_index(G,[(a, b)])\n",
    "    try:\n",
    "        for u,v,p in a:\n",
    "            return p\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jar_coe(a,b,graph=G):\n",
    "    a = nx.jaccard_coefficient(G,[(a, b)])\n",
    "    try:\n",
    "        for u,v,p in a:\n",
    "            return p\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adamic_adar_index(a,b,graph=G):\n",
    "    a = nx.adamic_adar_index(G,[(a, b)])\n",
    "    try:\n",
    "        for u,v,p in a:\n",
    "            return p\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preferential_attachment(a,b,graph=G):\n",
    "    a = nx.preferential_attachment(G,[(a, b)])\n",
    "    try:\n",
    "        for u,v,p in a:\n",
    "            return p\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "desire_train_feature = list()\n",
    "for i in range(len(X_desire_train)):\n",
    "    features = {\n",
    "                'reasource_allo_index': res_allo_index(X_desire_train['Source'][i], X_desire_train['Sink'][i], G),\n",
    "                'jarccard_coef': jar_coe(X_desire_train['Source'][i], X_desire_train['Sink'][i], G),\n",
    "                'adamic_adar_index': adamic_adar_index(X_desire_train['Source'][i], X_desire_train['Sink'][i], G),\n",
    "                'preferential_attachment': preferential_attachment(X_desire_train['Source'][i], X_desire_train['Sink'][i], G)\n",
    "    }\n",
    "    desire_train_feature.append(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reasource_allo_index</th>\n",
       "      <th>jarccard_coef</th>\n",
       "      <th>adamic_adar_index</th>\n",
       "      <th>preferential_attachment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>16000.000000</td>\n",
       "      <td>16000.000000</td>\n",
       "      <td>16000.000000</td>\n",
       "      <td>1.600000e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.072149</td>\n",
       "      <td>0.013657</td>\n",
       "      <td>1.710092</td>\n",
       "      <td>8.383947e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.561703</td>\n",
       "      <td>0.034148</td>\n",
       "      <td>20.153034</td>\n",
       "      <td>2.668631e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.540000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.001888</td>\n",
       "      <td>0.113775</td>\n",
       "      <td>7.263000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.005084</td>\n",
       "      <td>0.011236</td>\n",
       "      <td>0.888693</td>\n",
       "      <td>4.816200e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>187.018371</td>\n",
       "      <td>0.494118</td>\n",
       "      <td>2322.840422</td>\n",
       "      <td>2.840350e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reasource_allo_index  jarccard_coef  adamic_adar_index  \\\n",
       "count          16000.000000   16000.000000       16000.000000   \n",
       "mean               0.072149       0.013657           1.710092   \n",
       "std                1.561703       0.034148          20.153034   \n",
       "min                0.000000       0.000000           0.000000   \n",
       "25%                0.000000       0.000000           0.000000   \n",
       "50%                0.000030       0.001888           0.113775   \n",
       "75%                0.005084       0.011236           0.888693   \n",
       "max              187.018371       0.494118        2322.840422   \n",
       "\n",
       "       preferential_attachment  \n",
       "count             1.600000e+04  \n",
       "mean              8.383947e+05  \n",
       "std               2.668631e+07  \n",
       "min               0.000000e+00  \n",
       "25%               9.540000e+02  \n",
       "50%               7.263000e+03  \n",
       "75%               4.816200e+04  \n",
       "max               2.840350e+09  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_fea_df = pd.DataFrame(desire_train_feature)\n",
    "train_fea_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "desire_test_feature = list()\n",
    "for i in range(len(X_desire_test)):\n",
    "    features = {\n",
    "                'reasource_allo_index': res_allo_index(X_desire_test['Source'][i], X_desire_test['Sink'][i], G),\n",
    "                'jarccard_coef': jar_coe(X_desire_test['Source'][i], X_desire_test['Sink'][i], G),\n",
    "                'adamic_adar_index': adamic_adar_index(X_desire_test['Source'][i], X_desire_test['Sink'][i], G),\n",
    "                'preferential_attachment': preferential_attachment(X_desire_test['Source'][i], X_desire_test['Sink'][i], G)\n",
    "    }\n",
    "    desire_test_feature.append(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reasource_allo_index</th>\n",
       "      <th>jarccard_coef</th>\n",
       "      <th>adamic_adar_index</th>\n",
       "      <th>preferential_attachment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.001585</td>\n",
       "      <td>0.073847</td>\n",
       "      <td>24231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.050171</td>\n",
       "      <td>0.002445</td>\n",
       "      <td>0.877863</td>\n",
       "      <td>9804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>0.008113</td>\n",
       "      <td>0.011425</td>\n",
       "      <td>4.398665</td>\n",
       "      <td>531781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.003891</td>\n",
       "      <td>0.105323</td>\n",
       "      <td>13160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>0.011197</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.634174</td>\n",
       "      <td>1248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>0.006152</td>\n",
       "      <td>0.007949</td>\n",
       "      <td>0.708469</td>\n",
       "      <td>17545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      reasource_allo_index  jarccard_coef  adamic_adar_index  \\\n",
       "0                 0.000001       0.001585           0.073847   \n",
       "1                 0.000000       0.000000           0.000000   \n",
       "2                 0.050171       0.002445           0.877863   \n",
       "3                 0.000000       0.000000           0.000000   \n",
       "4                 0.000000       0.000000           0.000000   \n",
       "...                    ...            ...                ...   \n",
       "3995              0.008113       0.011425           4.398665   \n",
       "3996              0.000075       0.003891           0.105323   \n",
       "3997              0.000000       0.000000           0.000000   \n",
       "3998              0.011197       0.025000           0.634174   \n",
       "3999              0.006152       0.007949           0.708469   \n",
       "\n",
       "      preferential_attachment  \n",
       "0                       24231  \n",
       "1                        3550  \n",
       "2                        9804  \n",
       "3                         224  \n",
       "4                           0  \n",
       "...                       ...  \n",
       "3995                   531781  \n",
       "3996                    13160  \n",
       "3997                    11172  \n",
       "3998                     1248  \n",
       "3999                    17545  \n",
       "\n",
       "[4000 rows x 4 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_fea_df = pd.DataFrame(desire_test_feature)\n",
    "test_fea_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jaccard_followers</th>\n",
       "      <th>jaccard_followees</th>\n",
       "      <th>cosin_rec</th>\n",
       "      <th>num_followers_s</th>\n",
       "      <th>num_followers_d</th>\n",
       "      <th>num_followees_s</th>\n",
       "      <th>num_followees_d</th>\n",
       "      <th>inter_followers</th>\n",
       "      <th>inter_followees</th>\n",
       "      <th>shortest_path</th>\n",
       "      <th>...</th>\n",
       "      <th>lhn</th>\n",
       "      <th>flow2</th>\n",
       "      <th>flow3</th>\n",
       "      <th>hub_depressed</th>\n",
       "      <th>hub_promoted</th>\n",
       "      <th>sor</th>\n",
       "      <th>reasource_allo_index</th>\n",
       "      <th>jarccard_coef</th>\n",
       "      <th>adamic_adar_index</th>\n",
       "      <th>preferential_attachment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>16000.000000</td>\n",
       "      <td>16000.000000</td>\n",
       "      <td>16000.000000</td>\n",
       "      <td>16000.000000</td>\n",
       "      <td>16000.000000</td>\n",
       "      <td>16000.000000</td>\n",
       "      <td>16000.000000</td>\n",
       "      <td>16000.00000</td>\n",
       "      <td>16000.000000</td>\n",
       "      <td>16000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>16000.000000</td>\n",
       "      <td>1.600000e+04</td>\n",
       "      <td>1.600000e+04</td>\n",
       "      <td>16000.000000</td>\n",
       "      <td>16000.000000</td>\n",
       "      <td>1.600000e+04</td>\n",
       "      <td>16000.000000</td>\n",
       "      <td>16000.000000</td>\n",
       "      <td>16000.000000</td>\n",
       "      <td>1.600000e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.041698</td>\n",
       "      <td>0.001214</td>\n",
       "      <td>0.136861</td>\n",
       "      <td>19.816312</td>\n",
       "      <td>31.170938</td>\n",
       "      <td>308.736500</td>\n",
       "      <td>1362.875438</td>\n",
       "      <td>2.33925</td>\n",
       "      <td>0.475062</td>\n",
       "      <td>6.726000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009451</td>\n",
       "      <td>3.489046e-04</td>\n",
       "      <td>2.816190e-04</td>\n",
       "      <td>0.011130</td>\n",
       "      <td>0.010811</td>\n",
       "      <td>7.367214e+04</td>\n",
       "      <td>0.072149</td>\n",
       "      <td>0.013657</td>\n",
       "      <td>1.710092</td>\n",
       "      <td>8.383947e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.084653</td>\n",
       "      <td>0.014728</td>\n",
       "      <td>0.146697</td>\n",
       "      <td>41.425706</td>\n",
       "      <td>71.136443</td>\n",
       "      <td>5734.420441</td>\n",
       "      <td>25188.794319</td>\n",
       "      <td>6.31246</td>\n",
       "      <td>6.219871</td>\n",
       "      <td>19.950183</td>\n",
       "      <td>...</td>\n",
       "      <td>0.045450</td>\n",
       "      <td>2.924440e-03</td>\n",
       "      <td>2.533210e-03</td>\n",
       "      <td>0.217121</td>\n",
       "      <td>0.470735</td>\n",
       "      <td>2.214410e+06</td>\n",
       "      <td>1.561703</td>\n",
       "      <td>0.034148</td>\n",
       "      <td>20.153034</td>\n",
       "      <td>2.668631e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020255</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.692402e-09</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.540000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.086516</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.191617e-07</td>\n",
       "      <td>3.147250e-09</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.400000e+01</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.001888</td>\n",
       "      <td>0.113775</td>\n",
       "      <td>7.263000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.051282</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.209223</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004253</td>\n",
       "      <td>1.072719e-05</td>\n",
       "      <td>7.044665e-06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000e+02</td>\n",
       "      <td>0.005084</td>\n",
       "      <td>0.011236</td>\n",
       "      <td>0.888693</td>\n",
       "      <td>4.816200e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.475610</td>\n",
       "      <td>0.925499</td>\n",
       "      <td>772.000000</td>\n",
       "      <td>795.000000</td>\n",
       "      <td>385859.000000</td>\n",
       "      <td>759391.000000</td>\n",
       "      <td>274.00000</td>\n",
       "      <td>287.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.666667e-01</td>\n",
       "      <td>1.666667e-01</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>1.848260e+08</td>\n",
       "      <td>187.018371</td>\n",
       "      <td>0.494118</td>\n",
       "      <td>2322.840422</td>\n",
       "      <td>2.840350e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       jaccard_followers  jaccard_followees     cosin_rec  num_followers_s  \\\n",
       "count       16000.000000       16000.000000  16000.000000     16000.000000   \n",
       "mean            0.041698           0.001214      0.136861        19.816312   \n",
       "std             0.084653           0.014728      0.146697        41.425706   \n",
       "min             0.000000           0.000000      0.000000         0.000000   \n",
       "25%             0.000000           0.000000      0.020255         2.000000   \n",
       "50%             0.000000           0.000000      0.086516         7.000000   \n",
       "75%             0.051282           0.000000      0.209223        21.000000   \n",
       "max             1.000000           0.475610      0.925499       772.000000   \n",
       "\n",
       "       num_followers_d  num_followees_s  num_followees_d  inter_followers  \\\n",
       "count     16000.000000     16000.000000     16000.000000      16000.00000   \n",
       "mean         31.170938       308.736500      1362.875438          2.33925   \n",
       "std          71.136443      5734.420441     25188.794319          6.31246   \n",
       "min           0.000000         0.000000         0.000000          0.00000   \n",
       "25%           1.000000         0.000000         0.000000          0.00000   \n",
       "50%           9.000000         0.000000         0.000000          0.00000   \n",
       "75%          30.000000         0.000000         0.000000          2.00000   \n",
       "max         795.000000    385859.000000    759391.000000        274.00000   \n",
       "\n",
       "       inter_followees  shortest_path  ...           lhn         flow2  \\\n",
       "count     16000.000000   16000.000000  ...  16000.000000  1.600000e+04   \n",
       "mean          0.475062       6.726000  ...      0.009451  3.489046e-04   \n",
       "std           6.219871      19.950183  ...      0.045450  2.924440e-03   \n",
       "min           0.000000       2.000000  ...      0.000000  0.000000e+00   \n",
       "25%           0.000000       2.000000  ...      0.000000  1.692402e-09   \n",
       "50%           0.000000       2.000000  ...      0.000000  1.191617e-07   \n",
       "75%           0.000000       3.000000  ...      0.004253  1.072719e-05   \n",
       "max         287.000000      99.000000  ...      1.000000  1.666667e-01   \n",
       "\n",
       "              flow3  hub_depressed  hub_promoted           sor  \\\n",
       "count  1.600000e+04   16000.000000  16000.000000  1.600000e+04   \n",
       "mean   2.816190e-04       0.011130      0.010811  7.367214e+04   \n",
       "std    2.533210e-03       0.217121      0.470735  2.214410e+06   \n",
       "min    0.000000e+00       0.000000      0.000000  0.000000e+00   \n",
       "25%    0.000000e+00       0.000000      0.000000  9.000000e+00   \n",
       "50%    3.147250e-09       0.000000      0.000000  8.400000e+01   \n",
       "75%    7.044665e-06       0.000000      0.000000  6.000000e+02   \n",
       "max    1.666667e-01      21.000000     59.000000  1.848260e+08   \n",
       "\n",
       "       reasource_allo_index  jarccard_coef  adamic_adar_index  \\\n",
       "count          16000.000000   16000.000000       16000.000000   \n",
       "mean               0.072149       0.013657           1.710092   \n",
       "std                1.561703       0.034148          20.153034   \n",
       "min                0.000000       0.000000           0.000000   \n",
       "25%                0.000000       0.000000           0.000000   \n",
       "50%                0.000030       0.001888           0.113775   \n",
       "75%                0.005084       0.011236           0.888693   \n",
       "max              187.018371       0.494118        2322.840422   \n",
       "\n",
       "       preferential_attachment  \n",
       "count             1.600000e+04  \n",
       "mean              8.383947e+05  \n",
       "std               2.668631e+07  \n",
       "min               0.000000e+00  \n",
       "25%               9.540000e+02  \n",
       "50%               7.263000e+03  \n",
       "75%               4.816200e+04  \n",
       "max               2.840350e+09  \n",
       "\n",
       "[8 rows x 22 columns]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_train_features = pd.concat([X_train_features, train_fea_df], axis=1)\n",
    "all_train_features.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jaccard_followers</th>\n",
       "      <th>jaccard_followees</th>\n",
       "      <th>cosin_rec</th>\n",
       "      <th>num_followers_s</th>\n",
       "      <th>num_followers_d</th>\n",
       "      <th>num_followees_s</th>\n",
       "      <th>num_followees_d</th>\n",
       "      <th>inter_followers</th>\n",
       "      <th>inter_followees</th>\n",
       "      <th>shortest_path</th>\n",
       "      <th>...</th>\n",
       "      <th>lhn</th>\n",
       "      <th>flow2</th>\n",
       "      <th>flow3</th>\n",
       "      <th>hub_depressed</th>\n",
       "      <th>hub_promoted</th>\n",
       "      <th>sor</th>\n",
       "      <th>reasource_allo_index</th>\n",
       "      <th>jarccard_coef</th>\n",
       "      <th>adamic_adar_index</th>\n",
       "      <th>preferential_attachment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.00000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4.000000e+03</td>\n",
       "      <td>4.000000e+03</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4.000000e+03</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4.000000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.042241</td>\n",
       "      <td>0.001086</td>\n",
       "      <td>0.135453</td>\n",
       "      <td>19.961250</td>\n",
       "      <td>31.009250</td>\n",
       "      <td>547.144000</td>\n",
       "      <td>1169.85325</td>\n",
       "      <td>2.382250</td>\n",
       "      <td>0.430750</td>\n",
       "      <td>7.135750</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009473</td>\n",
       "      <td>3.177261e-04</td>\n",
       "      <td>2.586743e-04</td>\n",
       "      <td>0.016332</td>\n",
       "      <td>0.022049</td>\n",
       "      <td>9.022548e+04</td>\n",
       "      <td>0.053542</td>\n",
       "      <td>0.013809</td>\n",
       "      <td>1.560653</td>\n",
       "      <td>8.275989e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.083576</td>\n",
       "      <td>0.012643</td>\n",
       "      <td>0.147926</td>\n",
       "      <td>43.526353</td>\n",
       "      <td>71.336782</td>\n",
       "      <td>13849.236064</td>\n",
       "      <td>22523.29752</td>\n",
       "      <td>6.851122</td>\n",
       "      <td>4.838911</td>\n",
       "      <td>20.805818</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038629</td>\n",
       "      <td>2.100487e-03</td>\n",
       "      <td>1.716675e-03</td>\n",
       "      <td>0.359137</td>\n",
       "      <td>0.934449</td>\n",
       "      <td>3.202765e+06</td>\n",
       "      <td>0.311941</td>\n",
       "      <td>0.035988</td>\n",
       "      <td>6.077154</td>\n",
       "      <td>1.255715e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018300</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.281157e-09</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.942500e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083583</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.097430e-07</td>\n",
       "      <td>1.581598e-09</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.800000e+01</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.001584</td>\n",
       "      <td>0.100644</td>\n",
       "      <td>6.808000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.051282</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.206926</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004668</td>\n",
       "      <td>9.081371e-06</td>\n",
       "      <td>6.344299e-06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.027500e+02</td>\n",
       "      <td>0.004590</td>\n",
       "      <td>0.011206</td>\n",
       "      <td>0.854112</td>\n",
       "      <td>4.643875e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.297030</td>\n",
       "      <td>0.923102</td>\n",
       "      <td>772.000000</td>\n",
       "      <td>772.000000</td>\n",
       "      <td>759391.000000</td>\n",
       "      <td>759391.00000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.928596e-02</td>\n",
       "      <td>4.928018e-02</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>1.845575e+08</td>\n",
       "      <td>7.941534</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>151.256696</td>\n",
       "      <td>4.493166e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       jaccard_followers  jaccard_followees    cosin_rec  num_followers_s  \\\n",
       "count        4000.000000        4000.000000  4000.000000      4000.000000   \n",
       "mean            0.042241           0.001086     0.135453        19.961250   \n",
       "std             0.083576           0.012643     0.147926        43.526353   \n",
       "min             0.000000           0.000000     0.000000         0.000000   \n",
       "25%             0.000000           0.000000     0.018300         2.000000   \n",
       "50%             0.000000           0.000000     0.083583         7.000000   \n",
       "75%             0.051282           0.000000     0.206926        21.000000   \n",
       "max             1.000000           0.297030     0.923102       772.000000   \n",
       "\n",
       "       num_followers_d  num_followees_s  num_followees_d  inter_followers  \\\n",
       "count      4000.000000      4000.000000       4000.00000      4000.000000   \n",
       "mean         31.009250       547.144000       1169.85325         2.382250   \n",
       "std          71.336782     13849.236064      22523.29752         6.851122   \n",
       "min           0.000000         0.000000          0.00000         0.000000   \n",
       "25%           1.000000         0.000000          0.00000         0.000000   \n",
       "50%           8.000000         0.000000          0.00000         0.000000   \n",
       "75%          29.000000         0.000000          0.00000         2.000000   \n",
       "max         772.000000    759391.000000     759391.00000       155.000000   \n",
       "\n",
       "       inter_followees  shortest_path  ...          lhn         flow2  \\\n",
       "count      4000.000000    4000.000000  ...  4000.000000  4.000000e+03   \n",
       "mean          0.430750       7.135750  ...     0.009473  3.177261e-04   \n",
       "std           4.838911      20.805818  ...     0.038629  2.100487e-03   \n",
       "min           0.000000       2.000000  ...     0.000000  0.000000e+00   \n",
       "25%           0.000000       2.000000  ...     0.000000  1.281157e-09   \n",
       "50%           0.000000       2.000000  ...     0.000000  1.097430e-07   \n",
       "75%           0.000000       3.000000  ...     0.004668  9.081371e-06   \n",
       "max         121.000000      99.000000  ...     1.000000  4.928596e-02   \n",
       "\n",
       "              flow3  hub_depressed  hub_promoted           sor  \\\n",
       "count  4.000000e+03    4000.000000   4000.000000  4.000000e+03   \n",
       "mean   2.586743e-04       0.016332      0.022049  9.022548e+04   \n",
       "std    1.716675e-03       0.359137      0.934449  3.202765e+06   \n",
       "min    0.000000e+00       0.000000      0.000000  0.000000e+00   \n",
       "25%    0.000000e+00       0.000000      0.000000  8.000000e+00   \n",
       "50%    1.581598e-09       0.000000      0.000000  7.800000e+01   \n",
       "75%    6.344299e-06       0.000000      0.000000  6.027500e+02   \n",
       "max    4.928018e-02      21.000000     59.000000  1.845575e+08   \n",
       "\n",
       "       reasource_allo_index  jarccard_coef  adamic_adar_index  \\\n",
       "count           4000.000000    4000.000000        4000.000000   \n",
       "mean               0.053542       0.013809           1.560653   \n",
       "std                0.311941       0.035988           6.077154   \n",
       "min                0.000000       0.000000           0.000000   \n",
       "25%                0.000000       0.000000           0.000000   \n",
       "50%                0.000022       0.001584           0.100644   \n",
       "75%                0.004590       0.011206           0.854112   \n",
       "max                7.941534       0.647059         151.256696   \n",
       "\n",
       "       preferential_attachment  \n",
       "count             4.000000e+03  \n",
       "mean              8.275989e+05  \n",
       "std               1.255715e+07  \n",
       "min               0.000000e+00  \n",
       "25%               7.942500e+02  \n",
       "50%               6.808000e+03  \n",
       "75%               4.643875e+04  \n",
       "max               4.493166e+08  \n",
       "\n",
       "[8 rows x 22 columns]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_test_features = pd.concat([X_test_features, test_fea_df], axis=1)\n",
    "all_test_features.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 884,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import Normalizer\n",
    "# scaler = Normalizer(norm='l2')\n",
    "\n",
    "# scaler.fit(all_train_features)\n",
    "# all_train_features = scaler.transform(all_train_features)\n",
    "\n",
    "# scaler.fit(all_test_features)\n",
    "# all_test_features = scaler.transform(all_test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(X_desire_train, open('save/X_desire_train_data1.p','wb'))\n",
    "pickle.dump(y_desire_train, open('save/y_desire_train_data_label1.p','wb'))\n",
    "pickle.dump(X_desire_test, open('save/X_desire_test_data1.p','wb'))\n",
    "pickle.dump(y_desire_test, open('save/y_desire_test_data_label1.p','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(all_train_features, open('save/all_train_features1.p','wb'))\n",
    "pickle.dump(all_test_features, open('save/all_test_features1.p','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr_clf = LogisticRegression()\n",
    "lr_clf.fit(all_train_features, y_desire_train)\n",
    "# lr_clf.fit(X_train_features, y_desire_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.50125"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_clf.score(all_test_features, y_desire_test)\n",
    "# lr_clf.score(X_test_features, y_desire_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "def evaluate_roc_auc(clf, features, labels):\n",
    "    predicted = clf.predict_proba(features)\n",
    "\n",
    "    # check which class corresponds to positive links\n",
    "    positive_column = list(clf.classes_).index(1)\n",
    "    return roc_auc_score(labels, predicted[:, positive_column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=10, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=-1, oob_score=False, random_state=90051,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_clf = RandomForestClassifier(max_depth=10, random_state=90051, n_jobs=-1)\n",
    "rf_clf.fit(all_train_features, y_desire_train)\n",
    "# rf_clf.fit(X_train_features, y_desire_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85075"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_clf.score(all_test_features, y_desire_test)\n",
    "# rf_clf.score(X_test_features, y_desire_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 982,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.41947926e-02, 1.28865552e-04, 9.13911375e-02, 2.26704699e-02,\n",
       "       4.76901516e-02, 3.75759789e-03, 4.79726697e-03, 8.26624794e-03,\n",
       "       9.55759002e-05, 6.57976410e-02, 1.04121847e-02, 3.99208399e-02,\n",
       "       6.15069278e-04, 3.53766400e-03, 1.36974242e-02, 1.32724587e-01,\n",
       "       1.47883850e-01, 1.70422842e-01, 5.70587031e-02, 8.06543317e-02,\n",
       "       8.42827577e-02])"
      ]
     },
     "execution_count": 982,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances = rf_clf.feature_importances_\n",
    "importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9333645841146028\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "base = RandomForestClassifier()\n",
    "rf_param = {\n",
    "#     \"max_depth\":[7,9,11,13],\n",
    "    \"max_depth\":[15,17,19],\n",
    "#     \"min_samples_leaf\":[1,3,5],\n",
    "    \"min_samples_leaf\":[1],\n",
    "#     \"min_samples_split\":[2,4,6,8,10],\n",
    "    \"min_samples_split\":[4,6],\n",
    "#     \"max_features\":[\"sqrt\", \"log2\"],\n",
    "    \"max_features\":[\"log2\"],\n",
    "#     \"n_estimators\":[100]\n",
    "    \"n_estimators\":[1000,1200,1400,1600]\n",
    "}\n",
    "\n",
    "\n",
    "rf_grid = GridSearchCV(base, rf_param, n_jobs=-1, scoring='roc_auc')\n",
    "rf_grid.fit(all_train_features, y_desire_train)\n",
    "print(rf_grid.score(all_test_features, y_desire_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 979,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = rf_grid.best_estimator_.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=15, max_features='log2',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=6,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=1600,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 981,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.98330121e-02, 1.39174242e-04, 9.94969115e-02, 2.94160918e-02,\n",
       "       5.72694138e-02, 6.79110552e-03, 6.06283093e-03, 9.80153065e-03,\n",
       "       1.53878134e-04, 6.29048877e-02, 1.04874733e-02, 4.83532047e-02,\n",
       "       3.01134059e-04, 4.61230874e-03, 1.88372160e-02, 1.24670832e-01,\n",
       "       1.02001207e-01, 1.72028930e-01, 6.17423266e-02, 6.87002824e-02,\n",
       "       9.63962491e-02])"
      ]
     },
     "execution_count": 981,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_clf_dart = lightgbm.LGBMClassifier(boosting_type='dart',learning_rate=0.15,\n",
    "                                               subsample=0.5,\n",
    "                                               num_leaves=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_clf_gbdt = lightgbm.LGBMClassifier(boosting_type='gbdt',learning_rate=0.1,\n",
    "                                               subsample=0.5,max_depth=4,\n",
    "                                               num_leaves=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_clf_rf = lightgbm.LGBMClassifier(boosting_type='rf',bagging_freq=1,\n",
    "                                               bagging_fraction=0.75,feature_fraction=0.75,\n",
    "                                               num_leaves=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='dart', class_weight=None, colsample_bytree=1.0,\n",
       "               importance_type='split', learning_rate=0.15, max_depth=-1,\n",
       "               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "               n_estimators=100, n_jobs=-1, num_leaves=20, objective=None,\n",
       "               random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "               subsample=0.5, subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_clf_dart.fit(all_train_features, y_desire_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9349279034514254"
      ]
     },
     "execution_count": 636,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_roc_auc(lgb_clf_dart, all_test_features, y_desire_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9333645841146028"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_roc_auc(rf_grid, all_test_features, y_desire_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "voting = VotingClassifier(\n",
    "#     estimators=[('rf', rf_grid), ('xgb', xgb_grid), ('ada', ada_clf)]\n",
    "    estimators=[\n",
    "        ('lgb_dart', lgb_clf_dart), \n",
    "        ('lgb_gbdt', lgb_clf_gbdt), \n",
    "        ('lgb_rf', lgb_clf_rf),\n",
    "        \n",
    "    ]\n",
    "    , voting='soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lgb_dart',\n",
       "                              LGBMClassifier(boosting_type='dart',\n",
       "                                             class_weight=None,\n",
       "                                             colsample_bytree=1.0,\n",
       "                                             importance_type='split',\n",
       "                                             learning_rate=0.15, max_depth=-1,\n",
       "                                             min_child_samples=20,\n",
       "                                             min_child_weight=0.001,\n",
       "                                             min_split_gain=0.0,\n",
       "                                             n_estimators=100, n_jobs=-1,\n",
       "                                             num_leaves=20, objective=None,\n",
       "                                             random_state=None, reg_alpha=0.0,\n",
       "                                             reg_lambda=0.0, silent=True,...\n",
       "                                             importance_type='split',\n",
       "                                             learning_rate=0.1, max_depth=-1,\n",
       "                                             min_child_samples=20,\n",
       "                                             min_child_weight=0.001,\n",
       "                                             min_split_gain=0.0,\n",
       "                                             n_estimators=100, n_jobs=-1,\n",
       "                                             num_leaves=20, objective=None,\n",
       "                                             random_state=None, reg_alpha=0.0,\n",
       "                                             reg_lambda=0.0, silent=True,\n",
       "                                             subsample=1.0,\n",
       "                                             subsample_for_bin=200000,\n",
       "                                             subsample_freq=0))],\n",
       "                 flatten_transform=True, n_jobs=None, voting='soft',\n",
       "                 weights=None)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting.fit(all_train_features, y_desire_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.85925\n"
     ]
    }
   ],
   "source": [
    "print(voting.score(all_test_features, y_desire_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.929566703400492"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_roc_auc(voting, all_test_features, y_desire_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_data = read_sub()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Sink</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3563811</td>\n",
       "      <td>3600160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2052043</td>\n",
       "      <td>1401960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4517994</td>\n",
       "      <td>1690636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1660006</td>\n",
       "      <td>4349447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>581111</td>\n",
       "      <td>1882617</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Source     Sink\n",
       "0  3563811  3600160\n",
       "1  2052043  1401960\n",
       "2  4517994  1690636\n",
       "3  1660006  4349447\n",
       "4   581111  1882617"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sub = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sub['jaccard_followers'] = sub_data.apply(\n",
    "    lambda row:jaccard_followers(row['Source'], row['Sink'], train_graph=g), \n",
    "    axis=1)\n",
    "\n",
    "#mapping jaccrd followees to train and test data\n",
    "X_sub['jaccard_followees'] = sub_data.apply(\n",
    "    lambda row:jaccard_followees(row['Source'], row['Sink'], train_graph=g), \n",
    "    axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sub['cosin_rec'] = sub_data.apply(lambda row: sub_cosin_dict[(row['Source'], row['Sink'])], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sub['num_followers_s'], X_sub['num_followers_d'], \\\n",
    "X_sub['num_followees_s'], X_sub['num_followees_d'], \\\n",
    "X_sub['inter_followers'], X_sub['inter_followees'] = compute_features_stage1(sub_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sub['shortest_path'] = sub_data.apply(lambda row: compute_shortest_path_length(row['Source'], row['Sink']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sub['c_nei'] = sub_data.apply(lambda row: common_neighbours(row['Source'], row['Sink']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sub['prefer'] = sub_data.apply(lambda row: preferencial_attchment(row['Source'], row['Sink']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sub['sor'] = sub_data.apply(lambda row: sorensen(row['Source'], row['Sink']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sub['flow2'] = sub_data.apply(lambda row: random_walk_sub[(row['Source'], row['Sink'])][0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sub['flow3'] = sub_data.apply(lambda row: random_walk_sub[(row['Source'], row['Sink'])][1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00:00,  2.11s/it]\n"
     ]
    }
   ],
   "source": [
    "mappings = [\n",
    "    hub_depressed, \n",
    "    hub_promoted\n",
    "]\n",
    "\n",
    "for f in tqdm(mappings, position=0, leave=True):\n",
    "    X_sub[f.__name__] = sub_data.apply(lambda row: f(row['Source'], row['Sink']), axis=1)\n",
    "    X_sub[f.__name__] = sub_data.apply(lambda row:f(row['Source'], row['Sink']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sub['lhn'] = X_sub.apply(lambda row: lhn(row['c_nei'], row['prefer']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_feature = list()\n",
    "for i in range(len(sub_data)):\n",
    "    features = {\n",
    "                'reasource_allo_index': res_allo_index(sub_data['Source'][i], sub_data['Sink'][i], G),\n",
    "                'jarccard_coef': jar_coe(sub_data['Source'][i], sub_data['Sink'][i], G),\n",
    "                'adamic_adar_index': adamic_adar_index(sub_data['Source'][i], sub_data['Sink'][i], G),\n",
    "                'preferential_attachment': preferential_attachment(sub_data['Source'][i], sub_data['Sink'][i], G)\n",
    "    }\n",
    "    submission_feature.append(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reasource_allo_index</th>\n",
       "      <th>jarccard_coef</th>\n",
       "      <th>adamic_adar_index</th>\n",
       "      <th>preferential_attachment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.004624</td>\n",
       "      <td>0.011152</td>\n",
       "      <td>0.462729</td>\n",
       "      <td>4335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.003670</td>\n",
       "      <td>0.178806</td>\n",
       "      <td>18396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.006061</td>\n",
       "      <td>0.100722</td>\n",
       "      <td>5125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>502</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      reasource_allo_index  jarccard_coef  adamic_adar_index  \\\n",
       "0                 0.000000       0.000000           0.000000   \n",
       "1                 0.000000       0.000000           0.000000   \n",
       "2                 0.004624       0.011152           0.462729   \n",
       "3                 0.000028       0.003670           0.178806   \n",
       "4                 0.000000       0.000000           0.000000   \n",
       "...                    ...            ...                ...   \n",
       "1995              0.000000       0.000000           0.000000   \n",
       "1996              0.000049       0.006061           0.100722   \n",
       "1997              0.000000       0.000000           0.000000   \n",
       "1998              0.000000       0.000000           0.000000   \n",
       "1999              0.000000       0.000000           0.000000   \n",
       "\n",
       "      preferential_attachment  \n",
       "0                         667  \n",
       "1                         666  \n",
       "2                        4335  \n",
       "3                       18396  \n",
       "4                         920  \n",
       "...                       ...  \n",
       "1995                      116  \n",
       "1996                     5125  \n",
       "1997                       58  \n",
       "1998                      171  \n",
       "1999                      502  \n",
       "\n",
       "[2000 rows x 4 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_fea_df = pd.DataFrame(submission_feature)\n",
    "submission_fea_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jaccard_followers</th>\n",
       "      <th>jaccard_followees</th>\n",
       "      <th>cosin_rec</th>\n",
       "      <th>num_followers_s</th>\n",
       "      <th>num_followers_d</th>\n",
       "      <th>num_followees_s</th>\n",
       "      <th>num_followees_d</th>\n",
       "      <th>inter_followers</th>\n",
       "      <th>inter_followees</th>\n",
       "      <th>shortest_path</th>\n",
       "      <th>...</th>\n",
       "      <th>lhn</th>\n",
       "      <th>flow2</th>\n",
       "      <th>flow3</th>\n",
       "      <th>hub_depressed</th>\n",
       "      <th>hub_promoted</th>\n",
       "      <th>sor</th>\n",
       "      <th>reasource_allo_index</th>\n",
       "      <th>jarccard_coef</th>\n",
       "      <th>adamic_adar_index</th>\n",
       "      <th>preferential_attachment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013077</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009110</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8.123854e-08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.088616</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>7.365540e-05</td>\n",
       "      <td>7.788287e-05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50</td>\n",
       "      <td>0.004624</td>\n",
       "      <td>0.011152</td>\n",
       "      <td>0.462729</td>\n",
       "      <td>4335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.175508</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>5.578524e-08</td>\n",
       "      <td>7.085983e-08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>120</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.003670</td>\n",
       "      <td>0.178806</td>\n",
       "      <td>18396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.023031</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>6.330539e-09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>46</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.018680</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.270053e-08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004964</td>\n",
       "      <td>33</td>\n",
       "      <td>14</td>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000649</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8.028945e-09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010526</td>\n",
       "      <td>1540</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.006061</td>\n",
       "      <td>0.100722</td>\n",
       "      <td>5125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.034330</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.424484e-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011626</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.138948e-09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017670</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.085026e-10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>502</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      jaccard_followers  jaccard_followees  cosin_rec  num_followers_s  \\\n",
       "0              0.000000                0.0   0.013077                1   \n",
       "1              0.000000                0.0   0.009110                7   \n",
       "2              0.071429                0.0   0.088616               10   \n",
       "3              0.047619                0.0   0.175508               10   \n",
       "4              0.000000                0.0   0.023031                2   \n",
       "...                 ...                ...        ...              ...   \n",
       "1995           0.000000                0.0   0.018680                1   \n",
       "1996           0.021739                0.0   0.004964               33   \n",
       "1997           0.000000                0.0   0.034330                5   \n",
       "1998           0.000000                0.0   0.011626                2   \n",
       "1999           0.000000                0.0   0.017670                2   \n",
       "\n",
       "      num_followers_d  num_followees_s  num_followees_d  inter_followers  \\\n",
       "0                  10                0                0                0   \n",
       "1                   2                0                0                0   \n",
       "2                   5                0                0                1   \n",
       "3                  12                0                0                1   \n",
       "4                  23                0                0                0   \n",
       "...               ...              ...              ...              ...   \n",
       "1995                1                0                0                0   \n",
       "1996               14               95                0                1   \n",
       "1997                2                0                0                0   \n",
       "1998                1                0                0                0   \n",
       "1999                2                0                0                0   \n",
       "\n",
       "      inter_followees  shortest_path  ...       lhn         flow2  \\\n",
       "0                   0              3  ...  0.000000  0.000000e+00   \n",
       "1                   0              3  ...  0.000000  0.000000e+00   \n",
       "2                   0              2  ...  0.020000  7.365540e-05   \n",
       "3                   0              2  ...  0.008333  5.578524e-08   \n",
       "4                   0              3  ...  0.000000  0.000000e+00   \n",
       "...               ...            ...  ...       ...           ...   \n",
       "1995                0              3  ...  0.000000  0.000000e+00   \n",
       "1996                0              2  ...  0.000649  0.000000e+00   \n",
       "1997                0              3  ...  0.000000  0.000000e+00   \n",
       "1998                0              3  ...  0.000000  0.000000e+00   \n",
       "1999                0              3  ...  0.000000  0.000000e+00   \n",
       "\n",
       "             flow3  hub_depressed  hub_promoted   sor  reasource_allo_index  \\\n",
       "0     0.000000e+00            0.0      0.000000    10              0.000000   \n",
       "1     8.123854e-08            0.0      0.000000    14              0.000000   \n",
       "2     7.788287e-05            0.0      0.000000    50              0.004624   \n",
       "3     7.085983e-08            0.0      0.000000   120              0.000028   \n",
       "4     6.330539e-09            0.0      0.000000    46              0.000000   \n",
       "...            ...            ...           ...   ...                   ...   \n",
       "1995  1.270053e-08            0.0      0.000000     1              0.000000   \n",
       "1996  8.028945e-09            0.0      0.010526  1540              0.000049   \n",
       "1997  1.424484e-07            0.0      0.000000    10              0.000000   \n",
       "1998  1.138948e-09            0.0      0.000000     2              0.000000   \n",
       "1999  1.085026e-10            0.0      0.000000     4              0.000000   \n",
       "\n",
       "      jarccard_coef  adamic_adar_index  preferential_attachment  \n",
       "0          0.000000           0.000000                      667  \n",
       "1          0.000000           0.000000                      666  \n",
       "2          0.011152           0.462729                     4335  \n",
       "3          0.003670           0.178806                    18396  \n",
       "4          0.000000           0.000000                      920  \n",
       "...             ...                ...                      ...  \n",
       "1995       0.000000           0.000000                      116  \n",
       "1996       0.006061           0.100722                     5125  \n",
       "1997       0.000000           0.000000                       58  \n",
       "1998       0.000000           0.000000                      171  \n",
       "1999       0.000000           0.000000                      502  \n",
       "\n",
       "[2000 rows x 22 columns]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_sub_features = pd.concat([X_sub, submission_fea_df], axis=1)\n",
    "all_sub_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(all_sub_features, open('save/all_sub_features1.p','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 843,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import Normalizer\n",
    "# scaler = Normalizer(norm='l2')\n",
    "\n",
    "# scaler.fit(all_sub_features)\n",
    "# all_sub_features = scaler.transform(all_sub_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_sub['cosin_rec'] = sub_data.apply(lambda row: sub_cosin_dict[(row['Source'], row['Sink'])], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 969,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"save/all_sub_features.p\", \"wb\") as f:\n",
    "    pickle.dump(all_sub_features, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 21)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_sub_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_sub = voting.predict_proba(all_sub_features)\n",
    "y_sub = rf_grid.predict_proba(all_sub_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.90723864, 0.09276136],\n",
       "       [0.88313184, 0.11686816],\n",
       "       [0.00561666, 0.99438334],\n",
       "       [0.82503714, 0.17496286],\n",
       "       [0.93084603, 0.06915397],\n",
       "       [0.72072096, 0.27927904],\n",
       "       [0.89827279, 0.10172721],\n",
       "       [0.96766158, 0.03233842],\n",
       "       [0.87978143, 0.12021857],\n",
       "       [0.93212339, 0.06787661],\n",
       "       [0.71810801, 0.28189199],\n",
       "       [0.88170535, 0.11829465],\n",
       "       [0.00583333, 0.99416667],\n",
       "       [0.86686246, 0.13313754],\n",
       "       [0.96209116, 0.03790884]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_sub[0:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rf_clf.predict(all_sub_features)[:15]\n",
    "rf_grid.predict(all_sub_features)[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "829"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sum(rf_clf.predict(all_sub_features))\n",
    "sum(rf_grid.predict(all_sub_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(data={\"Id\":range(1,len(y_sub)+1), \"Predicted\":[x[1] for x in y_sub]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('new_feature.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.092761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.116868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.994383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.174963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.069154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  Predicted\n",
       "0   1   0.092761\n",
       "1   2   0.116868\n",
       "2   3   0.994383\n",
       "3   4   0.174963\n",
       "4   5   0.069154"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_1 = pd.read_csv(\"submission_file/nx_submissioin_rf_with_flow.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_2 = pd.read_csv(\"submission_file/nx_submissioin_rf_norm.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_list = []\n",
    "for i in range(len(result_2)):\n",
    "    if abs(result_1.iloc[i]['Predicted'] - result_2.iloc[i]['Predicted']) >= 0.5:\n",
    "        diff_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(diff_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}